--- BENCHMARK FOR testing_tensorflow_v2 ---
Executing TF on n_holes=2 ---------------------------
2019-06-20 14:50:07.377597: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 14:50:07.397784: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 14:50:07.398103: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55dc6b577b20 executing computations on platform Host. Devices:
2019-06-20 14:50:07.398135: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-0.25
Wrote profile results to testing_tensorflow_v2_bench.py.lprof
Timer unit: 1e-06 s

Total time: 0.004079 s
File: testing_tensorflow_v2_bench.py
Function: build_hamiltonian at line 22

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    22                                           @profile
    23                                           def build_hamiltonian(n_hole_states, n_particle_states):
    24         1          0.0      0.0      0.0      numh = n_hole_states
    25         1          1.0      1.0      0.0      nump = n_particle_states
    26         1          1.0      1.0      0.0      nums = numh + nump
    27                                               
    28         1         52.0     52.0      1.3      ref = np.append(np.ones(numh), np.zeros(nump))
    29         1          5.0      5.0      0.1      holes = np.arange(numh)
    30         1          1.0      1.0      0.0      particles = np.arange(numh,numh+nump)
    31         1          9.0      9.0      0.2      B1 = np.append(holes,particles)
    32                                               
    33                                               # one body part of Hamiltonian is floor-division of basis index
    34                                               # matrix elements are (P-1) where P is energy level
    35         1         26.0     26.0      0.6      H1B = np.diag(np.floor_divide(B1,2))
    36                                           
    37         1          3.0      3.0      0.1      H2B = np.zeros((nums, nums, nums, nums))
    38         5          4.0      0.8      0.1      for p in B1:
    39        20         15.0      0.8      0.4          for q in B1:
    40        80         61.0      0.8      1.5              for r in B1:
    41       320        258.0      0.8      6.3                  for s in B1:
    42                                           
    43       256        603.0      2.4     14.8                      pp = np.floor_divide(p,2)
    44       256        593.0      2.3     14.5                      qp = np.floor_divide(q,2)
    45       256        568.0      2.2     13.9                      rp = np.floor_divide(r,2)
    46       256        560.0      2.2     13.7                      sp = np.floor_divide(s,2)
    47                                           
    48       256        270.0      1.1      6.6                      ps = 1 if p%2==0 else -1
    49       256        245.0      1.0      6.0                      qs = 1 if q%2==0 else -1
    50       256        248.0      1.0      6.1                      rs = 1 if r%2==0 else -1
    51       256        243.0      0.9      6.0                      ss = 1 if s%2==0 else -1
    52                                           
    53       256        166.0      0.6      4.1                      if pp != qp or rp != sp:
    54        64         44.0      0.7      1.1                          continue
    55        64         44.0      0.7      1.1                      if ps == qs or rs == ss:
    56        16         11.0      0.7      0.3                          continue
    57        16         13.0      0.8      0.3                      if ps == rs and qs == ss:
    58         8         11.0      1.4      0.3                          H2B[p,q,r,s] = -0.25
    59        16         13.0      0.8      0.3                      if ps == ss and qs == rs:
    60         8         10.0      1.2      0.2                          H2B[p,q,r,s] = 0.25
    61                                                                   
    62         1          1.0      1.0      0.0      return (H1B, H2B, ref, holes, particles, B1)

Total time: 3.7e-05 s
File: testing_tensorflow_v2_bench.py
Function: get_occA at line 65

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    65                                           @profile
    66                                           def get_occA(B1_basis, ref):
    67         1          1.0      1.0      2.7      n = len(B1_basis)
    68         1          4.0      4.0     10.8      occA = np.zeros((n,n,n,n))
    69                                               
    70         5          3.0      0.6      8.1      for a in B1_basis:
    71        20         11.0      0.6     29.7          for b in B1_basis:
    72        16         18.0      1.1     48.6              occA[a,b,a,b] = ref[a] - ref[b]
    73                                                       
    74         1          0.0      0.0      0.0      return occA

Total time: 3.4e-05 s
File: testing_tensorflow_v2_bench.py
Function: get_occB at line 77

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    77                                           @profile
    78                                           def get_occB(B1_basis, ref):
    79         1          1.0      1.0      2.9      n = len(B1_basis)    
    80         1          2.0      2.0      5.9      occB = np.zeros((n,n,n,n))
    81                                               
    82         5          3.0      0.6      8.8      for a in B1_basis:
    83        20          9.0      0.5     26.5          for b in B1_basis:
    84        16         19.0      1.2     55.9              occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                                       
    86         1          0.0      0.0      0.0      return occB

Total time: 0.000192 s
File: testing_tensorflow_v2_bench.py
Function: get_occC at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                           @profile
    90                                           def get_occC(B1_basis, ref):
    91         1          1.0      1.0      0.5      n = len(B1_basis)        
    92         1         13.0     13.0      6.8      occC = np.zeros((n,n,n,n,n,n))
    93                                               
    94         5          3.0      0.6      1.6      for a in B1_basis:
    95        20         11.0      0.6      5.7          for b in B1_basis:
    96        80         41.0      0.5     21.4              for c in B1_basis:
    97        64        123.0      1.9     64.1                  occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                                           
    99         1          0.0      0.0      0.0      return occC

Total time: 0.000815 s
File: testing_tensorflow_v2_bench.py
Function: get_occD at line 102

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   102                                           @profile
   103                                           def get_occD(B1_basis, ref):
   104         1          1.0      1.0      0.1      n = len(B1_basis)    
   105         1          2.0      2.0      0.2      occD = np.zeros((n,n,n,n))
   106                                               
   107         5          4.0      0.8      0.5      for a in B1_basis:
   108        20         12.0      0.6      1.5          for b in B1_basis:
   109        80         43.0      0.5      5.3              for c in B1_basis:
   110       320        175.0      0.5     21.5                  for d in B1_basis:
   111       256        578.0      2.3     70.9                      occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                               
   113         1          0.0      0.0      0.0      return occD

Total time: 0.380169 s
File: testing_tensorflow_v2_bench.py
Function: normal_order at line 126

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   126                                           @profile
   127                                           def normal_order(H1B_t, H2B_t, holes):
   128                                               
   129         1      10616.0  10616.0      2.8      H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130         1        850.0    850.0      0.2      H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131         1        784.0    784.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                               
   133                                               # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134         1      21147.0  21147.0      5.6      with tf.Session() as sess:
   135                                                   
   136                                                   # - Calculate 0B tensor
   137                                                   # E = tf.Variable(0.0)
   138         1     104382.0 104382.0     27.5          contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139         1      96889.0  96889.0     25.5          contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                                           
   141         1       2534.0   2534.0      0.7          E_1b = tf.reduce_sum(contr_1b, 0)
   142         1       4620.0   4620.0      1.2          E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143         1       1293.0   1293.0      0.3          E = tf.add_n([E_1b, E_2b])
   144                                           
   145                                                   # - Calculate 1B tensor
   146         1      89724.0  89724.0     23.6          contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147         1       2494.0   2494.0      0.7          contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                                           
   149         1       1281.0   1281.0      0.3          f = tf.add_n([H1B_t, contr_2b])
   150                                           
   151                                                   # - Calculate 2B tensor
   152         1       1031.0   1031.0      0.3          G = tf.identity(H2B_t)
   153                                                   
   154         1      42506.0  42506.0     11.2          E_e, f_e, G_e = sess.run([E, f, G])
   155                                           #         E_e = E.eval()
   156                                           #         f_e = f.eval()
   157                                           #         G_e = G.eval()
   158                                                   
   159                                           #         print(sess.run([E, f, G]))
   160                                                   
   161         1         16.0     16.0      0.0      tf.reset_default_graph()
   162                                               
   163         1          2.0      2.0      0.0      return (E_e, f_e, G_e)

Total time: 0.420127 s
File: testing_tensorflow_v2_bench.py
Function: wegner at line 236

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                           @profile
   237                                           def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                               
   239         1       1192.0   1192.0      0.3      f = tf.convert_to_tensor(f, dtype=tf.float32)
   240         1        846.0    846.0      0.2      G = tf.convert_to_tensor(G, dtype=tf.float32)
   241         1        781.0    781.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242         1        776.0    776.0      0.2      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243         1        819.0    819.0      0.2      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244         1        805.0    805.0      0.2      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245         1        848.0    848.0      0.2      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246         1        802.0    802.0      0.2      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                               
   248         1        161.0    161.0      0.0      with tf.Session() as sess:
   249         1       1079.0   1079.0      0.3          plen = tf.size(particles)
   250         1        931.0    931.0      0.2          hlen = tf.size(holes)
   251                                           
   252                                                   # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                                   
   254                                                   # Decoupling 1B piece
   255                                                   # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256         1       3125.0   3125.0      0.7          particles_b = tf.broadcast_to(particles, [plen,plen])
   257         1       2917.0   2917.0      0.7          holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258         1       2388.0   2388.0      0.6          ph_comb = tf.concat([particles_b, holes_b], 0)
   259         1       4622.0   4622.0      1.1          hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                                   
   261         1       2170.0   2170.0      0.5          col_indices =tf.reshape(ph_comb, [-1])
   262         1       2218.0   2218.0      0.5          row_indices = tf.reshape(hp_comb, [-1])
   263         1       1713.0   1713.0      0.4          ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264         1       1336.0   1336.0      0.3          ph_updates = tf.gather_nd(f, ph_indices)
   265                                           
   266         1       2391.0   2391.0      0.6          fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267         1       1184.0   1184.0      0.3          fd = tf.subtract(f,fod)
   268                                           
   269                                                   # Decoupling 2B piece
   270                                                   # indices are constructed by all possible combinations of pphh(hhpp) states
   271         1      18563.0  18563.0      4.4          ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272         1       3521.0   3521.0      0.8          ind1_TC = tf.transpose(ind1_C) 
   273         1       2230.0   2230.0      0.5          ind1 = tf.reshape(ind1_TC,[-1])
   274                                           
   275         1      17882.0  17882.0      4.3          ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276         1       2429.0   2429.0      0.6          ind2_TC = tf.transpose(ind2_C)
   277         1       2176.0   2176.0      0.5          ind2 = tf.reshape(ind2_TC,[-1])
   278                                           
   279         1      12860.0  12860.0      3.1          ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280         1       2381.0   2381.0      0.6          ind3_TC = tf.transpose(ind3_C) 
   281         1       2160.0   2160.0      0.5          ind3 = tf.reshape(ind3_TC,[-1])
   282                                           
   283         1      15020.0  15020.0      3.6          ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284         1       2322.0   2322.0      0.6          ind4_TC = tf.transpose(ind4_C)
   285         1       2401.0   2401.0      0.6          ind4 = tf.reshape(ind4_TC,[-1])
   286                                           
   287         1       1571.0   1571.0      0.4          pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288         1       1311.0   1311.0      0.3          pphh_updates = tf.gather_nd(G, pphh_indices)
   289                                           
   290         1       2516.0   2516.0      0.6          God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291         1       1256.0   1256.0      0.3          Gd = tf.subtract(G,God)
   292                                           
   293                                           
   294                                                   # --- 1B piece
   295                                           
   296                                                   # Calculate 1B-1B contribution
   297         1      13383.0  13383.0      3.2          fd_fod = tf.tensordot(fd,fod,1)
   298         1       2408.0   2408.0      0.6          fd_fod_T = tf.transpose(fd_fod)
   299         1       1178.0   1178.0      0.3          eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                                           
   301                                                   # Calculate 1B-2B contribution
   302         1      25857.0  25857.0      6.2          fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303         1      25878.0  25878.0      6.2          fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304         1       1210.0   1210.0      0.3          eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                                           
   306                                                   # Calculate 2B-2B contribution
   307         1      26606.0  26606.0      6.3          Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308         1       2325.0   2325.0      0.6          Gd_God_T = tf.transpose(Gd_God)
   309         1       3277.0   3277.0      0.8          scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310         1          2.0      2.0      0.0          eta1B_2b2b = scaled_sub
   311                                           
   312         1       1371.0   1371.0      0.3          eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                                           
   314                                           
   315                                           
   316                                                   # --- 2B piece
   317                                           
   318                                                   # Calculate 1B-2B contribution
   319         1      28406.0  28406.0      6.8          fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320         1       2274.0   2274.0      0.5          fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321         1       1180.0   1180.0      0.3          ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                                           
   323         1      34061.0  34061.0      8.1          fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324         1       2347.0   2347.0      0.6          fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325         1       2268.0   2268.0      0.5          fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326         1       1192.0   1192.0      0.3          kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                                           
   328         1       1199.0   1199.0      0.3          eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                                           
   330                                           
   331                                                   # Calculate 2B-2B contribution
   332         1      25986.0  25986.0      6.2          GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333         1      25865.0  25865.0      6.2          GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334         1       3306.0   3306.0      0.8          scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                                           
   336         1          2.0      2.0      0.0          eta2B_2b2b_B = scaled_sub
   337                                           
   338         1      12931.0  12931.0      3.1          GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339         1       2219.0   2219.0      0.5          GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340         1      13070.0  13070.0      3.1          GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341         1       2232.0   2232.0      0.5          GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342         1       2218.0   2218.0      0.5          GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343         1       2203.0   2203.0      0.5          GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344         1       1244.0   1244.0      0.3          sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345         1       1202.0   1202.0      0.3          sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346         1       1185.0   1185.0      0.3          add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                                           
   348         1          2.0      2.0      0.0          eta2B_2b2b_A = add3
   349                                           
   350         1       1377.0   1377.0      0.3          eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                                   
   352         1      13644.0  13644.0      3.2          eta1B_e = eta1B.eval()
   353         1      11301.0  11301.0      2.7          eta2B_e = eta2B.eval()
   354                                                   
   355         1         14.0     14.0      0.0      tf.reset_default_graph()
   356                                               
   357         1          1.0      1.0      0.0      return (eta1B_e, eta2B_e)

Total time: 0.424412 s
File: testing_tensorflow_v2_bench.py
Function: flow at line 364

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   364                                           @profile
   365                                           def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                               
   367         1       1298.0   1298.0      0.3      f = tf.convert_to_tensor(f, dtype=tf.float32)
   368         1        858.0    858.0      0.2      G = tf.convert_to_tensor(G, dtype=tf.float32)
   369         1        784.0    784.0      0.2      eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370         1        878.0    878.0      0.2      eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371         1        788.0    788.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372         1        780.0    780.0      0.2      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373         1        809.0    809.0      0.2      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374         1        802.0    802.0      0.2      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375         1        915.0    915.0      0.2      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376         1        810.0    810.0      0.2      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                               
   378         1        165.0    165.0      0.0      with tf.Session() as sess:
   379                                                   
   380                                                   # --- 0B piece
   381                                           
   382                                                   # Calculate 1B-1B contribution (full contraction)
   383         1      13044.0  13044.0      3.1          occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384         1      12953.0  12953.0      3.1          occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385         1       1198.0   1198.0      0.3          dE_1b1b = tf.identity(occA_e1_f)
   386                                           
   387                                                   # Calculate 2B-2B contribution (full contraction)
   388                                               #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389         1       1614.0   1614.0      0.4          e2_occD = tf.matmul(eta2B, occD_t)
   390         1      15404.0  15404.0      3.6          e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391         1       1054.0   1054.0      0.2          dE_2b2b = tf.identity(e2_occD_G)
   392                                           
   393         1       1318.0   1318.0      0.3          dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                                           
   395                                                   # --- 1B piece
   396                                           
   397                                                   # Calculate 1B-1B contribution (contraction over 1 index)
   398         1      12807.0  12807.0      3.0          e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399         1       2331.0   2331.0      0.5          e1_f_T = tf.transpose(e1_f)
   400         1       1164.0   1164.0      0.3          e1_f_add = tf.add(e1_f,e1_f_T)
   401         1       1048.0   1048.0      0.2          df_1b1b = tf.identity(e1_f_add)
   402                                           
   403                                                   # Calculate 1B-2B contribution (contraction over 2 indices)
   404         1      32561.0  32561.0      7.7          occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405         1      26013.0  26013.0      6.1          occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406         1       1194.0   1194.0      0.3          sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407         1       1050.0   1050.0      0.2          df_1b2b = tf.identity(sub_1b2b)
   408                                           
   409                                                   # Calculate 2B-2B contribution (contraction over 3 indices)
   410         1      26306.0  26306.0      6.2          e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411         1       2291.0   2291.0      0.5          e2_occC_G_T = tf.transpose(e2_occC_G)
   412         1       3244.0   3244.0      0.8          add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413         1       1046.0   1046.0      0.2          df_2b2b = tf.identity(add_2b2b)
   414                                           
   415         1       1376.0   1376.0      0.3          df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                                           
   417                                                   # --- 2B piece
   418                                           
   419                                                   # Calculate 1B-2B contribution (contraction over 1 index)
   420         1      91243.0  91243.0     21.5          e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421         1       2315.0   2315.0      0.5          e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422         1       1280.0   1280.0      0.3          ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                                           
   424         1      27411.0  27411.0      6.5          e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425         1       2226.0   2226.0      0.5          e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426         1       2215.0   2215.0      0.5          e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427         1       1180.0   1180.0      0.3          kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                                           
   429         1       2499.0   2499.0      0.6          dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                                           
   431                                                   # Calculate 2B-2B contribution (occB term)
   432         1      31286.0  31286.0      7.4          e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433         1      27389.0  27389.0      6.5          G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434         1       3295.0   3295.0      0.8          sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                                           
   436         1       1063.0   1063.0      0.3          dG_2b2b_B = tf.identity(sub_term)
   437                                           
   438                                                   # Calculate 2B-2B contribution (occA term)
   439         1      13162.0  13162.0      3.1          e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440         1       2225.0   2225.0      0.5          e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441         1      12891.0  12891.0      3.0          e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442         1       2219.0   2219.0      0.5          e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443         1       2195.0   2195.0      0.5          e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444         1       2198.0   2198.0      0.5          e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445         1       1182.0   1182.0      0.3          sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446         1       1184.0   1184.0      0.3          sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447         1       1187.0   1187.0      0.3          add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                                           
   449         1       1047.0   1047.0      0.2          dG_2b2b_A = tf.identity(add3)
   450                                           
   451         1       1358.0   1358.0      0.3          dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                                   
   453         1       7763.0   7763.0      1.8          dE_e = dE.eval()
   454         1       6126.0   6126.0      1.4          df_e = df.eval()
   455         1       8356.0   8356.0      2.0          dG_e = dG.eval()
   456                                               
   457         1         13.0     13.0      0.0      tf.reset_default_graph()
   458                                               
   459         1          1.0      1.0      0.0      return (dE_e, df_e, dG_e)

Total time: 0.84532 s
File: testing_tensorflow_v2_bench.py
Function: derivative at line 466

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   466                                           @profile
   467                                           def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                               
   469         1         57.0     57.0      0.0      E, f, G = ravel(y, holes, particles)
   470                                           
   471         1     420401.0 420401.0     49.7      eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                               
   473         1     424626.0 424626.0     50.2      dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                               
   475         1        235.0    235.0      0.0      dy = unravel(dE, df, dG)
   476                                               
   477         1          1.0      1.0      0.0      return dy

Total time: 0.00044 s
File: testing_tensorflow_v2_bench.py
Function: unravel at line 485

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   485                                           @profile
   486                                           def unravel(E, f, G):
   487         2         45.0     22.5     10.2      unravel_E = np.reshape(E, -1)
   488         2          9.0      4.5      2.0      unravel_f = np.reshape(f, -1)
   489         2          6.0      3.0      1.4      unravel_G = np.reshape(G, -1)
   490                                               
   491         2        380.0    190.0     86.4      return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)

Total time: 8.5e-05 s
File: testing_tensorflow_v2_bench.py
Function: ravel at line 493

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   493                                           @profile
   494                                           def ravel(y, holes, particles):
   495                                               
   496         2         38.0     19.0     44.7      bas_len = len(np.append(holes,particles))
   497                                               
   498         2         19.0      9.5     22.4      ravel_E = np.reshape(y[0], ())
   499         2         15.0      7.5     17.6      ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500         2          5.0      2.5      5.9      ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501         2          7.0      3.5      8.2                           (bas_len, bas_len, bas_len, bas_len))
   502                                               
   503         2          1.0      0.5      1.2      return(ravel_E, ravel_f, ravel_G)

Total time: 1.23332 s
File: testing_tensorflow_v2_bench.py
Function: run at line 522

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   522                                           @profile
   523                                           def run(n_holes):
   524         1       6079.0   6079.0      0.5      H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                                           
   526         1         53.0     53.0      0.0      occA = get_occA(B1, ref)
   527         1         52.0     52.0      0.0      occB = get_occB(B1, ref)
   528         1        249.0    249.0      0.0      occC = get_occC(B1, ref)
   529         1       1025.0   1025.0      0.1      occD = get_occD(B1, ref)
   530                                               
   531         1     380235.0 380235.0     30.8      E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                                           
   533                                               
   534         1        224.0    224.0      0.0      y0 = unravel(E, f, G)
   535                                           
   536         1          1.0      1.0      0.0      t = 1
   537         1     845334.0 845334.0     68.5      dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                                           
   539         1         46.0     46.0      0.0      dE, df, dG = ravel(dy, holes, particles)
   540         1         18.0     18.0      0.0      print(dE)

2019-06-20 14:50:12.836071: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 14:50:12.857726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 14:50:12.858093: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x561280d486a0 executing computations on platform Host. Devices:
2019-06-20 14:50:12.858174: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-0.25
Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    22  260.281 MiB  260.281 MiB   @profile
    23                             def build_hamiltonian(n_hole_states, n_particle_states):
    24  260.281 MiB    0.000 MiB       numh = n_hole_states
    25  260.281 MiB    0.000 MiB       nump = n_particle_states
    26  260.281 MiB    0.000 MiB       nums = numh + nump
    27                                 
    28  260.281 MiB    0.000 MiB       ref = np.append(np.ones(numh), np.zeros(nump))
    29  260.281 MiB    0.000 MiB       holes = np.arange(numh)
    30  260.281 MiB    0.000 MiB       particles = np.arange(numh,numh+nump)
    31  260.281 MiB    0.000 MiB       B1 = np.append(holes,particles)
    32                                 
    33                                 # one body part of Hamiltonian is floor-division of basis index
    34                                 # matrix elements are (P-1) where P is energy level
    35  260.281 MiB    0.000 MiB       H1B = np.diag(np.floor_divide(B1,2))
    36                             
    37  260.281 MiB    0.000 MiB       H2B = np.zeros((nums, nums, nums, nums))
    38  260.281 MiB    0.000 MiB       for p in B1:
    39  260.281 MiB    0.000 MiB           for q in B1:
    40  260.281 MiB    0.000 MiB               for r in B1:
    41  260.281 MiB    0.000 MiB                   for s in B1:
    42                             
    43  260.281 MiB    0.000 MiB                       pp = np.floor_divide(p,2)
    44  260.281 MiB    0.000 MiB                       qp = np.floor_divide(q,2)
    45  260.281 MiB    0.000 MiB                       rp = np.floor_divide(r,2)
    46  260.281 MiB    0.000 MiB                       sp = np.floor_divide(s,2)
    47                             
    48  260.281 MiB    0.000 MiB                       ps = 1 if p%2==0 else -1
    49  260.281 MiB    0.000 MiB                       qs = 1 if q%2==0 else -1
    50  260.281 MiB    0.000 MiB                       rs = 1 if r%2==0 else -1
    51  260.281 MiB    0.000 MiB                       ss = 1 if s%2==0 else -1
    52                             
    53  260.281 MiB    0.000 MiB                       if pp != qp or rp != sp:
    54  260.281 MiB    0.000 MiB                           continue
    55  260.281 MiB    0.000 MiB                       if ps == qs or rs == ss:
    56  260.281 MiB    0.000 MiB                           continue
    57  260.281 MiB    0.000 MiB                       if ps == rs and qs == ss:
    58  260.281 MiB    0.000 MiB                           H2B[p,q,r,s] = -0.25
    59  260.281 MiB    0.000 MiB                       if ps == ss and qs == rs:
    60  260.281 MiB    0.000 MiB                           H2B[p,q,r,s] = 0.25
    61                                                     
    62  260.281 MiB    0.000 MiB       return (H1B, H2B, ref, holes, particles, B1)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    65  260.281 MiB  260.281 MiB   @profile
    66                             def get_occA(B1_basis, ref):
    67  260.281 MiB    0.000 MiB       n = len(B1_basis)
    68  260.281 MiB    0.000 MiB       occA = np.zeros((n,n,n,n))
    69                                 
    70  260.281 MiB    0.000 MiB       for a in B1_basis:
    71  260.281 MiB    0.000 MiB           for b in B1_basis:
    72  260.281 MiB    0.000 MiB               occA[a,b,a,b] = ref[a] - ref[b]
    73                                         
    74  260.281 MiB    0.000 MiB       return occA


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    77  260.281 MiB  260.281 MiB   @profile
    78                             def get_occB(B1_basis, ref):
    79  260.281 MiB    0.000 MiB       n = len(B1_basis)    
    80  260.281 MiB    0.000 MiB       occB = np.zeros((n,n,n,n))
    81                                 
    82  260.281 MiB    0.000 MiB       for a in B1_basis:
    83  260.281 MiB    0.000 MiB           for b in B1_basis:
    84  260.281 MiB    0.000 MiB               occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                         
    86  260.281 MiB    0.000 MiB       return occB


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    89  260.281 MiB  260.281 MiB   @profile
    90                             def get_occC(B1_basis, ref):
    91  260.281 MiB    0.000 MiB       n = len(B1_basis)        
    92  260.281 MiB    0.000 MiB       occC = np.zeros((n,n,n,n,n,n))
    93                                 
    94  260.281 MiB    0.000 MiB       for a in B1_basis:
    95  260.281 MiB    0.000 MiB           for b in B1_basis:
    96  260.281 MiB    0.000 MiB               for c in B1_basis:
    97  260.281 MiB    0.000 MiB                   occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                             
    99  260.281 MiB    0.000 MiB       return occC


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   102  260.281 MiB  260.281 MiB   @profile
   103                             def get_occD(B1_basis, ref):
   104  260.281 MiB    0.000 MiB       n = len(B1_basis)    
   105  260.281 MiB    0.000 MiB       occD = np.zeros((n,n,n,n))
   106                                 
   107  260.281 MiB    0.000 MiB       for a in B1_basis:
   108  260.281 MiB    0.000 MiB           for b in B1_basis:
   109  260.281 MiB    0.000 MiB               for c in B1_basis:
   110  260.281 MiB    0.000 MiB                   for d in B1_basis:
   111  260.281 MiB    0.000 MiB                       occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                 
   113  260.281 MiB    0.000 MiB       return occD


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   126  260.281 MiB  260.281 MiB   @profile
   127                             def normal_order(H1B_t, H2B_t, holes):
   128                                 
   129  262.922 MiB    2.641 MiB       H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130  262.922 MiB    0.000 MiB       H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131  262.922 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                 
   133                                 # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134  265.957 MiB    3.035 MiB       with tf.Session() as sess:
   135                                     
   136                                     # - Calculate 0B tensor
   137                                     # E = tf.Variable(0.0)
   138  267.332 MiB    1.047 MiB           contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139  267.828 MiB    0.258 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                             
   141  267.828 MiB    0.000 MiB           E_1b = tf.reduce_sum(contr_1b, 0)
   142  267.828 MiB    0.000 MiB           E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143  267.828 MiB    0.000 MiB           E = tf.add_n([E_1b, E_2b])
   144                             
   145                                     # - Calculate 1B tensor
   146  268.383 MiB    0.301 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147  268.383 MiB    0.000 MiB           contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                             
   149  268.383 MiB    0.000 MiB           f = tf.add_n([H1B_t, contr_2b])
   150                             
   151                                     # - Calculate 2B tensor
   152  268.383 MiB    0.000 MiB           G = tf.identity(H2B_t)
   153                                     
   154  274.008 MiB    5.625 MiB           E_e, f_e, G_e = sess.run([E, f, G])
   155                             #         E_e = E.eval()
   156                             #         f_e = f.eval()
   157                             #         G_e = G.eval()
   158                                     
   159                             #         print(sess.run([E, f, G]))
   160                                     
   161  274.008 MiB    0.000 MiB       tf.reset_default_graph()
   162                                 
   163  274.008 MiB    0.000 MiB       return (E_e, f_e, G_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   236  274.008 MiB  274.008 MiB   @profile
   237                             def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                 
   239  274.008 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   240  274.008 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   241  274.008 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242  274.008 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243  274.008 MiB    0.000 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244  274.008 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245  274.008 MiB    0.000 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246  274.008 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                 
   248  274.008 MiB    0.000 MiB       with tf.Session() as sess:
   249  274.008 MiB    0.000 MiB           plen = tf.size(particles)
   250  274.008 MiB    0.000 MiB           hlen = tf.size(holes)
   251                             
   252                                     # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                     
   254                                     # Decoupling 1B piece
   255                                     # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256  274.008 MiB    0.000 MiB           particles_b = tf.broadcast_to(particles, [plen,plen])
   257  274.008 MiB    0.000 MiB           holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258  274.008 MiB    0.000 MiB           ph_comb = tf.concat([particles_b, holes_b], 0)
   259  274.008 MiB    0.000 MiB           hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                     
   261  274.895 MiB    0.887 MiB           col_indices =tf.reshape(ph_comb, [-1])
   262  274.895 MiB    0.000 MiB           row_indices = tf.reshape(hp_comb, [-1])
   263  274.895 MiB    0.000 MiB           ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264  274.895 MiB    0.000 MiB           ph_updates = tf.gather_nd(f, ph_indices)
   265                             
   266  274.895 MiB    0.000 MiB           fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267  274.895 MiB    0.000 MiB           fd = tf.subtract(f,fod)
   268                             
   269                                     # Decoupling 2B piece
   270                                     # indices are constructed by all possible combinations of pphh(hhpp) states
   271  275.160 MiB    0.266 MiB           ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272  275.160 MiB    0.000 MiB           ind1_TC = tf.transpose(ind1_C) 
   273  275.160 MiB    0.000 MiB           ind1 = tf.reshape(ind1_TC,[-1])
   274                             
   275  275.160 MiB    0.000 MiB           ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276  275.160 MiB    0.000 MiB           ind2_TC = tf.transpose(ind2_C)
   277  275.160 MiB    0.000 MiB           ind2 = tf.reshape(ind2_TC,[-1])
   278                             
   279  275.160 MiB    0.000 MiB           ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280  275.160 MiB    0.000 MiB           ind3_TC = tf.transpose(ind3_C) 
   281  275.160 MiB    0.000 MiB           ind3 = tf.reshape(ind3_TC,[-1])
   282                             
   283  275.160 MiB    0.000 MiB           ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284  275.160 MiB    0.000 MiB           ind4_TC = tf.transpose(ind4_C)
   285  275.160 MiB    0.000 MiB           ind4 = tf.reshape(ind4_TC,[-1])
   286                             
   287  275.160 MiB    0.000 MiB           pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288  275.160 MiB    0.000 MiB           pphh_updates = tf.gather_nd(G, pphh_indices)
   289                             
   290  275.410 MiB    0.250 MiB           God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291  275.410 MiB    0.000 MiB           Gd = tf.subtract(G,God)
   292                             
   293                             
   294                                     # --- 1B piece
   295                             
   296                                     # Calculate 1B-1B contribution
   297  275.410 MiB    0.000 MiB           fd_fod = tf.tensordot(fd,fod,1)
   298  275.410 MiB    0.000 MiB           fd_fod_T = tf.transpose(fd_fod)
   299  275.410 MiB    0.000 MiB           eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                             
   301                                     # Calculate 1B-2B contribution
   302  275.410 MiB    0.000 MiB           fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303  275.633 MiB    0.223 MiB           fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304  275.633 MiB    0.000 MiB           eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                             
   306                                     # Calculate 2B-2B contribution
   307  275.633 MiB    0.000 MiB           Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308  275.633 MiB    0.000 MiB           Gd_God_T = tf.transpose(Gd_God)
   309  275.633 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310  275.633 MiB    0.000 MiB           eta1B_2b2b = scaled_sub
   311                             
   312  275.633 MiB    0.000 MiB           eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                             
   314                             
   315                             
   316                                     # --- 2B piece
   317                             
   318                                     # Calculate 1B-2B contribution
   319  275.633 MiB    0.000 MiB           fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320  275.633 MiB    0.000 MiB           fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321  275.633 MiB    0.000 MiB           ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                             
   323  275.633 MiB    0.000 MiB           fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324  275.633 MiB    0.000 MiB           fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325  275.633 MiB    0.000 MiB           fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326  275.633 MiB    0.000 MiB           kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                             
   328  275.633 MiB    0.000 MiB           eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                             
   330                             
   331                                     # Calculate 2B-2B contribution
   332  275.633 MiB    0.000 MiB           GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333  275.633 MiB    0.000 MiB           GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334  275.633 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                             
   336  275.633 MiB    0.000 MiB           eta2B_2b2b_B = scaled_sub
   337                             
   338  275.633 MiB    0.000 MiB           GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339  275.633 MiB    0.000 MiB           GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340  275.633 MiB    0.000 MiB           GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341  275.633 MiB    0.000 MiB           GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342  275.633 MiB    0.000 MiB           GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343  275.633 MiB    0.000 MiB           GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344  275.633 MiB    0.000 MiB           sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345  275.633 MiB    0.000 MiB           sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346  275.633 MiB    0.000 MiB           add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                             
   348  275.633 MiB    0.000 MiB           eta2B_2b2b_A = add3
   349                             
   350  275.633 MiB    0.000 MiB           eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                     
   352  275.887 MiB    0.254 MiB           eta1B_e = eta1B.eval()
   353  277.727 MiB    1.840 MiB           eta2B_e = eta2B.eval()
   354                                     
   355  277.727 MiB    0.000 MiB       tf.reset_default_graph()
   356                                 
   357  277.727 MiB    0.000 MiB       return (eta1B_e, eta2B_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   364  277.727 MiB  277.727 MiB   @profile
   365                             def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                 
   367  277.727 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   368  277.727 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   369  277.727 MiB    0.000 MiB       eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370  277.727 MiB    0.000 MiB       eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371  277.727 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372  277.727 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373  277.727 MiB    0.000 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374  277.727 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375  277.727 MiB    0.000 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376  277.727 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                 
   378  277.727 MiB    0.000 MiB       with tf.Session() as sess:
   379                                     
   380                                     # --- 0B piece
   381                             
   382                                     # Calculate 1B-1B contribution (full contraction)
   383  277.727 MiB    0.000 MiB           occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384  277.727 MiB    0.000 MiB           occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385  277.727 MiB    0.000 MiB           dE_1b1b = tf.identity(occA_e1_f)
   386                             
   387                                     # Calculate 2B-2B contribution (full contraction)
   388                                 #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389  277.727 MiB    0.000 MiB           e2_occD = tf.matmul(eta2B, occD_t)
   390  277.727 MiB    0.000 MiB           e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391  277.727 MiB    0.000 MiB           dE_2b2b = tf.identity(e2_occD_G)
   392                             
   393  277.727 MiB    0.000 MiB           dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                             
   395                                     # --- 1B piece
   396                             
   397                                     # Calculate 1B-1B contribution (contraction over 1 index)
   398  277.727 MiB    0.000 MiB           e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399  277.727 MiB    0.000 MiB           e1_f_T = tf.transpose(e1_f)
   400  277.727 MiB    0.000 MiB           e1_f_add = tf.add(e1_f,e1_f_T)
   401  277.727 MiB    0.000 MiB           df_1b1b = tf.identity(e1_f_add)
   402                             
   403                                     # Calculate 1B-2B contribution (contraction over 2 indices)
   404  278.012 MiB    0.285 MiB           occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405  278.012 MiB    0.000 MiB           occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406  278.012 MiB    0.000 MiB           sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407  278.012 MiB    0.000 MiB           df_1b2b = tf.identity(sub_1b2b)
   408                             
   409                                     # Calculate 2B-2B contribution (contraction over 3 indices)
   410  278.012 MiB    0.000 MiB           e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411  278.012 MiB    0.000 MiB           e2_occC_G_T = tf.transpose(e2_occC_G)
   412  278.270 MiB    0.258 MiB           add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413  278.270 MiB    0.000 MiB           df_2b2b = tf.identity(add_2b2b)
   414                             
   415  278.270 MiB    0.000 MiB           df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                             
   417                                     # --- 2B piece
   418                             
   419                                     # Calculate 1B-2B contribution (contraction over 1 index)
   420  278.270 MiB    0.000 MiB           e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421  278.270 MiB    0.000 MiB           e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422  278.270 MiB    0.000 MiB           ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                             
   424  278.508 MiB    0.238 MiB           e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425  278.508 MiB    0.000 MiB           e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426  278.508 MiB    0.000 MiB           e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427  278.508 MiB    0.000 MiB           kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                             
   429  278.508 MiB    0.000 MiB           dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                             
   431                                     # Calculate 2B-2B contribution (occB term)
   432  278.508 MiB    0.000 MiB           e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433  278.758 MiB    0.250 MiB           G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434  278.758 MiB    0.000 MiB           sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                             
   436  278.758 MiB    0.000 MiB           dG_2b2b_B = tf.identity(sub_term)
   437                             
   438                                     # Calculate 2B-2B contribution (occA term)
   439  278.758 MiB    0.000 MiB           e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440  278.758 MiB    0.000 MiB           e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441  278.758 MiB    0.000 MiB           e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442  278.758 MiB    0.000 MiB           e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443  278.758 MiB    0.000 MiB           e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444  278.758 MiB    0.000 MiB           e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445  278.758 MiB    0.000 MiB           sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446  278.758 MiB    0.000 MiB           sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447  278.758 MiB    0.000 MiB           add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                             
   449  278.758 MiB    0.000 MiB           dG_2b2b_A = tf.identity(add3)
   450                             
   451  278.758 MiB    0.000 MiB           dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                     
   453  278.762 MiB    0.004 MiB           dE_e = dE.eval()
   454  278.762 MiB    0.000 MiB           df_e = df.eval()
   455  279.184 MiB    0.422 MiB           dG_e = dG.eval()
   456                                 
   457  279.184 MiB    0.000 MiB       tf.reset_default_graph()
   458                                 
   459  279.184 MiB    0.000 MiB       return (dE_e, df_e, dG_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   466  274.008 MiB  274.008 MiB   @profile
   467                             def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                 
   469  274.008 MiB  274.008 MiB       E, f, G = ravel(y, holes, particles)
   470                             
   471  277.727 MiB  277.727 MiB       eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                 
   473  279.184 MiB  279.184 MiB       dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                 
   475  279.184 MiB  279.184 MiB       dy = unravel(dE, df, dG)
   476                                 
   477  279.184 MiB    0.000 MiB       return dy


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   485  279.184 MiB  279.184 MiB   @profile
   486                             def unravel(E, f, G):
   487  279.184 MiB    0.000 MiB       unravel_E = np.reshape(E, -1)
   488  279.184 MiB    0.000 MiB       unravel_f = np.reshape(f, -1)
   489  279.184 MiB    0.000 MiB       unravel_G = np.reshape(G, -1)
   490                                 
   491  279.184 MiB    0.000 MiB       return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   493  279.184 MiB  279.184 MiB   @profile
   494                             def ravel(y, holes, particles):
   495                                 
   496  279.184 MiB    0.000 MiB       bas_len = len(np.append(holes,particles))
   497                                 
   498  279.184 MiB    0.000 MiB       ravel_E = np.reshape(y[0], ())
   499  279.184 MiB    0.000 MiB       ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500  279.184 MiB    0.000 MiB       ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501  279.184 MiB    0.000 MiB                            (bas_len, bas_len, bas_len, bas_len))
   502                                 
   503  279.184 MiB    0.000 MiB       return(ravel_E, ravel_f, ravel_G)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   522  260.281 MiB  260.281 MiB   @profile
   523                             def run(n_holes):
   524  260.281 MiB  260.281 MiB       H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                             
   526  260.281 MiB  260.281 MiB       occA = get_occA(B1, ref)
   527  260.281 MiB  260.281 MiB       occB = get_occB(B1, ref)
   528  260.281 MiB  260.281 MiB       occC = get_occC(B1, ref)
   529  260.281 MiB  260.281 MiB       occD = get_occD(B1, ref)
   530                                 
   531  274.008 MiB  274.008 MiB       E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                             
   533                                 
   534  274.008 MiB  274.008 MiB       y0 = unravel(E, f, G)
   535                             
   536  274.008 MiB    0.000 MiB       t = 1
   537  279.184 MiB  279.184 MiB       dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                             
   539  279.184 MiB  279.184 MiB       dE, df, dG = ravel(dy, holes, particles)
   540  279.184 MiB    0.000 MiB       print(dE)


---------------------------------------------\n

Executing TF on n_holes=4 ---------------------------
2019-06-20 14:50:23.145053: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 14:50:23.165906: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 14:50:23.166534: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56469ae9bf60 executing computations on platform Host. Devices:
2019-06-20 14:50:23.166591: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-1.75
Wrote profile results to testing_tensorflow_v2_bench.py.lprof
Timer unit: 1e-06 s

Total time: 0.060746 s
File: testing_tensorflow_v2_bench.py
Function: build_hamiltonian at line 22

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    22                                           @profile
    23                                           def build_hamiltonian(n_hole_states, n_particle_states):
    24         1          1.0      1.0      0.0      numh = n_hole_states
    25         1          1.0      1.0      0.0      nump = n_particle_states
    26         1          1.0      1.0      0.0      nums = numh + nump
    27                                               
    28         1         54.0     54.0      0.1      ref = np.append(np.ones(numh), np.zeros(nump))
    29         1          5.0      5.0      0.0      holes = np.arange(numh)
    30         1          2.0      2.0      0.0      particles = np.arange(numh,numh+nump)
    31         1          9.0      9.0      0.0      B1 = np.append(holes,particles)
    32                                               
    33                                               # one body part of Hamiltonian is floor-division of basis index
    34                                               # matrix elements are (P-1) where P is energy level
    35         1         45.0     45.0      0.1      H1B = np.diag(np.floor_divide(B1,2))
    36                                           
    37         1         14.0     14.0      0.0      H2B = np.zeros((nums, nums, nums, nums))
    38         9         10.0      1.1      0.0      for p in B1:
    39        72         54.0      0.8      0.1          for q in B1:
    40       576        447.0      0.8      0.7              for r in B1:
    41      4608       3471.0      0.8      5.7                  for s in B1:
    42                                           
    43      4096       9577.0      2.3     15.8                      pp = np.floor_divide(p,2)
    44      4096       9285.0      2.3     15.3                      qp = np.floor_divide(q,2)
    45      4096       9168.0      2.2     15.1                      rp = np.floor_divide(r,2)
    46      4096       9149.0      2.2     15.1                      sp = np.floor_divide(s,2)
    47                                           
    48      4096       4252.0      1.0      7.0                      ps = 1 if p%2==0 else -1
    49      4096       3903.0      1.0      6.4                      qs = 1 if q%2==0 else -1
    50      4096       3910.0      1.0      6.4                      rs = 1 if r%2==0 else -1
    51      4096       3857.0      0.9      6.3                      ss = 1 if s%2==0 else -1
    52                                           
    53      4096       2687.0      0.7      4.4                      if pp != qp or rp != sp:
    54       768        478.0      0.6      0.8                          continue
    55       256        165.0      0.6      0.3                      if ps == qs or rs == ss:
    56        64         43.0      0.7      0.1                          continue
    57        64         45.0      0.7      0.1                      if ps == rs and qs == ss:
    58        32         39.0      1.2      0.1                          H2B[p,q,r,s] = -0.25
    59        64         38.0      0.6      0.1                      if ps == ss and qs == rs:
    60        32         35.0      1.1      0.1                          H2B[p,q,r,s] = 0.25
    61                                                                   
    62         1          1.0      1.0      0.0      return (H1B, H2B, ref, holes, particles, B1)

Total time: 0.000117 s
File: testing_tensorflow_v2_bench.py
Function: get_occA at line 65

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    65                                           @profile
    66                                           def get_occA(B1_basis, ref):
    67         1          2.0      2.0      1.7      n = len(B1_basis)
    68         1         18.0     18.0     15.4      occA = np.zeros((n,n,n,n))
    69                                               
    70         9          5.0      0.6      4.3      for a in B1_basis:
    71        72         33.0      0.5     28.2          for b in B1_basis:
    72        64         59.0      0.9     50.4              occA[a,b,a,b] = ref[a] - ref[b]
    73                                                       
    74         1          0.0      0.0      0.0      return occA

Total time: 0.000117 s
File: testing_tensorflow_v2_bench.py
Function: get_occB at line 77

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    77                                           @profile
    78                                           def get_occB(B1_basis, ref):
    79         1          1.0      1.0      0.9      n = len(B1_basis)    
    80         1         14.0     14.0     12.0      occB = np.zeros((n,n,n,n))
    81                                               
    82         9          3.0      0.3      2.6      for a in B1_basis:
    83        72         27.0      0.4     23.1          for b in B1_basis:
    84        64         71.0      1.1     60.7              occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                                       
    86         1          1.0      1.0      0.9      return occB

Total time: 0.001968 s
File: testing_tensorflow_v2_bench.py
Function: get_occC at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                           @profile
    90                                           def get_occC(B1_basis, ref):
    91         1          1.0      1.0      0.1      n = len(B1_basis)        
    92         1         31.0     31.0      1.6      occC = np.zeros((n,n,n,n,n,n))
    93                                               
    94         9          7.0      0.8      0.4      for a in B1_basis:
    95        72         34.0      0.5      1.7          for b in B1_basis:
    96       576        298.0      0.5     15.1              for c in B1_basis:
    97       512       1597.0      3.1     81.1                  occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                                           
    99         1          0.0      0.0      0.0      return occC

Total time: 0.011775 s
File: testing_tensorflow_v2_bench.py
Function: get_occD at line 102

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   102                                           @profile
   103                                           def get_occD(B1_basis, ref):
   104         1          1.0      1.0      0.0      n = len(B1_basis)    
   105         1         13.0     13.0      0.1      occD = np.zeros((n,n,n,n))
   106                                               
   107         9          2.0      0.2      0.0      for a in B1_basis:
   108        72         33.0      0.5      0.3          for b in B1_basis:
   109       576        280.0      0.5      2.4              for c in B1_basis:
   110      4608       2186.0      0.5     18.6                  for d in B1_basis:
   111      4096       9260.0      2.3     78.6                      occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                               
   113         1          0.0      0.0      0.0      return occD

Total time: 0.387506 s
File: testing_tensorflow_v2_bench.py
Function: normal_order at line 126

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   126                                           @profile
   127                                           def normal_order(H1B_t, H2B_t, holes):
   128                                               
   129         1      11426.0  11426.0      2.9      H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130         1        907.0    907.0      0.2      H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131         1        796.0    796.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                               
   133                                               # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134         1      22307.0  22307.0      5.8      with tf.Session() as sess:
   135                                                   
   136                                                   # - Calculate 0B tensor
   137                                                   # E = tf.Variable(0.0)
   138         1     110599.0 110599.0     28.5          contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139         1      91289.0  91289.0     23.6          contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                                           
   141         1       2556.0   2556.0      0.7          E_1b = tf.reduce_sum(contr_1b, 0)
   142         1       4661.0   4661.0      1.2          E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143         1       1308.0   1308.0      0.3          E = tf.add_n([E_1b, E_2b])
   144                                           
   145                                                   # - Calculate 1B tensor
   146         1      92603.0  92603.0     23.9          contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147         1       2941.0   2941.0      0.8          contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                                           
   149         1       1303.0   1303.0      0.3          f = tf.add_n([H1B_t, contr_2b])
   150                                           
   151                                                   # - Calculate 2B tensor
   152         1       1028.0   1028.0      0.3          G = tf.identity(H2B_t)
   153                                                   
   154         1      43765.0  43765.0     11.3          E_e, f_e, G_e = sess.run([E, f, G])
   155                                           #         E_e = E.eval()
   156                                           #         f_e = f.eval()
   157                                           #         G_e = G.eval()
   158                                                   
   159                                           #         print(sess.run([E, f, G]))
   160                                                   
   161         1         16.0     16.0      0.0      tf.reset_default_graph()
   162                                               
   163         1          1.0      1.0      0.0      return (E_e, f_e, G_e)

Total time: 0.471093 s
File: testing_tensorflow_v2_bench.py
Function: wegner at line 236

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                           @profile
   237                                           def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                               
   239         1       1219.0   1219.0      0.3      f = tf.convert_to_tensor(f, dtype=tf.float32)
   240         1        893.0    893.0      0.2      G = tf.convert_to_tensor(G, dtype=tf.float32)
   241         1        794.0    794.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242         1        778.0    778.0      0.2      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243         1        834.0    834.0      0.2      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244         1        830.0    830.0      0.2      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245         1       4059.0   4059.0      0.9      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246         1       1137.0   1137.0      0.2      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                               
   248         1        199.0    199.0      0.0      with tf.Session() as sess:
   249         1       1147.0   1147.0      0.2          plen = tf.size(particles)
   250         1        944.0    944.0      0.2          hlen = tf.size(holes)
   251                                           
   252                                                   # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                                   
   254                                                   # Decoupling 1B piece
   255                                                   # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256         1       3015.0   3015.0      0.6          particles_b = tf.broadcast_to(particles, [plen,plen])
   257         1       3052.0   3052.0      0.6          holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258         1       2410.0   2410.0      0.5          ph_comb = tf.concat([particles_b, holes_b], 0)
   259         1       4732.0   4732.0      1.0          hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                                   
   261         1       2198.0   2198.0      0.5          col_indices =tf.reshape(ph_comb, [-1])
   262         1       2149.0   2149.0      0.5          row_indices = tf.reshape(hp_comb, [-1])
   263         1       1436.0   1436.0      0.3          ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264         1       1374.0   1374.0      0.3          ph_updates = tf.gather_nd(f, ph_indices)
   265                                           
   266         1       2379.0   2379.0      0.5          fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267         1       1187.0   1187.0      0.3          fd = tf.subtract(f,fod)
   268                                           
   269                                                   # Decoupling 2B piece
   270                                                   # indices are constructed by all possible combinations of pphh(hhpp) states
   271         1      13082.0  13082.0      2.8          ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272         1       2360.0   2360.0      0.5          ind1_TC = tf.transpose(ind1_C) 
   273         1       2170.0   2170.0      0.5          ind1 = tf.reshape(ind1_TC,[-1])
   274                                           
   275         1      17655.0  17655.0      3.7          ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276         1       2329.0   2329.0      0.5          ind2_TC = tf.transpose(ind2_C)
   277         1       2142.0   2142.0      0.5          ind2 = tf.reshape(ind2_TC,[-1])
   278                                           
   279         1      13178.0  13178.0      2.8          ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280         1       2424.0   2424.0      0.5          ind3_TC = tf.transpose(ind3_C) 
   281         1       2181.0   2181.0      0.5          ind3 = tf.reshape(ind3_TC,[-1])
   282                                           
   283         1      22652.0  22652.0      4.8          ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284         1       2589.0   2589.0      0.5          ind4_TC = tf.transpose(ind4_C)
   285         1       2323.0   2323.0      0.5          ind4 = tf.reshape(ind4_TC,[-1])
   286                                           
   287         1       1656.0   1656.0      0.4          pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288         1       1407.0   1407.0      0.3          pphh_updates = tf.gather_nd(G, pphh_indices)
   289                                           
   290         1       2426.0   2426.0      0.5          God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291         1       1241.0   1241.0      0.3          Gd = tf.subtract(G,God)
   292                                           
   293                                           
   294                                                   # --- 1B piece
   295                                           
   296                                                   # Calculate 1B-1B contribution
   297         1      13271.0  13271.0      2.8          fd_fod = tf.tensordot(fd,fod,1)
   298         1       2377.0   2377.0      0.5          fd_fod_T = tf.transpose(fd_fod)
   299         1       1212.0   1212.0      0.3          eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                                           
   301                                                   # Calculate 1B-2B contribution
   302         1      25970.0  25970.0      5.5          fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303         1      25880.0  25880.0      5.5          fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304         1       1215.0   1215.0      0.3          eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                                           
   306                                                   # Calculate 2B-2B contribution
   307         1      26283.0  26283.0      5.6          Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308         1       2394.0   2394.0      0.5          Gd_God_T = tf.transpose(Gd_God)
   309         1       3288.0   3288.0      0.7          scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310         1          2.0      2.0      0.0          eta1B_2b2b = scaled_sub
   311                                           
   312         1       1354.0   1354.0      0.3          eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                                           
   314                                           
   315                                           
   316                                                   # --- 2B piece
   317                                           
   318                                                   # Calculate 1B-2B contribution
   319         1      28494.0  28494.0      6.0          fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320         1       2673.0   2673.0      0.6          fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321         1       1224.0   1224.0      0.3          ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                                           
   323         1      54147.0  54147.0     11.5          fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324         1       8101.0   8101.0      1.7          fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325         1       2599.0   2599.0      0.6          fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326         1       1282.0   1282.0      0.3          kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                                           
   328         1       1918.0   1918.0      0.4          eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                                           
   330                                           
   331                                                   # Calculate 2B-2B contribution
   332         1      31389.0  31389.0      6.7          GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333         1      26950.0  26950.0      5.7          GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334         1       3324.0   3324.0      0.7          scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                                           
   336         1          2.0      2.0      0.0          eta2B_2b2b_B = scaled_sub
   337                                           
   338         1      13145.0  13145.0      2.8          GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339         1       2228.0   2228.0      0.5          GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340         1      13016.0  13016.0      2.8          GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341         1       2221.0   2221.0      0.5          GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342         1       2208.0   2208.0      0.5          GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343         1       2217.0   2217.0      0.5          GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344         1       1209.0   1209.0      0.3          sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345         1       1191.0   1191.0      0.3          sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346         1       1175.0   1175.0      0.2          add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                                           
   348         1          2.0      2.0      0.0          eta2B_2b2b_A = add3
   349                                           
   350         1       1374.0   1374.0      0.3          eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                                   
   352         1      23285.0  23285.0      4.9          eta1B_e = eta1B.eval()
   353         1      13877.0  13877.0      2.9          eta2B_e = eta2B.eval()
   354                                                   
   355         1         14.0     14.0      0.0      tf.reset_default_graph()
   356                                               
   357         1          1.0      1.0      0.0      return (eta1B_e, eta2B_e)

Total time: 0.450304 s
File: testing_tensorflow_v2_bench.py
Function: flow at line 364

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   364                                           @profile
   365                                           def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                               
   367         1       1276.0   1276.0      0.3      f = tf.convert_to_tensor(f, dtype=tf.float32)
   368         1        861.0    861.0      0.2      G = tf.convert_to_tensor(G, dtype=tf.float32)
   369         1        823.0    823.0      0.2      eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370         1        825.0    825.0      0.2      eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371         1        822.0    822.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372         1        860.0    860.0      0.2      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373         1        901.0    901.0      0.2      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374         1        837.0    837.0      0.2      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375         1       2340.0   2340.0      0.5      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376         1       1071.0   1071.0      0.2      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                               
   378         1        205.0    205.0      0.0      with tf.Session() as sess:
   379                                                   
   380                                                   # --- 0B piece
   381                                           
   382                                                   # Calculate 1B-1B contribution (full contraction)
   383         1      20986.0  20986.0      4.7          occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384         1      13881.0  13881.0      3.1          occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385         1       1141.0   1141.0      0.3          dE_1b1b = tf.identity(occA_e1_f)
   386                                           
   387                                                   # Calculate 2B-2B contribution (full contraction)
   388                                               #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389         1       1657.0   1657.0      0.4          e2_occD = tf.matmul(eta2B, occD_t)
   390         1      15321.0  15321.0      3.4          e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391         1       1049.0   1049.0      0.2          dE_2b2b = tf.identity(e2_occD_G)
   392                                           
   393         1       1323.0   1323.0      0.3          dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                                           
   395                                                   # --- 1B piece
   396                                           
   397                                                   # Calculate 1B-1B contribution (contraction over 1 index)
   398         1      12813.0  12813.0      2.8          e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399         1       2315.0   2315.0      0.5          e1_f_T = tf.transpose(e1_f)
   400         1       1161.0   1161.0      0.3          e1_f_add = tf.add(e1_f,e1_f_T)
   401         1       1054.0   1054.0      0.2          df_1b1b = tf.identity(e1_f_add)
   402                                           
   403                                                   # Calculate 1B-2B contribution (contraction over 2 indices)
   404         1      25748.0  25748.0      5.7          occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405         1      25768.0  25768.0      5.7          occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406         1       1183.0   1183.0      0.3          sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407         1       1084.0   1084.0      0.2          df_1b2b = tf.identity(sub_1b2b)
   408                                           
   409                                                   # Calculate 2B-2B contribution (contraction over 3 indices)
   410         1      26438.0  26438.0      5.9          e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411         1       2298.0   2298.0      0.5          e2_occC_G_T = tf.transpose(e2_occC_G)
   412         1       3285.0   3285.0      0.7          add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413         1       1062.0   1062.0      0.2          df_2b2b = tf.identity(add_2b2b)
   414                                           
   415         1       1374.0   1374.0      0.3          df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                                           
   417                                                   # --- 2B piece
   418                                           
   419                                                   # Calculate 1B-2B contribution (contraction over 1 index)
   420         1      99910.0  99910.0     22.2          e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421         1       2436.0   2436.0      0.5          e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422         1       1347.0   1347.0      0.3          ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                                           
   424         1      29719.0  29719.0      6.6          e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425         1       2314.0   2314.0      0.5          e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426         1       2270.0   2270.0      0.5          e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427         1       1193.0   1193.0      0.3          kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                                           
   429         1       2233.0   2233.0      0.5          dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                                           
   431                                                   # Calculate 2B-2B contribution (occB term)
   432         1      25748.0  25748.0      5.7          e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433         1      27584.0  27584.0      6.1          G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434         1       3352.0   3352.0      0.7          sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                                           
   436         1       1497.0   1497.0      0.3          dG_2b2b_B = tf.identity(sub_term)
   437                                           
   438                                                   # Calculate 2B-2B contribution (occA term)
   439         1      13608.0  13608.0      3.0          e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440         1       2572.0   2572.0      0.6          e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441         1      13978.0  13978.0      3.1          e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442         1       2231.0   2231.0      0.5          e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443         1       2207.0   2207.0      0.5          e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444         1       2699.0   2699.0      0.6          e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445         1       1210.0   1210.0      0.3          sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446         1       1195.0   1195.0      0.3          sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447         1       1184.0   1184.0      0.3          add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                                           
   449         1       1051.0   1051.0      0.2          dG_2b2b_A = tf.identity(add3)
   450                                           
   451         1       1834.0   1834.0      0.4          dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                                   
   453         1       9766.0   9766.0      2.2          dE_e = dE.eval()
   454         1      13914.0  13914.0      3.1          df_e = df.eval()
   455         1      11468.0  11468.0      2.5          dG_e = dG.eval()
   456                                               
   457         1         21.0     21.0      0.0      tf.reset_default_graph()
   458                                               
   459         1          1.0      1.0      0.0      return (dE_e, df_e, dG_e)

Total time: 0.922143 s
File: testing_tensorflow_v2_bench.py
Function: derivative at line 466

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   466                                           @profile
   467                                           def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                               
   469         1         49.0     49.0      0.0      E, f, G = ravel(y, holes, particles)
   470                                           
   471         1     471382.0 471382.0     51.1      eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                               
   473         1     450532.0 450532.0     48.9      dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                               
   475         1        179.0    179.0      0.0      dy = unravel(dE, df, dG)
   476                                               
   477         1          1.0      1.0      0.0      return dy

Total time: 0.000427 s
File: testing_tensorflow_v2_bench.py
Function: unravel at line 485

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   485                                           @profile
   486                                           def unravel(E, f, G):
   487         2         74.0     37.0     17.3      unravel_E = np.reshape(E, -1)
   488         2         17.0      8.5      4.0      unravel_f = np.reshape(f, -1)
   489         2          6.0      3.0      1.4      unravel_G = np.reshape(G, -1)
   490                                               
   491         2        330.0    165.0     77.3      return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)

Total time: 0.000105 s
File: testing_tensorflow_v2_bench.py
Function: ravel at line 493

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   493                                           @profile
   494                                           def ravel(y, holes, particles):
   495                                               
   496         2         48.0     24.0     45.7      bas_len = len(np.append(holes,particles))
   497                                               
   498         2         30.0     15.0     28.6      ravel_E = np.reshape(y[0], ())
   499         2         11.0      5.5     10.5      ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500         2         10.0      5.0      9.5      ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501         2          5.0      2.5      4.8                           (bas_len, bas_len, bas_len, bas_len))
   502                                               
   503         2          1.0      0.5      1.0      return(ravel_E, ravel_f, ravel_G)

Total time: 1.41767 s
File: testing_tensorflow_v2_bench.py
Function: run at line 522

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   522                                           @profile
   523                                           def run(n_holes):
   524         1      90090.0  90090.0      6.4      H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                                           
   526         1        167.0    167.0      0.0      occA = get_occA(B1, ref)
   527         1        169.0    169.0      0.0      occB = get_occB(B1, ref)
   528         1       2323.0   2323.0      0.2      occC = get_occC(B1, ref)
   529         1      14809.0  14809.0      1.0      occD = get_occD(B1, ref)
   530                                               
   531         1     387581.0 387581.0     27.3      E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                                           
   533                                               
   534         1        267.0    267.0      0.0      y0 = unravel(E, f, G)
   535                                           
   536         1          1.0      1.0      0.0      t = 1
   537         1     922163.0 922163.0     65.0      dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                                           
   539         1         75.0     75.0      0.0      dE, df, dG = ravel(dy, holes, particles)
   540         1         23.0     23.0      0.0      print(dE)

2019-06-20 14:50:32.050898: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 14:50:32.073764: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 14:50:32.074074: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x564a0118b3e0 executing computations on platform Host. Devices:
2019-06-20 14:50:32.074112: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-1.75
Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    22  260.168 MiB  260.168 MiB   @profile
    23                             def build_hamiltonian(n_hole_states, n_particle_states):
    24  260.168 MiB    0.000 MiB       numh = n_hole_states
    25  260.168 MiB    0.000 MiB       nump = n_particle_states
    26  260.168 MiB    0.000 MiB       nums = numh + nump
    27                                 
    28  260.168 MiB    0.000 MiB       ref = np.append(np.ones(numh), np.zeros(nump))
    29  260.168 MiB    0.000 MiB       holes = np.arange(numh)
    30  260.168 MiB    0.000 MiB       particles = np.arange(numh,numh+nump)
    31  260.168 MiB    0.000 MiB       B1 = np.append(holes,particles)
    32                                 
    33                                 # one body part of Hamiltonian is floor-division of basis index
    34                                 # matrix elements are (P-1) where P is energy level
    35  260.168 MiB    0.000 MiB       H1B = np.diag(np.floor_divide(B1,2))
    36                             
    37  260.168 MiB    0.000 MiB       H2B = np.zeros((nums, nums, nums, nums))
    38  260.168 MiB    0.000 MiB       for p in B1:
    39  260.168 MiB    0.000 MiB           for q in B1:
    40  260.168 MiB    0.000 MiB               for r in B1:
    41  260.168 MiB    0.000 MiB                   for s in B1:
    42                             
    43  260.168 MiB    0.000 MiB                       pp = np.floor_divide(p,2)
    44  260.168 MiB    0.000 MiB                       qp = np.floor_divide(q,2)
    45  260.168 MiB    0.000 MiB                       rp = np.floor_divide(r,2)
    46  260.168 MiB    0.000 MiB                       sp = np.floor_divide(s,2)
    47                             
    48  260.168 MiB    0.000 MiB                       ps = 1 if p%2==0 else -1
    49  260.168 MiB    0.000 MiB                       qs = 1 if q%2==0 else -1
    50  260.168 MiB    0.000 MiB                       rs = 1 if r%2==0 else -1
    51  260.168 MiB    0.000 MiB                       ss = 1 if s%2==0 else -1
    52                             
    53  260.168 MiB    0.000 MiB                       if pp != qp or rp != sp:
    54  260.168 MiB    0.000 MiB                           continue
    55  260.168 MiB    0.000 MiB                       if ps == qs or rs == ss:
    56  260.168 MiB    0.000 MiB                           continue
    57  260.168 MiB    0.000 MiB                       if ps == rs and qs == ss:
    58  260.168 MiB    0.000 MiB                           H2B[p,q,r,s] = -0.25
    59  260.168 MiB    0.000 MiB                       if ps == ss and qs == rs:
    60  260.168 MiB    0.000 MiB                           H2B[p,q,r,s] = 0.25
    61                                                     
    62  260.168 MiB    0.000 MiB       return (H1B, H2B, ref, holes, particles, B1)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    65  260.168 MiB  260.168 MiB   @profile
    66                             def get_occA(B1_basis, ref):
    67  260.168 MiB    0.000 MiB       n = len(B1_basis)
    68  260.168 MiB    0.000 MiB       occA = np.zeros((n,n,n,n))
    69                                 
    70  260.168 MiB    0.000 MiB       for a in B1_basis:
    71  260.168 MiB    0.000 MiB           for b in B1_basis:
    72  260.168 MiB    0.000 MiB               occA[a,b,a,b] = ref[a] - ref[b]
    73                                         
    74  260.168 MiB    0.000 MiB       return occA


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    77  260.168 MiB  260.168 MiB   @profile
    78                             def get_occB(B1_basis, ref):
    79  260.168 MiB    0.000 MiB       n = len(B1_basis)    
    80  260.168 MiB    0.000 MiB       occB = np.zeros((n,n,n,n))
    81                                 
    82  260.168 MiB    0.000 MiB       for a in B1_basis:
    83  260.168 MiB    0.000 MiB           for b in B1_basis:
    84  260.168 MiB    0.000 MiB               occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                         
    86  260.168 MiB    0.000 MiB       return occB


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    89  260.168 MiB  260.168 MiB   @profile
    90                             def get_occC(B1_basis, ref):
    91  260.168 MiB    0.000 MiB       n = len(B1_basis)        
    92  260.168 MiB    0.000 MiB       occC = np.zeros((n,n,n,n,n,n))
    93                                 
    94  262.207 MiB    0.000 MiB       for a in B1_basis:
    95  262.207 MiB    0.000 MiB           for b in B1_basis:
    96  262.207 MiB    0.000 MiB               for c in B1_basis:
    97  262.207 MiB    0.258 MiB                   occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                             
    99  262.207 MiB    0.000 MiB       return occC


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   102  262.207 MiB  262.207 MiB   @profile
   103                             def get_occD(B1_basis, ref):
   104  262.207 MiB    0.000 MiB       n = len(B1_basis)    
   105  262.207 MiB    0.000 MiB       occD = np.zeros((n,n,n,n))
   106                                 
   107  262.207 MiB    0.000 MiB       for a in B1_basis:
   108  262.207 MiB    0.000 MiB           for b in B1_basis:
   109  262.207 MiB    0.000 MiB               for c in B1_basis:
   110  262.207 MiB    0.000 MiB                   for d in B1_basis:
   111  262.207 MiB    0.000 MiB                       occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                 
   113  262.207 MiB    0.000 MiB       return occD


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   126  262.207 MiB  262.207 MiB   @profile
   127                             def normal_order(H1B_t, H2B_t, holes):
   128                                 
   129  264.910 MiB    2.703 MiB       H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130  264.910 MiB    0.000 MiB       H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131  264.910 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                 
   133                                 # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134  267.961 MiB    3.051 MiB       with tf.Session() as sess:
   135                                     
   136                                     # - Calculate 0B tensor
   137                                     # E = tf.Variable(0.0)
   138  269.332 MiB    1.047 MiB           contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139  269.828 MiB    0.258 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                             
   141  269.828 MiB    0.000 MiB           E_1b = tf.reduce_sum(contr_1b, 0)
   142  269.828 MiB    0.000 MiB           E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143  269.996 MiB    0.168 MiB           E = tf.add_n([E_1b, E_2b])
   144                             
   145                                     # - Calculate 1B tensor
   146  270.512 MiB    0.258 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147  270.512 MiB    0.000 MiB           contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                             
   149  270.512 MiB    0.000 MiB           f = tf.add_n([H1B_t, contr_2b])
   150                             
   151                                     # - Calculate 2B tensor
   152  270.512 MiB    0.000 MiB           G = tf.identity(H2B_t)
   153                                     
   154  275.992 MiB    5.480 MiB           E_e, f_e, G_e = sess.run([E, f, G])
   155                             #         E_e = E.eval()
   156                             #         f_e = f.eval()
   157                             #         G_e = G.eval()
   158                                     
   159                             #         print(sess.run([E, f, G]))
   160                                     
   161  275.992 MiB    0.000 MiB       tf.reset_default_graph()
   162                                 
   163  275.992 MiB    0.000 MiB       return (E_e, f_e, G_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   236  275.992 MiB  275.992 MiB   @profile
   237                             def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                 
   239  275.992 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   240  275.992 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   241  275.992 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242  275.992 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243  277.359 MiB    1.367 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244  277.359 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245  282.254 MiB    4.895 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246  282.254 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                 
   248  282.254 MiB    0.000 MiB       with tf.Session() as sess:
   249  282.254 MiB    0.000 MiB           plen = tf.size(particles)
   250  282.254 MiB    0.000 MiB           hlen = tf.size(holes)
   251                             
   252                                     # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                     
   254                                     # Decoupling 1B piece
   255                                     # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256  282.254 MiB    0.000 MiB           particles_b = tf.broadcast_to(particles, [plen,plen])
   257  282.254 MiB    0.000 MiB           holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258  282.254 MiB    0.000 MiB           ph_comb = tf.concat([particles_b, holes_b], 0)
   259  282.254 MiB    0.000 MiB           hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                     
   261  282.254 MiB    0.000 MiB           col_indices =tf.reshape(ph_comb, [-1])
   262  282.254 MiB    0.000 MiB           row_indices = tf.reshape(hp_comb, [-1])
   263  282.254 MiB    0.000 MiB           ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264  282.414 MiB    0.160 MiB           ph_updates = tf.gather_nd(f, ph_indices)
   265                             
   266  282.414 MiB    0.000 MiB           fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267  282.414 MiB    0.000 MiB           fd = tf.subtract(f,fod)
   268                             
   269                                     # Decoupling 2B piece
   270                                     # indices are constructed by all possible combinations of pphh(hhpp) states
   271  282.664 MiB    0.250 MiB           ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272  282.664 MiB    0.000 MiB           ind1_TC = tf.transpose(ind1_C) 
   273  282.664 MiB    0.000 MiB           ind1 = tf.reshape(ind1_TC,[-1])
   274                             
   275  282.664 MiB    0.000 MiB           ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276  282.664 MiB    0.000 MiB           ind2_TC = tf.transpose(ind2_C)
   277  282.664 MiB    0.000 MiB           ind2 = tf.reshape(ind2_TC,[-1])
   278                             
   279  282.664 MiB    0.000 MiB           ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280  282.664 MiB    0.000 MiB           ind3_TC = tf.transpose(ind3_C) 
   281  282.664 MiB    0.000 MiB           ind3 = tf.reshape(ind3_TC,[-1])
   282                             
   283  282.664 MiB    0.000 MiB           ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284  282.664 MiB    0.000 MiB           ind4_TC = tf.transpose(ind4_C)
   285  282.664 MiB    0.000 MiB           ind4 = tf.reshape(ind4_TC,[-1])
   286                             
   287  282.664 MiB    0.000 MiB           pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288  282.914 MiB    0.250 MiB           pphh_updates = tf.gather_nd(G, pphh_indices)
   289                             
   290  282.914 MiB    0.000 MiB           God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291  282.914 MiB    0.000 MiB           Gd = tf.subtract(G,God)
   292                             
   293                             
   294                                     # --- 1B piece
   295                             
   296                                     # Calculate 1B-1B contribution
   297  282.914 MiB    0.000 MiB           fd_fod = tf.tensordot(fd,fod,1)
   298  282.914 MiB    0.000 MiB           fd_fod_T = tf.transpose(fd_fod)
   299  282.914 MiB    0.000 MiB           eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                             
   301                                     # Calculate 1B-2B contribution
   302  282.914 MiB    0.000 MiB           fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303  283.137 MiB    0.223 MiB           fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304  283.137 MiB    0.000 MiB           eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                             
   306                                     # Calculate 2B-2B contribution
   307  283.137 MiB    0.000 MiB           Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308  283.137 MiB    0.000 MiB           Gd_God_T = tf.transpose(Gd_God)
   309  283.137 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310  283.137 MiB    0.000 MiB           eta1B_2b2b = scaled_sub
   311                             
   312  283.137 MiB    0.000 MiB           eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                             
   314                             
   315                             
   316                                     # --- 2B piece
   317                             
   318                                     # Calculate 1B-2B contribution
   319  283.137 MiB    0.000 MiB           fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320  283.137 MiB    0.000 MiB           fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321  283.137 MiB    0.000 MiB           ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                             
   323  283.137 MiB    0.000 MiB           fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324  283.137 MiB    0.000 MiB           fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325  283.137 MiB    0.000 MiB           fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326  283.137 MiB    0.000 MiB           kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                             
   328  283.137 MiB    0.000 MiB           eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                             
   330                             
   331                                     # Calculate 2B-2B contribution
   332  283.137 MiB    0.000 MiB           GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333  283.137 MiB    0.000 MiB           GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334  283.137 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                             
   336  283.137 MiB    0.000 MiB           eta2B_2b2b_B = scaled_sub
   337                             
   338  283.137 MiB    0.000 MiB           GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339  283.137 MiB    0.000 MiB           GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340  283.137 MiB    0.000 MiB           GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341  283.137 MiB    0.000 MiB           GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342  283.137 MiB    0.000 MiB           GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343  283.137 MiB    0.000 MiB           GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344  283.137 MiB    0.000 MiB           sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345  283.137 MiB    0.000 MiB           sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346  283.137 MiB    0.000 MiB           add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                             
   348  283.137 MiB    0.000 MiB           eta2B_2b2b_A = add3
   349                             
   350  283.137 MiB    0.000 MiB           eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                     
   352  287.523 MiB    4.387 MiB           eta1B_e = eta1B.eval()
   353  287.523 MiB    0.000 MiB           eta2B_e = eta2B.eval()
   354                                     
   355  287.523 MiB    0.000 MiB       tf.reset_default_graph()
   356                                 
   357  287.523 MiB    0.000 MiB       return (eta1B_e, eta2B_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   364  287.523 MiB  287.523 MiB   @profile
   365                             def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                 
   367  287.523 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   368  287.523 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   369  287.523 MiB    0.000 MiB       eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370  287.523 MiB    0.000 MiB       eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371  287.523 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372  287.523 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373  287.523 MiB    0.000 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374  287.523 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375  287.523 MiB    0.000 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376  287.523 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                 
   378  287.523 MiB    0.000 MiB       with tf.Session() as sess:
   379                                     
   380                                     # --- 0B piece
   381                             
   382                                     # Calculate 1B-1B contribution (full contraction)
   383  287.523 MiB    0.000 MiB           occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384  287.523 MiB    0.000 MiB           occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385  287.523 MiB    0.000 MiB           dE_1b1b = tf.identity(occA_e1_f)
   386                             
   387                                     # Calculate 2B-2B contribution (full contraction)
   388                                 #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389  287.523 MiB    0.000 MiB           e2_occD = tf.matmul(eta2B, occD_t)
   390  287.523 MiB    0.000 MiB           e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391  287.523 MiB    0.000 MiB           dE_2b2b = tf.identity(e2_occD_G)
   392                             
   393  287.523 MiB    0.000 MiB           dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                             
   395                                     # --- 1B piece
   396                             
   397                                     # Calculate 1B-1B contribution (contraction over 1 index)
   398  287.523 MiB    0.000 MiB           e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399  287.523 MiB    0.000 MiB           e1_f_T = tf.transpose(e1_f)
   400  287.523 MiB    0.000 MiB           e1_f_add = tf.add(e1_f,e1_f_T)
   401  287.523 MiB    0.000 MiB           df_1b1b = tf.identity(e1_f_add)
   402                             
   403                                     # Calculate 1B-2B contribution (contraction over 2 indices)
   404  287.523 MiB    0.000 MiB           occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405  287.523 MiB    0.000 MiB           occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406  287.523 MiB    0.000 MiB           sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407  287.523 MiB    0.000 MiB           df_1b2b = tf.identity(sub_1b2b)
   408                             
   409                                     # Calculate 2B-2B contribution (contraction over 3 indices)
   410  287.523 MiB    0.000 MiB           e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411  287.816 MiB    0.293 MiB           e2_occC_G_T = tf.transpose(e2_occC_G)
   412  287.816 MiB    0.000 MiB           add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413  287.816 MiB    0.000 MiB           df_2b2b = tf.identity(add_2b2b)
   414                             
   415  287.816 MiB    0.000 MiB           df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                             
   417                                     # --- 2B piece
   418                             
   419                                     # Calculate 1B-2B contribution (contraction over 1 index)
   420  287.816 MiB    0.000 MiB           e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421  287.816 MiB    0.000 MiB           e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422  287.816 MiB    0.000 MiB           ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                             
   424  288.066 MiB    0.250 MiB           e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425  288.066 MiB    0.000 MiB           e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426  288.066 MiB    0.000 MiB           e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427  288.066 MiB    0.000 MiB           kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                             
   429  288.066 MiB    0.000 MiB           dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                             
   431                                     # Calculate 2B-2B contribution (occB term)
   432  288.066 MiB    0.000 MiB           e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433  288.316 MiB    0.250 MiB           G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434  288.316 MiB    0.000 MiB           sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                             
   436  288.316 MiB    0.000 MiB           dG_2b2b_B = tf.identity(sub_term)
   437                             
   438                                     # Calculate 2B-2B contribution (occA term)
   439  288.316 MiB    0.000 MiB           e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440  288.316 MiB    0.000 MiB           e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441  288.316 MiB    0.000 MiB           e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442  288.316 MiB    0.000 MiB           e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443  288.316 MiB    0.000 MiB           e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444  288.316 MiB    0.000 MiB           e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445  288.316 MiB    0.000 MiB           sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446  288.316 MiB    0.000 MiB           sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447  288.316 MiB    0.000 MiB           add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                             
   449  288.316 MiB    0.000 MiB           dG_2b2b_A = tf.identity(add3)
   450                             
   451  288.316 MiB    0.000 MiB           dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                     
   453  288.320 MiB    0.004 MiB           dE_e = dE.eval()
   454  291.020 MiB    2.699 MiB           df_e = df.eval()
   455  291.020 MiB    0.000 MiB           dG_e = dG.eval()
   456                                 
   457  291.020 MiB    0.000 MiB       tf.reset_default_graph()
   458                                 
   459  291.020 MiB    0.000 MiB       return (dE_e, df_e, dG_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   466  275.992 MiB  275.992 MiB   @profile
   467                             def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                 
   469  275.992 MiB  275.992 MiB       E, f, G = ravel(y, holes, particles)
   470                             
   471  287.523 MiB  287.523 MiB       eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                 
   473  291.020 MiB  291.020 MiB       dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                 
   475  291.020 MiB  291.020 MiB       dy = unravel(dE, df, dG)
   476                                 
   477  291.020 MiB    0.000 MiB       return dy


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   485  291.020 MiB  291.020 MiB   @profile
   486                             def unravel(E, f, G):
   487  291.020 MiB    0.000 MiB       unravel_E = np.reshape(E, -1)
   488  291.020 MiB    0.000 MiB       unravel_f = np.reshape(f, -1)
   489  291.020 MiB    0.000 MiB       unravel_G = np.reshape(G, -1)
   490                                 
   491  291.020 MiB    0.000 MiB       return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   493  291.020 MiB  291.020 MiB   @profile
   494                             def ravel(y, holes, particles):
   495                                 
   496  291.020 MiB    0.000 MiB       bas_len = len(np.append(holes,particles))
   497                                 
   498  291.020 MiB    0.000 MiB       ravel_E = np.reshape(y[0], ())
   499  291.020 MiB    0.000 MiB       ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500  291.020 MiB    0.000 MiB       ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501  291.020 MiB    0.000 MiB                            (bas_len, bas_len, bas_len, bas_len))
   502                                 
   503  291.020 MiB    0.000 MiB       return(ravel_E, ravel_f, ravel_G)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   522  260.168 MiB  260.168 MiB   @profile
   523                             def run(n_holes):
   524  260.168 MiB  260.168 MiB       H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                             
   526  260.168 MiB  260.168 MiB       occA = get_occA(B1, ref)
   527  260.168 MiB  260.168 MiB       occB = get_occB(B1, ref)
   528  262.207 MiB  262.207 MiB       occC = get_occC(B1, ref)
   529  262.207 MiB  262.207 MiB       occD = get_occD(B1, ref)
   530                                 
   531  275.992 MiB  275.992 MiB       E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                             
   533                                 
   534  275.992 MiB  275.992 MiB       y0 = unravel(E, f, G)
   535                             
   536  275.992 MiB    0.000 MiB       t = 1
   537  291.020 MiB  291.020 MiB       dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                             
   539  291.020 MiB  291.020 MiB       dE, df, dG = ravel(dy, holes, particles)
   540  291.020 MiB    0.000 MiB       print(dE)


---------------------------------------------\n

Executing TF on n_holes=6 ---------------------------
2019-06-20 14:51:05.318782: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 14:51:05.341782: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 14:51:05.342519: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55bdcaeb8260 executing computations on platform Host. Devices:
2019-06-20 14:51:05.342577: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-5.625
Wrote profile results to testing_tensorflow_v2_bench.py.lprof
Timer unit: 1e-06 s

Total time: 0.290558 s
File: testing_tensorflow_v2_bench.py
Function: build_hamiltonian at line 22

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    22                                           @profile
    23                                           def build_hamiltonian(n_hole_states, n_particle_states):
    24         1          1.0      1.0      0.0      numh = n_hole_states
    25         1          1.0      1.0      0.0      nump = n_particle_states
    26         1          1.0      1.0      0.0      nums = numh + nump
    27                                               
    28         1         51.0     51.0      0.0      ref = np.append(np.ones(numh), np.zeros(nump))
    29         1          6.0      6.0      0.0      holes = np.arange(numh)
    30         1          2.0      2.0      0.0      particles = np.arange(numh,numh+nump)
    31         1          9.0      9.0      0.0      B1 = np.append(holes,particles)
    32                                               
    33                                               # one body part of Hamiltonian is floor-division of basis index
    34                                               # matrix elements are (P-1) where P is energy level
    35         1         32.0     32.0      0.0      H1B = np.diag(np.floor_divide(B1,2))
    36                                           
    37         1         13.0     13.0      0.0      H2B = np.zeros((nums, nums, nums, nums))
    38        13          7.0      0.5      0.0      for p in B1:
    39       156        108.0      0.7      0.0          for q in B1:
    40      1872       1270.0      0.7      0.4              for r in B1:
    41     22464      15808.0      0.7      5.4                  for s in B1:
    42                                           
    43     20736      47019.0      2.3     16.2                      pp = np.floor_divide(p,2)
    44     20736      45151.0      2.2     15.5                      qp = np.floor_divide(q,2)
    45     20736      44659.0      2.2     15.4                      rp = np.floor_divide(r,2)
    46     20736      44600.0      2.2     15.3                      sp = np.floor_divide(s,2)
    47                                           
    48     20736      20572.0      1.0      7.1                      ps = 1 if p%2==0 else -1
    49     20736      18788.0      0.9      6.5                      qs = 1 if q%2==0 else -1
    50     20736      18876.0      0.9      6.5                      rs = 1 if r%2==0 else -1
    51     20736      18674.0      0.9      6.4                      ss = 1 if s%2==0 else -1
    52                                           
    53     20736      12537.0      0.6      4.3                      if pp != qp or rp != sp:
    54      2880       1537.0      0.5      0.5                          continue
    55       576        386.0      0.7      0.1                      if ps == qs or rs == ss:
    56       144         76.0      0.5      0.0                          continue
    57       144         79.0      0.5      0.0                      if ps == rs and qs == ss:
    58        72         94.0      1.3      0.0                          H2B[p,q,r,s] = -0.25
    59       144         96.0      0.7      0.0                      if ps == ss and qs == rs:
    60        72        104.0      1.4      0.0                          H2B[p,q,r,s] = 0.25
    61                                                                   
    62         1          1.0      1.0      0.0      return (H1B, H2B, ref, holes, particles, B1)

Total time: 0.000263 s
File: testing_tensorflow_v2_bench.py
Function: get_occA at line 65

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    65                                           @profile
    66                                           def get_occA(B1_basis, ref):
    67         1          1.0      1.0      0.4      n = len(B1_basis)
    68         1         56.0     56.0     21.3      occA = np.zeros((n,n,n,n))
    69                                               
    70        13          8.0      0.6      3.0      for a in B1_basis:
    71       156         61.0      0.4     23.2          for b in B1_basis:
    72       144        137.0      1.0     52.1              occA[a,b,a,b] = ref[a] - ref[b]
    73                                                       
    74         1          0.0      0.0      0.0      return occA

Total time: 0.000311 s
File: testing_tensorflow_v2_bench.py
Function: get_occB at line 77

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    77                                           @profile
    78                                           def get_occB(B1_basis, ref):
    79         1          0.0      0.0      0.0      n = len(B1_basis)    
    80         1         78.0     78.0     25.1      occB = np.zeros((n,n,n,n))
    81                                               
    82        13          6.0      0.5      1.9      for a in B1_basis:
    83       156         67.0      0.4     21.5          for b in B1_basis:
    84       144        159.0      1.1     51.1              occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                                       
    86         1          1.0      1.0      0.3      return occB

Total time: 0.00608 s
File: testing_tensorflow_v2_bench.py
Function: get_occC at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                           @profile
    90                                           def get_occC(B1_basis, ref):
    91         1          1.0      1.0      0.0      n = len(B1_basis)        
    92         1         10.0     10.0      0.2      occC = np.zeros((n,n,n,n,n,n))
    93                                               
    94        13          6.0      0.5      0.1      for a in B1_basis:
    95       156         78.0      0.5      1.3          for b in B1_basis:
    96      1872        867.0      0.5     14.3              for c in B1_basis:
    97      1728       5117.0      3.0     84.2                  occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                                           
    99         1          1.0      1.0      0.0      return occC

Total time: 0.054632 s
File: testing_tensorflow_v2_bench.py
Function: get_occD at line 102

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   102                                           @profile
   103                                           def get_occD(B1_basis, ref):
   104         1          2.0      2.0      0.0      n = len(B1_basis)    
   105         1         56.0     56.0      0.1      occD = np.zeros((n,n,n,n))
   106                                               
   107        13          8.0      0.6      0.0      for a in B1_basis:
   108       156         63.0      0.4      0.1          for b in B1_basis:
   109      1872        840.0      0.4      1.5              for c in B1_basis:
   110     22464       9645.0      0.4     17.7                  for d in B1_basis:
   111     20736      44016.0      2.1     80.6                      occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                               
   113         1          2.0      2.0      0.0      return occD

Total time: 0.497401 s
File: testing_tensorflow_v2_bench.py
Function: normal_order at line 126

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   126                                           @profile
   127                                           def normal_order(H1B_t, H2B_t, holes):
   128                                               
   129         1      10179.0  10179.0      2.0      H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130         1        985.0    985.0      0.2      H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131         1        806.0    806.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                               
   133                                               # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134         1      24884.0  24884.0      5.0      with tf.Session() as sess:
   135                                                   
   136                                                   # - Calculate 0B tensor
   137                                                   # E = tf.Variable(0.0)
   138         1     112461.0 112461.0     22.6          contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139         1      90168.0  90168.0     18.1          contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                                           
   141         1       2786.0   2786.0      0.6          E_1b = tf.reduce_sum(contr_1b, 0)
   142         1       4712.0   4712.0      0.9          E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143         1       1298.0   1298.0      0.3          E = tf.add_n([E_1b, E_2b])
   144                                           
   145                                                   # - Calculate 1B tensor
   146         1     146223.0 146223.0     29.4          contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147         1       7358.0   7358.0      1.5          contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                                           
   149         1       5196.0   5196.0      1.0          f = tf.add_n([H1B_t, contr_2b])
   150                                           
   151                                                   # - Calculate 2B tensor
   152         1       6097.0   6097.0      1.2          G = tf.identity(H2B_t)
   153                                                   
   154         1      84228.0  84228.0     16.9          E_e, f_e, G_e = sess.run([E, f, G])
   155                                           #         E_e = E.eval()
   156                                           #         f_e = f.eval()
   157                                           #         G_e = G.eval()
   158                                                   
   159                                           #         print(sess.run([E, f, G]))
   160                                                   
   161         1         19.0     19.0      0.0      tf.reset_default_graph()
   162                                               
   163         1          1.0      1.0      0.0      return (E_e, f_e, G_e)

Total time: 1.08338 s
File: testing_tensorflow_v2_bench.py
Function: wegner at line 236

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                           @profile
   237                                           def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                               
   239         1       1911.0   1911.0      0.2      f = tf.convert_to_tensor(f, dtype=tf.float32)
   240         1       3347.0   3347.0      0.3      G = tf.convert_to_tensor(G, dtype=tf.float32)
   241         1       2483.0   2483.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242         1       1492.0   1492.0      0.1      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243         1       1485.0   1485.0      0.1      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244         1       1050.0   1050.0      0.1      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245         1      63752.0  63752.0      5.9      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246         1       1243.0   1243.0      0.1      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                               
   248         1        230.0    230.0      0.0      with tf.Session() as sess:
   249         1       1272.0   1272.0      0.1          plen = tf.size(particles)
   250         1        984.0    984.0      0.1          hlen = tf.size(holes)
   251                                           
   252                                                   # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                                   
   254                                                   # Decoupling 1B piece
   255                                                   # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256         1       3187.0   3187.0      0.3          particles_b = tf.broadcast_to(particles, [plen,plen])
   257         1       3244.0   3244.0      0.3          holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258         1       2555.0   2555.0      0.2          ph_comb = tf.concat([particles_b, holes_b], 0)
   259         1       4931.0   4931.0      0.5          hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                                   
   261         1       2208.0   2208.0      0.2          col_indices =tf.reshape(ph_comb, [-1])
   262         1       2172.0   2172.0      0.2          row_indices = tf.reshape(hp_comb, [-1])
   263         1       1422.0   1422.0      0.1          ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264         1       1324.0   1324.0      0.1          ph_updates = tf.gather_nd(f, ph_indices)
   265                                           
   266         1       2598.0   2598.0      0.2          fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267         1       1205.0   1205.0      0.1          fd = tf.subtract(f,fod)
   268                                           
   269                                                   # Decoupling 2B piece
   270                                                   # indices are constructed by all possible combinations of pphh(hhpp) states
   271         1      13261.0  13261.0      1.2          ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272         1       2686.0   2686.0      0.2          ind1_TC = tf.transpose(ind1_C) 
   273         1       2306.0   2306.0      0.2          ind1 = tf.reshape(ind1_TC,[-1])
   274                                           
   275         1      17911.0  17911.0      1.7          ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276         1       2353.0   2353.0      0.2          ind2_TC = tf.transpose(ind2_C)
   277         1       2433.0   2433.0      0.2          ind2 = tf.reshape(ind2_TC,[-1])
   278                                           
   279         1      13399.0  13399.0      1.2          ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280         1       2340.0   2340.0      0.2          ind3_TC = tf.transpose(ind3_C) 
   281         1       2155.0   2155.0      0.2          ind3 = tf.reshape(ind3_TC,[-1])
   282                                           
   283         1      14889.0  14889.0      1.4          ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284         1       2354.0   2354.0      0.2          ind4_TC = tf.transpose(ind4_C)
   285         1       2229.0   2229.0      0.2          ind4 = tf.reshape(ind4_TC,[-1])
   286                                           
   287         1       1683.0   1683.0      0.2          pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288         1       1377.0   1377.0      0.1          pphh_updates = tf.gather_nd(G, pphh_indices)
   289                                           
   290         1       2367.0   2367.0      0.2          God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291         1       1200.0   1200.0      0.1          Gd = tf.subtract(G,God)
   292                                           
   293                                           
   294                                                   # --- 1B piece
   295                                           
   296                                                   # Calculate 1B-1B contribution
   297         1      13132.0  13132.0      1.2          fd_fod = tf.tensordot(fd,fod,1)
   298         1       2456.0   2456.0      0.2          fd_fod_T = tf.transpose(fd_fod)
   299         1       1216.0   1216.0      0.1          eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                                           
   301                                                   # Calculate 1B-2B contribution
   302         1      26389.0  26389.0      2.4          fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303         1      26911.0  26911.0      2.5          fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304         1       1167.0   1167.0      0.1          eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                                           
   306                                                   # Calculate 2B-2B contribution
   307         1      28022.0  28022.0      2.6          Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308         1       2463.0   2463.0      0.2          Gd_God_T = tf.transpose(Gd_God)
   309         1       3357.0   3357.0      0.3          scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310         1          2.0      2.0      0.0          eta1B_2b2b = scaled_sub
   311                                           
   312         1       1370.0   1370.0      0.1          eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                                           
   314                                           
   315                                           
   316                                                   # --- 2B piece
   317                                           
   318                                                   # Calculate 1B-2B contribution
   319         1      28869.0  28869.0      2.7          fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320         1       2348.0   2348.0      0.2          fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321         1       1187.0   1187.0      0.1          ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                                           
   323         1      29162.0  29162.0      2.7          fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324         1       2318.0   2318.0      0.2          fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325         1       2387.0   2387.0      0.2          fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326         1       1513.0   1513.0      0.1          kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                                           
   328         1       1240.0   1240.0      0.1          eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                                           
   330                                           
   331                                                   # Calculate 2B-2B contribution
   332         1      28853.0  28853.0      2.7          GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333         1      32445.0  32445.0      3.0          GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334         1       5840.0   5840.0      0.5          scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                                           
   336         1          2.0      2.0      0.0          eta2B_2b2b_B = scaled_sub
   337                                           
   338         1      14135.0  14135.0      1.3          GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339         1       2445.0   2445.0      0.2          GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340         1      13900.0  13900.0      1.3          GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341         1       2359.0   2359.0      0.2          GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342         1       2303.0   2303.0      0.2          GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343         1       2477.0   2477.0      0.2          GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344         1       1303.0   1303.0      0.1          sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345         1       1236.0   1236.0      0.1          sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346         1       1208.0   1208.0      0.1          add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                                           
   348         1          1.0      1.0      0.0          eta2B_2b2b_A = add3
   349                                           
   350         1       1376.0   1376.0      0.1          eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                                   
   352         1     579487.0 579487.0     53.5          eta1B_e = eta1B.eval()
   353         1      29449.0  29449.0      2.7          eta2B_e = eta2B.eval()
   354                                                   
   355         1         16.0     16.0      0.0      tf.reset_default_graph()
   356                                               
   357         1          1.0      1.0      0.0      return (eta1B_e, eta2B_e)

Total time: 1.43063 s
File: testing_tensorflow_v2_bench.py
Function: flow at line 364

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   364                                           @profile
   365                                           def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                               
   367         1       1589.0   1589.0      0.1      f = tf.convert_to_tensor(f, dtype=tf.float32)
   368         1       1025.0   1025.0      0.1      G = tf.convert_to_tensor(G, dtype=tf.float32)
   369         1        836.0    836.0      0.1      eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370         1        906.0    906.0      0.1      eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371         1        838.0    838.0      0.1      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372         1        824.0    824.0      0.1      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373         1       1088.0   1088.0      0.1      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374         1        934.0    934.0      0.1      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375         1      34075.0  34075.0      2.4      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376         1       1314.0   1314.0      0.1      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                               
   378         1        193.0    193.0      0.0      with tf.Session() as sess:
   379                                                   
   380                                                   # --- 0B piece
   381                                           
   382                                                   # Calculate 1B-1B contribution (full contraction)
   383         1      14792.0  14792.0      1.0          occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384         1      22541.0  22541.0      1.6          occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385         1       1408.0   1408.0      0.1          dE_1b1b = tf.identity(occA_e1_f)
   386                                           
   387                                                   # Calculate 2B-2B contribution (full contraction)
   388                                               #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389         1       1781.0   1781.0      0.1          e2_occD = tf.matmul(eta2B, occD_t)
   390         1      24926.0  24926.0      1.7          e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391         1       1610.0   1610.0      0.1          dE_2b2b = tf.identity(e2_occD_G)
   392                                           
   393         1       5415.0   5415.0      0.4          dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                                           
   395                                                   # --- 1B piece
   396                                           
   397                                                   # Calculate 1B-1B contribution (contraction over 1 index)
   398         1      43692.0  43692.0      3.1          e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399         1       8232.0   8232.0      0.6          e1_f_T = tf.transpose(e1_f)
   400         1       3291.0   3291.0      0.2          e1_f_add = tf.add(e1_f,e1_f_T)
   401         1       4065.0   4065.0      0.3          df_1b1b = tf.identity(e1_f_add)
   402                                           
   403                                                   # Calculate 1B-2B contribution (contraction over 2 indices)
   404         1      63657.0  63657.0      4.4          occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405         1      51838.0  51838.0      3.6          occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406         1       1721.0   1721.0      0.1          sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407         1       1531.0   1531.0      0.1          df_1b2b = tf.identity(sub_1b2b)
   408                                           
   409                                                   # Calculate 2B-2B contribution (contraction over 3 indices)
   410         1      71565.0  71565.0      5.0          e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411         1       8693.0   8693.0      0.6          e2_occC_G_T = tf.transpose(e2_occC_G)
   412         1       7705.0   7705.0      0.5          add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413         1       1214.0   1214.0      0.1          df_2b2b = tf.identity(add_2b2b)
   414                                           
   415         1       1608.0   1608.0      0.1          df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                                           
   417                                                   # --- 2B piece
   418                                           
   419                                                   # Calculate 1B-2B contribution (contraction over 1 index)
   420         1     178229.0 178229.0     12.5          e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421         1      21452.0  21452.0      1.5          e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422         1       7258.0   7258.0      0.5          ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                                           
   424         1     140380.0 140380.0      9.8          e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425         1       9506.0   9506.0      0.7          e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426         1      18639.0  18639.0      1.3          e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427         1       7153.0   7153.0      0.5          kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                                           
   429         1       8962.0   8962.0      0.6          dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                                           
   431                                                   # Calculate 2B-2B contribution (occB term)
   432         1      73751.0  73751.0      5.2          e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433         1      27345.0  27345.0      1.9          G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434         1       3372.0   3372.0      0.2          sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                                           
   436         1       1059.0   1059.0      0.1          dG_2b2b_B = tf.identity(sub_term)
   437                                           
   438                                                   # Calculate 2B-2B contribution (occA term)
   439         1      13034.0  13034.0      0.9          e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440         1       2236.0   2236.0      0.2          e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441         1      13109.0  13109.0      0.9          e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442         1       2231.0   2231.0      0.2          e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443         1       2227.0   2227.0      0.2          e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444         1       2218.0   2218.0      0.2          e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445         1       1222.0   1222.0      0.1          sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446         1       1205.0   1205.0      0.1          sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447         1       1191.0   1191.0      0.1          add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                                           
   449         1       1058.0   1058.0      0.1          dG_2b2b_A = tf.identity(add3)
   450                                           
   451         1       1370.0   1370.0      0.1          dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                                   
   453         1      42554.0  42554.0      3.0          dE_e = dE.eval()
   454         1     439568.0 439568.0     30.7          df_e = df.eval()
   455         1      25376.0  25376.0      1.8          dG_e = dG.eval()
   456                                               
   457         1         17.0     17.0      0.0      tf.reset_default_graph()
   458                                               
   459         1          3.0      3.0      0.0      return (dE_e, df_e, dG_e)

Total time: 2.5149 s
File: testing_tensorflow_v2_bench.py
Function: derivative at line 466

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   466                                           @profile
   467                                           def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                               
   469         1         50.0     50.0      0.0      E, f, G = ravel(y, holes, particles)
   470                                           
   471         1    1083689.0 1083689.0     43.1      eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                               
   473         1    1431008.0 1431008.0     56.9      dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                               
   475         1        157.0    157.0      0.0      dy = unravel(dE, df, dG)
   476                                               
   477         1          1.0      1.0      0.0      return dy

Total time: 0.000334 s
File: testing_tensorflow_v2_bench.py
Function: unravel at line 485

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   485                                           @profile
   486                                           def unravel(E, f, G):
   487         2         51.0     25.5     15.3      unravel_E = np.reshape(E, -1)
   488         2          8.0      4.0      2.4      unravel_f = np.reshape(f, -1)
   489         2          5.0      2.5      1.5      unravel_G = np.reshape(G, -1)
   490                                               
   491         2        270.0    135.0     80.8      return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)

Total time: 9.8e-05 s
File: testing_tensorflow_v2_bench.py
Function: ravel at line 493

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   493                                           @profile
   494                                           def ravel(y, holes, particles):
   495                                               
   496         2         55.0     27.5     56.1      bas_len = len(np.append(holes,particles))
   497                                               
   498         2         20.0     10.0     20.4      ravel_E = np.reshape(y[0], ())
   499         2         13.0      6.5     13.3      ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500         2          3.0      1.5      3.1      ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501         2          6.0      3.0      6.1                           (bas_len, bas_len, bas_len, bas_len))
   502                                               
   503         2          1.0      0.5      1.0      return(ravel_E, ravel_f, ravel_G)

Total time: 3.51935 s
File: testing_tensorflow_v2_bench.py
Function: run at line 522

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   522                                           @profile
   523                                           def run(n_holes):
   524         1     426936.0 426936.0     12.1      H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                                           
   526         1        353.0    353.0      0.0      occA = get_occA(B1, ref)
   527         1        412.0    412.0      0.0      occB = get_occB(B1, ref)
   528         1       7289.0   7289.0      0.2      occC = get_occC(B1, ref)
   529         1      68675.0  68675.0      2.0      occD = get_occD(B1, ref)
   530                                               
   531         1     497513.0 497513.0     14.1      E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                                           
   533                                               
   534         1        198.0    198.0      0.0      y0 = unravel(E, f, G)
   535                                           
   536         1          1.0      1.0      0.0      t = 1
   537         1    2517885.0 2517885.0     71.5      dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                                           
   539         1         69.0     69.0      0.0      dE, df, dG = ravel(dy, holes, particles)
   540         1         18.0     18.0      0.0      print(dE)

2019-06-20 14:51:27.491732: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 14:51:27.517773: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 14:51:27.518362: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5573688eb610 executing computations on platform Host. Devices:
2019-06-20 14:51:27.518427: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-5.625
Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    22  259.684 MiB  259.684 MiB   @profile
    23                             def build_hamiltonian(n_hole_states, n_particle_states):
    24  259.684 MiB    0.000 MiB       numh = n_hole_states
    25  259.684 MiB    0.000 MiB       nump = n_particle_states
    26  259.684 MiB    0.000 MiB       nums = numh + nump
    27                                 
    28  259.684 MiB    0.000 MiB       ref = np.append(np.ones(numh), np.zeros(nump))
    29  259.684 MiB    0.000 MiB       holes = np.arange(numh)
    30  259.684 MiB    0.000 MiB       particles = np.arange(numh,numh+nump)
    31  259.684 MiB    0.000 MiB       B1 = np.append(holes,particles)
    32                                 
    33                                 # one body part of Hamiltonian is floor-division of basis index
    34                                 # matrix elements are (P-1) where P is energy level
    35  259.684 MiB    0.000 MiB       H1B = np.diag(np.floor_divide(B1,2))
    36                             
    37  259.684 MiB    0.000 MiB       H2B = np.zeros((nums, nums, nums, nums))
    38  259.684 MiB    0.000 MiB       for p in B1:
    39  259.684 MiB    0.000 MiB           for q in B1:
    40  259.684 MiB    0.000 MiB               for r in B1:
    41  259.684 MiB    0.000 MiB                   for s in B1:
    42                             
    43  259.684 MiB    0.000 MiB                       pp = np.floor_divide(p,2)
    44  259.684 MiB    0.000 MiB                       qp = np.floor_divide(q,2)
    45  259.684 MiB    0.000 MiB                       rp = np.floor_divide(r,2)
    46  259.684 MiB    0.000 MiB                       sp = np.floor_divide(s,2)
    47                             
    48  259.684 MiB    0.000 MiB                       ps = 1 if p%2==0 else -1
    49  259.684 MiB    0.000 MiB                       qs = 1 if q%2==0 else -1
    50  259.684 MiB    0.000 MiB                       rs = 1 if r%2==0 else -1
    51  259.684 MiB    0.000 MiB                       ss = 1 if s%2==0 else -1
    52                             
    53  259.684 MiB    0.000 MiB                       if pp != qp or rp != sp:
    54  259.684 MiB    0.000 MiB                           continue
    55  259.684 MiB    0.000 MiB                       if ps == qs or rs == ss:
    56  259.684 MiB    0.000 MiB                           continue
    57  259.684 MiB    0.000 MiB                       if ps == rs and qs == ss:
    58  259.684 MiB    0.000 MiB                           H2B[p,q,r,s] = -0.25
    59  259.684 MiB    0.000 MiB                       if ps == ss and qs == rs:
    60  259.684 MiB    0.000 MiB                           H2B[p,q,r,s] = 0.25
    61                                                     
    62  259.684 MiB    0.000 MiB       return (H1B, H2B, ref, holes, particles, B1)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    65  259.684 MiB  259.684 MiB   @profile
    66                             def get_occA(B1_basis, ref):
    67  259.684 MiB    0.000 MiB       n = len(B1_basis)
    68  259.867 MiB    0.184 MiB       occA = np.zeros((n,n,n,n))
    69                                 
    70  259.867 MiB    0.000 MiB       for a in B1_basis:
    71  259.867 MiB    0.000 MiB           for b in B1_basis:
    72  259.867 MiB    0.000 MiB               occA[a,b,a,b] = ref[a] - ref[b]
    73                                         
    74  259.867 MiB    0.000 MiB       return occA


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    77  259.867 MiB  259.867 MiB   @profile
    78                             def get_occB(B1_basis, ref):
    79  259.867 MiB    0.000 MiB       n = len(B1_basis)    
    80  259.867 MiB    0.000 MiB       occB = np.zeros((n,n,n,n))
    81                                 
    82  259.867 MiB    0.000 MiB       for a in B1_basis:
    83  259.867 MiB    0.000 MiB           for b in B1_basis:
    84  259.867 MiB    0.000 MiB               occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                         
    86  259.867 MiB    0.000 MiB       return occB


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    89  259.867 MiB  259.867 MiB   @profile
    90                             def get_occC(B1_basis, ref):
    91  259.867 MiB    0.000 MiB       n = len(B1_basis)        
    92  259.867 MiB    0.000 MiB       occC = np.zeros((n,n,n,n,n,n))
    93                                 
    94  266.828 MiB    0.000 MiB       for a in B1_basis:
    95  266.828 MiB    0.000 MiB           for b in B1_basis:
    96  266.828 MiB    0.000 MiB               for c in B1_basis:
    97  266.828 MiB    0.258 MiB                   occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                             
    99  266.828 MiB    0.000 MiB       return occC


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   102  266.828 MiB  266.828 MiB   @profile
   103                             def get_occD(B1_basis, ref):
   104  266.828 MiB    0.000 MiB       n = len(B1_basis)    
   105  266.828 MiB    0.000 MiB       occD = np.zeros((n,n,n,n))
   106                                 
   107  266.828 MiB    0.000 MiB       for a in B1_basis:
   108  266.828 MiB    0.000 MiB           for b in B1_basis:
   109  266.828 MiB    0.000 MiB               for c in B1_basis:
   110  266.828 MiB    0.000 MiB                   for d in B1_basis:
   111  266.828 MiB    0.000 MiB                       occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                 
   113  266.828 MiB    0.000 MiB       return occD


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   126  266.828 MiB  266.828 MiB   @profile
   127                             def normal_order(H1B_t, H2B_t, holes):
   128                                 
   129  269.504 MiB    2.676 MiB       H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130  269.504 MiB    0.000 MiB       H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131  269.504 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                 
   133                                 # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134  272.648 MiB    3.145 MiB       with tf.Session() as sess:
   135                                     
   136                                     # - Calculate 0B tensor
   137                                     # E = tf.Variable(0.0)
   138  274.258 MiB    1.453 MiB           contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139  274.953 MiB    0.438 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                             
   141  274.953 MiB    0.000 MiB           E_1b = tf.reduce_sum(contr_1b, 0)
   142  274.953 MiB    0.000 MiB           E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143  274.953 MiB    0.000 MiB           E = tf.add_n([E_1b, E_2b])
   144                             
   145                                     # - Calculate 1B tensor
   146  275.688 MiB    0.477 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147  275.688 MiB    0.000 MiB           contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                             
   149  275.688 MiB    0.000 MiB           f = tf.add_n([H1B_t, contr_2b])
   150                             
   151                                     # - Calculate 2B tensor
   152  275.688 MiB    0.000 MiB           G = tf.identity(H2B_t)
   153                                     
   154  283.363 MiB    7.676 MiB           E_e, f_e, G_e = sess.run([E, f, G])
   155                             #         E_e = E.eval()
   156                             #         f_e = f.eval()
   157                             #         G_e = G.eval()
   158                                     
   159                             #         print(sess.run([E, f, G]))
   160                                     
   161  283.363 MiB    0.000 MiB       tf.reset_default_graph()
   162                                 
   163  283.363 MiB    0.000 MiB       return (E_e, f_e, G_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   236  283.363 MiB  283.363 MiB   @profile
   237                             def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                 
   239  283.363 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   240  283.363 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   241  283.363 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242  283.363 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243  283.363 MiB    0.000 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244  283.363 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245  304.992 MiB   21.629 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246  304.992 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                 
   248  304.992 MiB    0.000 MiB       with tf.Session() as sess:
   249  304.992 MiB    0.000 MiB           plen = tf.size(particles)
   250  304.992 MiB    0.000 MiB           hlen = tf.size(holes)
   251                             
   252                                     # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                     
   254                                     # Decoupling 1B piece
   255                                     # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256  304.992 MiB    0.000 MiB           particles_b = tf.broadcast_to(particles, [plen,plen])
   257  304.992 MiB    0.000 MiB           holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258  304.992 MiB    0.000 MiB           ph_comb = tf.concat([particles_b, holes_b], 0)
   259  304.992 MiB    0.000 MiB           hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                     
   261  304.992 MiB    0.000 MiB           col_indices =tf.reshape(ph_comb, [-1])
   262  304.992 MiB    0.000 MiB           row_indices = tf.reshape(hp_comb, [-1])
   263  304.992 MiB    0.000 MiB           ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264  304.992 MiB    0.000 MiB           ph_updates = tf.gather_nd(f, ph_indices)
   265                             
   266  304.992 MiB    0.000 MiB           fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267  304.992 MiB    0.000 MiB           fd = tf.subtract(f,fod)
   268                             
   269                                     # Decoupling 2B piece
   270                                     # indices are constructed by all possible combinations of pphh(hhpp) states
   271  305.273 MiB    0.281 MiB           ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272  305.273 MiB    0.000 MiB           ind1_TC = tf.transpose(ind1_C) 
   273  305.273 MiB    0.000 MiB           ind1 = tf.reshape(ind1_TC,[-1])
   274                             
   275  305.273 MiB    0.000 MiB           ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276  305.273 MiB    0.000 MiB           ind2_TC = tf.transpose(ind2_C)
   277  305.273 MiB    0.000 MiB           ind2 = tf.reshape(ind2_TC,[-1])
   278                             
   279  305.273 MiB    0.000 MiB           ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280  305.273 MiB    0.000 MiB           ind3_TC = tf.transpose(ind3_C) 
   281  305.273 MiB    0.000 MiB           ind3 = tf.reshape(ind3_TC,[-1])
   282                             
   283  305.273 MiB    0.000 MiB           ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284  305.273 MiB    0.000 MiB           ind4_TC = tf.transpose(ind4_C)
   285  305.273 MiB    0.000 MiB           ind4 = tf.reshape(ind4_TC,[-1])
   286                             
   287  305.273 MiB    0.000 MiB           pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288  305.523 MiB    0.250 MiB           pphh_updates = tf.gather_nd(G, pphh_indices)
   289                             
   290  305.523 MiB    0.000 MiB           God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291  305.523 MiB    0.000 MiB           Gd = tf.subtract(G,God)
   292                             
   293                             
   294                                     # --- 1B piece
   295                             
   296                                     # Calculate 1B-1B contribution
   297  305.523 MiB    0.000 MiB           fd_fod = tf.tensordot(fd,fod,1)
   298  305.523 MiB    0.000 MiB           fd_fod_T = tf.transpose(fd_fod)
   299  305.523 MiB    0.000 MiB           eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                             
   301                                     # Calculate 1B-2B contribution
   302  305.523 MiB    0.000 MiB           fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303  305.777 MiB    0.254 MiB           fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304  305.777 MiB    0.000 MiB           eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                             
   306                                     # Calculate 2B-2B contribution
   307  305.777 MiB    0.000 MiB           Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308  305.777 MiB    0.000 MiB           Gd_God_T = tf.transpose(Gd_God)
   309  305.777 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310  305.777 MiB    0.000 MiB           eta1B_2b2b = scaled_sub
   311                             
   312  305.777 MiB    0.000 MiB           eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                             
   314                             
   315                             
   316                                     # --- 2B piece
   317                             
   318                                     # Calculate 1B-2B contribution
   319  305.777 MiB    0.000 MiB           fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320  305.777 MiB    0.000 MiB           fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321  305.777 MiB    0.000 MiB           ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                             
   323  305.777 MiB    0.000 MiB           fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324  305.777 MiB    0.000 MiB           fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325  305.777 MiB    0.000 MiB           fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326  305.777 MiB    0.000 MiB           kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                             
   328  305.777 MiB    0.000 MiB           eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                             
   330                             
   331                                     # Calculate 2B-2B contribution
   332  305.777 MiB    0.000 MiB           GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333  305.777 MiB    0.000 MiB           GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334  305.777 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                             
   336  305.777 MiB    0.000 MiB           eta2B_2b2b_B = scaled_sub
   337                             
   338  305.777 MiB    0.000 MiB           GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339  305.777 MiB    0.000 MiB           GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340  305.777 MiB    0.000 MiB           GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341  305.777 MiB    0.000 MiB           GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342  305.777 MiB    0.000 MiB           GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343  305.777 MiB    0.000 MiB           GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344  305.777 MiB    0.000 MiB           sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345  305.777 MiB    0.000 MiB           sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346  305.777 MiB    0.000 MiB           add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                             
   348  305.777 MiB    0.000 MiB           eta2B_2b2b_A = add3
   349                             
   350  305.777 MiB    0.000 MiB           eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                     
   352  388.770 MiB   82.992 MiB           eta1B_e = eta1B.eval()
   353  365.949 MiB    0.000 MiB           eta2B_e = eta2B.eval()
   354                                     
   355  365.949 MiB    0.000 MiB       tf.reset_default_graph()
   356                                 
   357  365.949 MiB    0.000 MiB       return (eta1B_e, eta2B_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   364  365.949 MiB  365.949 MiB   @profile
   365                             def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                 
   367  365.949 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   368  307.645 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   369  307.645 MiB    0.000 MiB       eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370  307.645 MiB    0.000 MiB       eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371  307.645 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372  307.645 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373  307.645 MiB    0.000 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374  307.645 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375  330.430 MiB   22.785 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376  330.430 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                 
   378  330.430 MiB    0.000 MiB       with tf.Session() as sess:
   379                                     
   380                                     # --- 0B piece
   381                             
   382                                     # Calculate 1B-1B contribution (full contraction)
   383  330.430 MiB    0.000 MiB           occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384  330.430 MiB    0.000 MiB           occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385  330.430 MiB    0.000 MiB           dE_1b1b = tf.identity(occA_e1_f)
   386                             
   387                                     # Calculate 2B-2B contribution (full contraction)
   388                                 #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389  330.430 MiB    0.000 MiB           e2_occD = tf.matmul(eta2B, occD_t)
   390  330.430 MiB    0.000 MiB           e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391  330.430 MiB    0.000 MiB           dE_2b2b = tf.identity(e2_occD_G)
   392                             
   393  330.430 MiB    0.000 MiB           dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                             
   395                                     # --- 1B piece
   396                             
   397                                     # Calculate 1B-1B contribution (contraction over 1 index)
   398  330.430 MiB    0.000 MiB           e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399  330.430 MiB    0.000 MiB           e1_f_T = tf.transpose(e1_f)
   400  330.430 MiB    0.000 MiB           e1_f_add = tf.add(e1_f,e1_f_T)
   401  330.430 MiB    0.000 MiB           df_1b1b = tf.identity(e1_f_add)
   402                             
   403                                     # Calculate 1B-2B contribution (contraction over 2 indices)
   404  330.430 MiB    0.000 MiB           occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405  330.430 MiB    0.000 MiB           occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406  330.430 MiB    0.000 MiB           sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407  330.430 MiB    0.000 MiB           df_1b2b = tf.identity(sub_1b2b)
   408                             
   409                                     # Calculate 2B-2B contribution (contraction over 3 indices)
   410  330.664 MiB    0.234 MiB           e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411  330.676 MiB    0.012 MiB           e2_occC_G_T = tf.transpose(e2_occC_G)
   412  330.676 MiB    0.000 MiB           add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413  330.676 MiB    0.000 MiB           df_2b2b = tf.identity(add_2b2b)
   414                             
   415  330.676 MiB    0.000 MiB           df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                             
   417                                     # --- 2B piece
   418                             
   419                                     # Calculate 1B-2B contribution (contraction over 1 index)
   420  330.676 MiB    0.000 MiB           e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421  330.676 MiB    0.000 MiB           e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422  330.676 MiB    0.000 MiB           ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                             
   424  330.926 MiB    0.250 MiB           e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425  330.926 MiB    0.000 MiB           e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426  330.926 MiB    0.000 MiB           e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427  330.926 MiB    0.000 MiB           kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                             
   429  330.926 MiB    0.000 MiB           dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                             
   431                                     # Calculate 2B-2B contribution (occB term)
   432  330.926 MiB    0.000 MiB           e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433  331.176 MiB    0.250 MiB           G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434  331.176 MiB    0.000 MiB           sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                             
   436  331.176 MiB    0.000 MiB           dG_2b2b_B = tf.identity(sub_term)
   437                             
   438                                     # Calculate 2B-2B contribution (occA term)
   439  331.176 MiB    0.000 MiB           e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440  331.176 MiB    0.000 MiB           e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441  331.176 MiB    0.000 MiB           e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442  331.176 MiB    0.000 MiB           e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443  331.176 MiB    0.000 MiB           e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444  331.176 MiB    0.000 MiB           e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445  331.176 MiB    0.000 MiB           sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446  331.176 MiB    0.000 MiB           sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447  331.176 MiB    0.000 MiB           add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                             
   449  331.176 MiB    0.000 MiB           dG_2b2b_A = tf.identity(add3)
   450                             
   451  331.176 MiB    0.000 MiB           dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                     
   453  368.559 MiB   37.383 MiB           dE_e = dE.eval()
   454  392.020 MiB   23.461 MiB           df_e = df.eval()
   455  392.020 MiB    0.000 MiB           dG_e = dG.eval()
   456                                 
   457  392.020 MiB    0.000 MiB       tf.reset_default_graph()
   458                                 
   459  392.020 MiB    0.000 MiB       return (dE_e, df_e, dG_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   466  283.363 MiB  283.363 MiB   @profile
   467                             def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                 
   469  283.363 MiB  283.363 MiB       E, f, G = ravel(y, holes, particles)
   470                             
   471  365.949 MiB  365.949 MiB       eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                 
   473  392.020 MiB  392.020 MiB       dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                 
   475  392.020 MiB  392.020 MiB       dy = unravel(dE, df, dG)
   476                                 
   477  392.020 MiB    0.000 MiB       return dy


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   485  392.020 MiB  392.020 MiB   @profile
   486                             def unravel(E, f, G):
   487  392.020 MiB    0.000 MiB       unravel_E = np.reshape(E, -1)
   488  392.020 MiB    0.000 MiB       unravel_f = np.reshape(f, -1)
   489  392.020 MiB    0.000 MiB       unravel_G = np.reshape(G, -1)
   490                                 
   491  392.020 MiB    0.000 MiB       return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   493  343.855 MiB  343.855 MiB   @profile
   494                             def ravel(y, holes, particles):
   495                                 
   496  343.855 MiB    0.000 MiB       bas_len = len(np.append(holes,particles))
   497                                 
   498  343.855 MiB    0.000 MiB       ravel_E = np.reshape(y[0], ())
   499  343.855 MiB    0.000 MiB       ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500  343.855 MiB    0.000 MiB       ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501  343.855 MiB    0.000 MiB                            (bas_len, bas_len, bas_len, bas_len))
   502                                 
   503  343.855 MiB    0.000 MiB       return(ravel_E, ravel_f, ravel_G)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   522  259.684 MiB  259.684 MiB   @profile
   523                             def run(n_holes):
   524  259.684 MiB  259.684 MiB       H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                             
   526  259.867 MiB  259.867 MiB       occA = get_occA(B1, ref)
   527  259.867 MiB  259.867 MiB       occB = get_occB(B1, ref)
   528  266.828 MiB  266.828 MiB       occC = get_occC(B1, ref)
   529  266.828 MiB  266.828 MiB       occD = get_occD(B1, ref)
   530                                 
   531  283.363 MiB  283.363 MiB       E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                             
   533                                 
   534  283.363 MiB  283.363 MiB       y0 = unravel(E, f, G)
   535                             
   536  283.363 MiB    0.000 MiB       t = 1
   537  343.855 MiB  343.855 MiB       dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                             
   539  343.855 MiB  343.855 MiB       dE, df, dG = ravel(dy, holes, particles)
   540  343.855 MiB    0.000 MiB       print(dE)


---------------------------------------------\n

Executing TF on n_holes=8 ---------------------------
2019-06-20 14:53:52.773884: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 14:53:52.793774: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 14:53:52.794095: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5635617e8ab0 executing computations on platform Host. Devices:
2019-06-20 14:53:52.794138: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-13.0
Wrote profile results to testing_tensorflow_v2_bench.py.lprof
Timer unit: 1e-06 s

Total time: 0.905299 s
File: testing_tensorflow_v2_bench.py
Function: build_hamiltonian at line 22

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    22                                           @profile
    23                                           def build_hamiltonian(n_hole_states, n_particle_states):
    24         1          1.0      1.0      0.0      numh = n_hole_states
    25         1          1.0      1.0      0.0      nump = n_particle_states
    26         1          1.0      1.0      0.0      nums = numh + nump
    27                                               
    28         1         62.0     62.0      0.0      ref = np.append(np.ones(numh), np.zeros(nump))
    29         1          5.0      5.0      0.0      holes = np.arange(numh)
    30         1          2.0      2.0      0.0      particles = np.arange(numh,numh+nump)
    31         1          8.0      8.0      0.0      B1 = np.append(holes,particles)
    32                                               
    33                                               # one body part of Hamiltonian is floor-division of basis index
    34                                               # matrix elements are (P-1) where P is energy level
    35         1         30.0     30.0      0.0      H1B = np.diag(np.floor_divide(B1,2))
    36                                           
    37         1         10.0     10.0      0.0      H2B = np.zeros((nums, nums, nums, nums))
    38        17          9.0      0.5      0.0      for p in B1:
    39       272        176.0      0.6      0.0          for q in B1:
    40      4352       2894.0      0.7      0.3              for r in B1:
    41     69632      46137.0      0.7      5.1                  for s in B1:
    42                                           
    43     65536     143935.0      2.2     15.9                      pp = np.floor_divide(p,2)
    44     65536     144497.0      2.2     16.0                      qp = np.floor_divide(q,2)
    45     65536     140305.0      2.1     15.5                      rp = np.floor_divide(r,2)
    46     65536     140863.0      2.1     15.6                      sp = np.floor_divide(s,2)
    47                                           
    48     65536      63426.0      1.0      7.0                      ps = 1 if p%2==0 else -1
    49     65536      59042.0      0.9      6.5                      qs = 1 if q%2==0 else -1
    50     65536      59750.0      0.9      6.6                      rs = 1 if r%2==0 else -1
    51     65536      59060.0      0.9      6.5                      ss = 1 if s%2==0 else -1
    52                                           
    53     65536      39584.0      0.6      4.4                      if pp != qp or rp != sp:
    54      7168       3992.0      0.6      0.4                          continue
    55      1024        690.0      0.7      0.1                      if ps == qs or rs == ss:
    56       256        131.0      0.5      0.0                          continue
    57       256        172.0      0.7      0.0                      if ps == rs and qs == ss:
    58       128        165.0      1.3      0.0                          H2B[p,q,r,s] = -0.25
    59       256        154.0      0.6      0.0                      if ps == ss and qs == rs:
    60       128        196.0      1.5      0.0                          H2B[p,q,r,s] = 0.25
    61                                                                   
    62         1          1.0      1.0      0.0      return (H1B, H2B, ref, holes, particles, B1)

Total time: 0.000523 s
File: testing_tensorflow_v2_bench.py
Function: get_occA at line 65

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    65                                           @profile
    66                                           def get_occA(B1_basis, ref):
    67         1          2.0      2.0      0.4      n = len(B1_basis)
    68         1         62.0     62.0     11.9      occA = np.zeros((n,n,n,n))
    69                                               
    70        17          9.0      0.5      1.7      for a in B1_basis:
    71       272        114.0      0.4     21.8          for b in B1_basis:
    72       256        336.0      1.3     64.2              occA[a,b,a,b] = ref[a] - ref[b]
    73                                                       
    74         1          0.0      0.0      0.0      return occA

Total time: 0.000537 s
File: testing_tensorflow_v2_bench.py
Function: get_occB at line 77

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    77                                           @profile
    78                                           def get_occB(B1_basis, ref):
    79         1          1.0      1.0      0.2      n = len(B1_basis)    
    80         1         45.0     45.0      8.4      occB = np.zeros((n,n,n,n))
    81                                               
    82        17          6.0      0.4      1.1      for a in B1_basis:
    83       272        111.0      0.4     20.7          for b in B1_basis:
    84       256        374.0      1.5     69.6              occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                                       
    86         1          0.0      0.0      0.0      return occB

Total time: 0.013882 s
File: testing_tensorflow_v2_bench.py
Function: get_occC at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                           @profile
    90                                           def get_occC(B1_basis, ref):
    91         1          1.0      1.0      0.0      n = len(B1_basis)        
    92         1          8.0      8.0      0.1      occC = np.zeros((n,n,n,n,n,n))
    93                                               
    94        17          7.0      0.4      0.1      for a in B1_basis:
    95       272        100.0      0.4      0.7          for b in B1_basis:
    96      4352       1851.0      0.4     13.3              for c in B1_basis:
    97      4096      11914.0      2.9     85.8                  occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                                           
    99         1          1.0      1.0      0.0      return occC

Total time: 0.165496 s
File: testing_tensorflow_v2_bench.py
Function: get_occD at line 102

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   102                                           @profile
   103                                           def get_occD(B1_basis, ref):
   104         1          2.0      2.0      0.0      n = len(B1_basis)    
   105         1         54.0     54.0      0.0      occD = np.zeros((n,n,n,n))
   106                                               
   107        17         10.0      0.6      0.0      for a in B1_basis:
   108       272        111.0      0.4      0.1          for b in B1_basis:
   109      4352       1686.0      0.4      1.0              for c in B1_basis:
   110     69632      27234.0      0.4     16.5                  for d in B1_basis:
   111     65536     136399.0      2.1     82.4                      occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                               
   113         1          0.0      0.0      0.0      return occD

Total time: 0.371236 s
File: testing_tensorflow_v2_bench.py
Function: normal_order at line 126

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   126                                           @profile
   127                                           def normal_order(H1B_t, H2B_t, holes):
   128                                               
   129         1      10079.0  10079.0      2.7      H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130         1       1430.0   1430.0      0.4      H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131         1        862.0    862.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                               
   133                                               # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134         1      20769.0  20769.0      5.6      with tf.Session() as sess:
   135                                                   
   136                                                   # - Calculate 0B tensor
   137                                                   # E = tf.Variable(0.0)
   138         1      94193.0  94193.0     25.4          contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139         1      89100.0  89100.0     24.0          contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                                           
   141         1       2438.0   2438.0      0.7          E_1b = tf.reduce_sum(contr_1b, 0)
   142         1       4485.0   4485.0      1.2          E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143         1       1256.0   1256.0      0.3          E = tf.add_n([E_1b, E_2b])
   144                                           
   145                                                   # - Calculate 1B tensor
   146         1      86615.0  86615.0     23.3          contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147         1       2469.0   2469.0      0.7          contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                                           
   149         1       1242.0   1242.0      0.3          f = tf.add_n([H1B_t, contr_2b])
   150                                           
   151                                                   # - Calculate 2B tensor
   152         1       1000.0   1000.0      0.3          G = tf.identity(H2B_t)
   153                                                   
   154         1      55280.0  55280.0     14.9          E_e, f_e, G_e = sess.run([E, f, G])
   155                                           #         E_e = E.eval()
   156                                           #         f_e = f.eval()
   157                                           #         G_e = G.eval()
   158                                                   
   159                                           #         print(sess.run([E, f, G]))
   160                                                   
   161         1         17.0     17.0      0.0      tf.reset_default_graph()
   162                                               
   163         1          1.0      1.0      0.0      return (E_e, f_e, G_e)

Total time: 5.28216 s
File: testing_tensorflow_v2_bench.py
Function: wegner at line 236

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                           @profile
   237                                           def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                               
   239         1       1222.0   1222.0      0.0      f = tf.convert_to_tensor(f, dtype=tf.float32)
   240         1       1075.0   1075.0      0.0      G = tf.convert_to_tensor(G, dtype=tf.float32)
   241         1        814.0    814.0      0.0      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242         1        777.0    777.0      0.0      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243         1       1065.0   1065.0      0.0      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244         1       1236.0   1236.0      0.0      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245         1     347671.0 347671.0      6.6      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246         1       1395.0   1395.0      0.0      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                               
   248         1        205.0    205.0      0.0      with tf.Session() as sess:
   249         1       1283.0   1283.0      0.0          plen = tf.size(particles)
   250         1        966.0    966.0      0.0          hlen = tf.size(holes)
   251                                           
   252                                                   # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                                   
   254                                                   # Decoupling 1B piece
   255                                                   # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256         1       3056.0   3056.0      0.1          particles_b = tf.broadcast_to(particles, [plen,plen])
   257         1       2993.0   2993.0      0.1          holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258         1       2471.0   2471.0      0.0          ph_comb = tf.concat([particles_b, holes_b], 0)
   259         1       4699.0   4699.0      0.1          hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                                   
   261         1       2264.0   2264.0      0.0          col_indices =tf.reshape(ph_comb, [-1])
   262         1       2168.0   2168.0      0.0          row_indices = tf.reshape(hp_comb, [-1])
   263         1       1435.0   1435.0      0.0          ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264         1       1304.0   1304.0      0.0          ph_updates = tf.gather_nd(f, ph_indices)
   265                                           
   266         1       2410.0   2410.0      0.0          fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267         1       1214.0   1214.0      0.0          fd = tf.subtract(f,fod)
   268                                           
   269                                                   # Decoupling 2B piece
   270                                                   # indices are constructed by all possible combinations of pphh(hhpp) states
   271         1      13179.0  13179.0      0.2          ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272         1       2401.0   2401.0      0.0          ind1_TC = tf.transpose(ind1_C) 
   273         1       2198.0   2198.0      0.0          ind1 = tf.reshape(ind1_TC,[-1])
   274                                           
   275         1      17963.0  17963.0      0.3          ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276         1       2350.0   2350.0      0.0          ind2_TC = tf.transpose(ind2_C)
   277         1       2144.0   2144.0      0.0          ind2 = tf.reshape(ind2_TC,[-1])
   278                                           
   279         1      13145.0  13145.0      0.2          ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280         1       2266.0   2266.0      0.0          ind3_TC = tf.transpose(ind3_C) 
   281         1       2155.0   2155.0      0.0          ind3 = tf.reshape(ind3_TC,[-1])
   282                                           
   283         1      14384.0  14384.0      0.3          ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284         1       2318.0   2318.0      0.0          ind4_TC = tf.transpose(ind4_C)
   285         1       2192.0   2192.0      0.0          ind4 = tf.reshape(ind4_TC,[-1])
   286                                           
   287         1       1534.0   1534.0      0.0          pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288         1       1276.0   1276.0      0.0          pphh_updates = tf.gather_nd(G, pphh_indices)
   289                                           
   290         1       2316.0   2316.0      0.0          God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291         1       1163.0   1163.0      0.0          Gd = tf.subtract(G,God)
   292                                           
   293                                           
   294                                                   # --- 1B piece
   295                                           
   296                                                   # Calculate 1B-1B contribution
   297         1      12608.0  12608.0      0.2          fd_fod = tf.tensordot(fd,fod,1)
   298         1       2370.0   2370.0      0.0          fd_fod_T = tf.transpose(fd_fod)
   299         1       1154.0   1154.0      0.0          eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                                           
   301                                                   # Calculate 1B-2B contribution
   302         1      26123.0  26123.0      0.5          fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303         1      25317.0  25317.0      0.5          fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304         1       1140.0   1140.0      0.0          eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                                           
   306                                                   # Calculate 2B-2B contribution
   307         1      25117.0  25117.0      0.5          Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308         1       2319.0   2319.0      0.0          Gd_God_T = tf.transpose(Gd_God)
   309         1       3252.0   3252.0      0.1          scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310         1          1.0      1.0      0.0          eta1B_2b2b = scaled_sub
   311                                           
   312         1       1338.0   1338.0      0.0          eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                                           
   314                                           
   315                                           
   316                                                   # --- 2B piece
   317                                           
   318                                                   # Calculate 1B-2B contribution
   319         1      26911.0  26911.0      0.5          fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320         1       2359.0   2359.0      0.0          fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321         1       1169.0   1169.0      0.0          ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                                           
   323         1      26855.0  26855.0      0.5          fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324         1       2258.0   2258.0      0.0          fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325         1       2255.0   2255.0      0.0          fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326         1       1144.0   1144.0      0.0          kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                                           
   328         1       1154.0   1154.0      0.0          eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                                           
   330                                           
   331                                                   # Calculate 2B-2B contribution
   332         1      24891.0  24891.0      0.5          GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333         1      24900.0  24900.0      0.5          GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334         1       3130.0   3130.0      0.1          scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                                           
   336         1          1.0      1.0      0.0          eta2B_2b2b_B = scaled_sub
   337                                           
   338         1      12643.0  12643.0      0.2          GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339         1       2103.0   2103.0      0.0          GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340         1      12831.0  12831.0      0.2          GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341         1       2164.0   2164.0      0.0          GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342         1       2155.0   2155.0      0.0          GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343         1       2147.0   2147.0      0.0          GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344         1       1152.0   1152.0      0.0          sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345         1       1119.0   1119.0      0.0          sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346         1       1111.0   1111.0      0.0          add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                                           
   348         1          1.0      1.0      0.0          eta2B_2b2b_A = add3
   349                                           
   350         1       1395.0   1395.0      0.0          eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                                   
   352         1    4401216.0 4401216.0     83.3          eta1B_e = eta1B.eval()
   353         1     159628.0 159628.0      3.0          eta2B_e = eta2B.eval()
   354                                                   
   355         1         20.0     20.0      0.0      tf.reset_default_graph()
   356                                               
   357         1          2.0      2.0      0.0      return (eta1B_e, eta2B_e)

Total time: 4.54036 s
File: testing_tensorflow_v2_bench.py
Function: flow at line 364

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   364                                           @profile
   365                                           def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                               
   367         1       1270.0   1270.0      0.0      f = tf.convert_to_tensor(f, dtype=tf.float32)
   368         1       1162.0   1162.0      0.0      G = tf.convert_to_tensor(G, dtype=tf.float32)
   369         1        851.0    851.0      0.0      eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370         1       1039.0   1039.0      0.0      eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371         1        864.0    864.0      0.0      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372         1        846.0    846.0      0.0      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373         1       1168.0   1168.0      0.0      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374         1       1518.0   1518.0      0.0      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375         1     331235.0 331235.0      7.3      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376         1       1543.0   1543.0      0.0      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                               
   378         1        195.0    195.0      0.0      with tf.Session() as sess:
   379                                                   
   380                                                   # --- 0B piece
   381                                           
   382                                                   # Calculate 1B-1B contribution (full contraction)
   383         1      13393.0  13393.0      0.3          occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384         1      13173.0  13173.0      0.3          occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385         1       1070.0   1070.0      0.0          dE_1b1b = tf.identity(occA_e1_f)
   386                                           
   387                                                   # Calculate 2B-2B contribution (full contraction)
   388                                               #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389         1       1595.0   1595.0      0.0          e2_occD = tf.matmul(eta2B, occD_t)
   390         1      15311.0  15311.0      0.3          e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391         1       1055.0   1055.0      0.0          dE_2b2b = tf.identity(e2_occD_G)
   392                                           
   393         1       1310.0   1310.0      0.0          dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                                           
   395                                                   # --- 1B piece
   396                                           
   397                                                   # Calculate 1B-1B contribution (contraction over 1 index)
   398         1      12961.0  12961.0      0.3          e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399         1       2300.0   2300.0      0.1          e1_f_T = tf.transpose(e1_f)
   400         1       1166.0   1166.0      0.0          e1_f_add = tf.add(e1_f,e1_f_T)
   401         1       1069.0   1069.0      0.0          df_1b1b = tf.identity(e1_f_add)
   402                                           
   403                                                   # Calculate 1B-2B contribution (contraction over 2 indices)
   404         1      25702.0  25702.0      0.6          occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405         1      25329.0  25329.0      0.6          occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406         1       1179.0   1179.0      0.0          sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407         1       1028.0   1028.0      0.0          df_1b2b = tf.identity(sub_1b2b)
   408                                           
   409                                                   # Calculate 2B-2B contribution (contraction over 3 indices)
   410         1      25652.0  25652.0      0.6          e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411         1       2254.0   2254.0      0.0          e2_occC_G_T = tf.transpose(e2_occC_G)
   412         1       3271.0   3271.0      0.1          add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413         1       1050.0   1050.0      0.0          df_2b2b = tf.identity(add_2b2b)
   414                                           
   415         1       1346.0   1346.0      0.0          df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                                           
   417                                                   # --- 2B piece
   418                                           
   419                                                   # Calculate 1B-2B contribution (contraction over 1 index)
   420         1      93049.0  93049.0      2.0          e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421         1       2305.0   2305.0      0.1          e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422         1       1325.0   1325.0      0.0          ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                                           
   424         1      28109.0  28109.0      0.6          e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425         1       2234.0   2234.0      0.0          e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426         1       2253.0   2253.0      0.0          e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427         1       1255.0   1255.0      0.0          kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                                           
   429         1       2404.0   2404.0      0.1          dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                                           
   431                                                   # Calculate 2B-2B contribution (occB term)
   432         1      26038.0  26038.0      0.6          e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433         1      26253.0  26253.0      0.6          G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434         1       3296.0   3296.0      0.1          sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                                           
   436         1       1041.0   1041.0      0.0          dG_2b2b_B = tf.identity(sub_term)
   437                                           
   438                                                   # Calculate 2B-2B contribution (occA term)
   439         1      12530.0  12530.0      0.3          e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440         1       2148.0   2148.0      0.0          e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441         1      12895.0  12895.0      0.3          e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442         1       2153.0   2153.0      0.0          e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443         1       2137.0   2137.0      0.0          e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444         1       2122.0   2122.0      0.0          e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445         1       1153.0   1153.0      0.0          sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446         1       1168.0   1168.0      0.0          sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447         1       1148.0   1148.0      0.0          add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                                           
   449         1       1022.0   1022.0      0.0          dG_2b2b_A = tf.identity(add3)
   450                                           
   451         1       1282.0   1282.0      0.0          dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                                   
   453         1     226202.0 226202.0      5.0          dE_e = dE.eval()
   454         1    3438566.0 3438566.0     75.7          df_e = df.eval()
   455         1     153348.0 153348.0      3.4          dG_e = dG.eval()
   456                                               
   457         1         20.0     20.0      0.0      tf.reset_default_graph()
   458                                               
   459         1          1.0      1.0      0.0      return (dE_e, df_e, dG_e)

Total time: 9.8233 s
File: testing_tensorflow_v2_bench.py
Function: derivative at line 466

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   466                                           @profile
   467                                           def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                               
   469         1         57.0     57.0      0.0      E, f, G = ravel(y, holes, particles)
   470                                           
   471         1    5282458.0 5282458.0     53.8      eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                               
   473         1    4540583.0 4540583.0     46.2      dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                               
   475         1        203.0    203.0      0.0      dy = unravel(dE, df, dG)
   476                                               
   477         1          1.0      1.0      0.0      return dy

Total time: 0.000332 s
File: testing_tensorflow_v2_bench.py
Function: unravel at line 485

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   485                                           @profile
   486                                           def unravel(E, f, G):
   487         2         51.0     25.5     15.4      unravel_E = np.reshape(E, -1)
   488         2          9.0      4.5      2.7      unravel_f = np.reshape(f, -1)
   489         2          6.0      3.0      1.8      unravel_G = np.reshape(G, -1)
   490                                               
   491         2        266.0    133.0     80.1      return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)

Total time: 8.7e-05 s
File: testing_tensorflow_v2_bench.py
Function: ravel at line 493

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   493                                           @profile
   494                                           def ravel(y, holes, particles):
   495                                               
   496         2         48.0     24.0     55.2      bas_len = len(np.append(holes,particles))
   497                                               
   498         2         17.0      8.5     19.5      ravel_E = np.reshape(y[0], ())
   499         2         11.0      5.5     12.6      ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500         2          4.0      2.0      4.6      ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501         2          6.0      3.0      6.9                           (bas_len, bas_len, bas_len, bas_len))
   502                                               
   503         2          1.0      0.5      1.1      return(ravel_E, ravel_f, ravel_G)

Total time: 11.7589 s
File: testing_tensorflow_v2_bench.py
Function: run at line 522

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   522                                           @profile
   523                                           def run(n_holes):
   524         1    1337749.0 1337749.0     11.4      H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                                           
   526         1        664.0    664.0      0.0      occA = get_occA(B1, ref)
   527         1        686.0    686.0      0.0      occB = get_occB(B1, ref)
   528         1      16532.0  16532.0      0.1      occC = get_occC(B1, ref)
   529         1     208411.0 208411.0      1.8      occD = get_occD(B1, ref)
   530                                               
   531         1     371308.0 371308.0      3.2      E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                                           
   533                                               
   534         1        150.0    150.0      0.0      y0 = unravel(E, f, G)
   535                                           
   536         1          1.0      1.0      0.0      t = 1
   537         1    9823316.0 9823316.0     83.5      dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                                           
   539         1         46.0     46.0      0.0      dE, df, dG = ravel(dy, holes, particles)
   540         1         17.0     17.0      0.0      print(dE)

2019-06-20 14:54:54.622875: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 14:54:54.645942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 14:54:54.646717: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x555c2f24f740 executing computations on platform Host. Devices:
2019-06-20 14:54:54.646784: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-13.0
Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    22  259.543 MiB  259.543 MiB   @profile
    23                             def build_hamiltonian(n_hole_states, n_particle_states):
    24  259.543 MiB    0.000 MiB       numh = n_hole_states
    25  259.543 MiB    0.000 MiB       nump = n_particle_states
    26  259.543 MiB    0.000 MiB       nums = numh + nump
    27                                 
    28  259.543 MiB    0.000 MiB       ref = np.append(np.ones(numh), np.zeros(nump))
    29  259.543 MiB    0.000 MiB       holes = np.arange(numh)
    30  259.543 MiB    0.000 MiB       particles = np.arange(numh,numh+nump)
    31  259.543 MiB    0.000 MiB       B1 = np.append(holes,particles)
    32                                 
    33                                 # one body part of Hamiltonian is floor-division of basis index
    34                                 # matrix elements are (P-1) where P is energy level
    35  259.543 MiB    0.000 MiB       H1B = np.diag(np.floor_divide(B1,2))
    36                             
    37  259.543 MiB    0.000 MiB       H2B = np.zeros((nums, nums, nums, nums))
    38  259.543 MiB    0.000 MiB       for p in B1:
    39  259.543 MiB    0.000 MiB           for q in B1:
    40  259.543 MiB    0.000 MiB               for r in B1:
    41  259.543 MiB    0.000 MiB                   for s in B1:
    42                             
    43  259.543 MiB    0.000 MiB                       pp = np.floor_divide(p,2)
    44  259.543 MiB    0.000 MiB                       qp = np.floor_divide(q,2)
    45  259.543 MiB    0.000 MiB                       rp = np.floor_divide(r,2)
    46  259.543 MiB    0.000 MiB                       sp = np.floor_divide(s,2)
    47                             
    48  259.543 MiB    0.000 MiB                       ps = 1 if p%2==0 else -1
    49  259.543 MiB    0.000 MiB                       qs = 1 if q%2==0 else -1
    50  259.543 MiB    0.000 MiB                       rs = 1 if r%2==0 else -1
    51  259.543 MiB    0.000 MiB                       ss = 1 if s%2==0 else -1
    52                             
    53  259.543 MiB    0.000 MiB                       if pp != qp or rp != sp:
    54  259.543 MiB    0.000 MiB                           continue
    55  259.543 MiB    0.000 MiB                       if ps == qs or rs == ss:
    56  259.543 MiB    0.000 MiB                           continue
    57  259.543 MiB    0.000 MiB                       if ps == rs and qs == ss:
    58  259.543 MiB    0.000 MiB                           H2B[p,q,r,s] = -0.25
    59  259.543 MiB    0.000 MiB                       if ps == ss and qs == rs:
    60  259.543 MiB    0.000 MiB                           H2B[p,q,r,s] = 0.25
    61                                                     
    62  259.543 MiB    0.000 MiB       return (H1B, H2B, ref, holes, particles, B1)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    65  259.543 MiB  259.543 MiB   @profile
    66                             def get_occA(B1_basis, ref):
    67  259.543 MiB    0.000 MiB       n = len(B1_basis)
    68  259.727 MiB    0.184 MiB       occA = np.zeros((n,n,n,n))
    69                                 
    70  259.984 MiB    0.000 MiB       for a in B1_basis:
    71  259.984 MiB    0.000 MiB           for b in B1_basis:
    72  259.984 MiB    0.258 MiB               occA[a,b,a,b] = ref[a] - ref[b]
    73                                         
    74  259.984 MiB    0.000 MiB       return occA


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    77  259.984 MiB  259.984 MiB   @profile
    78                             def get_occB(B1_basis, ref):
    79  259.984 MiB    0.000 MiB       n = len(B1_basis)    
    80  260.242 MiB    0.258 MiB       occB = np.zeros((n,n,n,n))
    81                                 
    82  260.500 MiB    0.000 MiB       for a in B1_basis:
    83  260.500 MiB    0.000 MiB           for b in B1_basis:
    84  260.500 MiB    0.258 MiB               occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                         
    86  260.500 MiB    0.000 MiB       return occB


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    89  260.500 MiB  260.500 MiB   @profile
    90                             def get_occC(B1_basis, ref):
    91  260.500 MiB    0.000 MiB       n = len(B1_basis)        
    92  260.500 MiB    0.000 MiB       occC = np.zeros((n,n,n,n,n,n))
    93                                 
    94  276.484 MiB    0.000 MiB       for a in B1_basis:
    95  276.484 MiB    0.000 MiB           for b in B1_basis:
    96  276.484 MiB    0.000 MiB               for c in B1_basis:
    97  276.484 MiB    0.258 MiB                   occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                             
    99  276.484 MiB    0.000 MiB       return occC


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   102  276.484 MiB  276.484 MiB   @profile
   103                             def get_occD(B1_basis, ref):
   104  276.484 MiB    0.000 MiB       n = len(B1_basis)    
   105  276.742 MiB    0.258 MiB       occD = np.zeros((n,n,n,n))
   106                                 
   107  277.000 MiB    0.000 MiB       for a in B1_basis:
   108  277.000 MiB    0.000 MiB           for b in B1_basis:
   109  277.000 MiB    0.000 MiB               for c in B1_basis:
   110  277.000 MiB    0.000 MiB                   for d in B1_basis:
   111  277.000 MiB    0.258 MiB                       occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                 
   113  277.000 MiB    0.000 MiB       return occD


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   126  277.000 MiB  277.000 MiB   @profile
   127                             def normal_order(H1B_t, H2B_t, holes):
   128                                 
   129  279.336 MiB    2.336 MiB       H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130  280.199 MiB    0.863 MiB       H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131  280.199 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                 
   133                                 # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134  282.898 MiB    2.699 MiB       with tf.Session() as sess:
   135                                     
   136                                     # - Calculate 0B tensor
   137                                     # E = tf.Variable(0.0)
   138  284.117 MiB    0.992 MiB           contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139  284.777 MiB    0.406 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                             
   141  284.777 MiB    0.000 MiB           E_1b = tf.reduce_sum(contr_1b, 0)
   142  284.777 MiB    0.000 MiB           E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143  284.777 MiB    0.000 MiB           E = tf.add_n([E_1b, E_2b])
   144                             
   145                                     # - Calculate 1B tensor
   146  285.371 MiB    0.453 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147  285.371 MiB    0.000 MiB           contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                             
   149  285.371 MiB    0.000 MiB           f = tf.add_n([H1B_t, contr_2b])
   150                             
   151                                     # - Calculate 2B tensor
   152  285.371 MiB    0.000 MiB           G = tf.identity(H2B_t)
   153                                     
   154  296.348 MiB   10.977 MiB           E_e, f_e, G_e = sess.run([E, f, G])
   155                             #         E_e = E.eval()
   156                             #         f_e = f.eval()
   157                             #         G_e = G.eval()
   158                                     
   159                             #         print(sess.run([E, f, G]))
   160                                     
   161  296.348 MiB    0.000 MiB       tf.reset_default_graph()
   162                                 
   163  296.348 MiB    0.000 MiB       return (E_e, f_e, G_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   236  296.348 MiB  296.348 MiB   @profile
   237                             def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                 
   239  296.348 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   240  296.348 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   241  296.348 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242  296.348 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243  296.348 MiB    0.000 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244  296.348 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245  361.543 MiB   65.195 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246  361.543 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                 
   248  361.543 MiB    0.000 MiB       with tf.Session() as sess:
   249  361.543 MiB    0.000 MiB           plen = tf.size(particles)
   250  361.543 MiB    0.000 MiB           hlen = tf.size(holes)
   251                             
   252                                     # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                     
   254                                     # Decoupling 1B piece
   255                                     # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256  361.543 MiB    0.000 MiB           particles_b = tf.broadcast_to(particles, [plen,plen])
   257  361.543 MiB    0.000 MiB           holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258  361.543 MiB    0.000 MiB           ph_comb = tf.concat([particles_b, holes_b], 0)
   259  361.543 MiB    0.000 MiB           hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                     
   261  361.543 MiB    0.000 MiB           col_indices =tf.reshape(ph_comb, [-1])
   262  361.543 MiB    0.000 MiB           row_indices = tf.reshape(hp_comb, [-1])
   263  361.543 MiB    0.000 MiB           ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264  361.543 MiB    0.000 MiB           ph_updates = tf.gather_nd(f, ph_indices)
   265                             
   266  361.543 MiB    0.000 MiB           fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267  361.543 MiB    0.000 MiB           fd = tf.subtract(f,fod)
   268                             
   269                                     # Decoupling 2B piece
   270                                     # indices are constructed by all possible combinations of pphh(hhpp) states
   271  361.820 MiB    0.277 MiB           ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272  361.820 MiB    0.000 MiB           ind1_TC = tf.transpose(ind1_C) 
   273  361.820 MiB    0.000 MiB           ind1 = tf.reshape(ind1_TC,[-1])
   274                             
   275  361.820 MiB    0.000 MiB           ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276  361.820 MiB    0.000 MiB           ind2_TC = tf.transpose(ind2_C)
   277  361.820 MiB    0.000 MiB           ind2 = tf.reshape(ind2_TC,[-1])
   278                             
   279  361.820 MiB    0.000 MiB           ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280  361.820 MiB    0.000 MiB           ind3_TC = tf.transpose(ind3_C) 
   281  361.820 MiB    0.000 MiB           ind3 = tf.reshape(ind3_TC,[-1])
   282                             
   283  361.820 MiB    0.000 MiB           ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284  361.820 MiB    0.000 MiB           ind4_TC = tf.transpose(ind4_C)
   285  361.820 MiB    0.000 MiB           ind4 = tf.reshape(ind4_TC,[-1])
   286                             
   287  361.820 MiB    0.000 MiB           pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288  362.070 MiB    0.250 MiB           pphh_updates = tf.gather_nd(G, pphh_indices)
   289                             
   290  362.070 MiB    0.000 MiB           God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291  362.070 MiB    0.000 MiB           Gd = tf.subtract(G,God)
   292                             
   293                             
   294                                     # --- 1B piece
   295                             
   296                                     # Calculate 1B-1B contribution
   297  362.070 MiB    0.000 MiB           fd_fod = tf.tensordot(fd,fod,1)
   298  362.070 MiB    0.000 MiB           fd_fod_T = tf.transpose(fd_fod)
   299  362.070 MiB    0.000 MiB           eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                             
   301                                     # Calculate 1B-2B contribution
   302  362.070 MiB    0.000 MiB           fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303  362.324 MiB    0.254 MiB           fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304  362.324 MiB    0.000 MiB           eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                             
   306                                     # Calculate 2B-2B contribution
   307  362.324 MiB    0.000 MiB           Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308  362.324 MiB    0.000 MiB           Gd_God_T = tf.transpose(Gd_God)
   309  362.324 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310  362.324 MiB    0.000 MiB           eta1B_2b2b = scaled_sub
   311                             
   312  362.324 MiB    0.000 MiB           eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                             
   314                             
   315                             
   316                                     # --- 2B piece
   317                             
   318                                     # Calculate 1B-2B contribution
   319  362.324 MiB    0.000 MiB           fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320  362.324 MiB    0.000 MiB           fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321  362.324 MiB    0.000 MiB           ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                             
   323  362.324 MiB    0.000 MiB           fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324  362.324 MiB    0.000 MiB           fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325  362.324 MiB    0.000 MiB           fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326  362.324 MiB    0.000 MiB           kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                             
   328  362.324 MiB    0.000 MiB           eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                             
   330                             
   331                                     # Calculate 2B-2B contribution
   332  362.324 MiB    0.000 MiB           GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333  362.324 MiB    0.000 MiB           GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334  362.324 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                             
   336  362.324 MiB    0.000 MiB           eta2B_2b2b_B = scaled_sub
   337                             
   338  362.324 MiB    0.000 MiB           GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339  362.324 MiB    0.000 MiB           GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340  362.324 MiB    0.000 MiB           GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341  362.324 MiB    0.000 MiB           GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342  362.324 MiB    0.000 MiB           GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343  362.324 MiB    0.000 MiB           GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344  362.324 MiB    0.000 MiB           sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345  362.324 MiB    0.000 MiB           sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346  362.324 MiB    0.000 MiB           add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                             
   348  362.324 MiB    0.000 MiB           eta2B_2b2b_A = add3
   349                             
   350  362.324 MiB    0.000 MiB           eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                     
   352  496.699 MiB  134.375 MiB           eta1B_e = eta1B.eval()
   353  365.508 MiB    0.000 MiB           eta2B_e = eta2B.eval()
   354                                     
   355  365.508 MiB    0.000 MiB       tf.reset_default_graph()
   356                                 
   357  365.508 MiB    0.000 MiB       return (eta1B_e, eta2B_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   364  365.508 MiB  365.508 MiB   @profile
   365                             def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                 
   367  365.508 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   368  365.508 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   369  365.508 MiB    0.000 MiB       eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370  365.508 MiB    0.000 MiB       eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371  365.508 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372  365.508 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373  365.508 MiB    0.000 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374  365.508 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375  429.512 MiB   64.004 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376  429.512 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                 
   378  429.512 MiB    0.000 MiB       with tf.Session() as sess:
   379                                     
   380                                     # --- 0B piece
   381                             
   382                                     # Calculate 1B-1B contribution (full contraction)
   383  429.512 MiB    0.000 MiB           occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384  429.512 MiB    0.000 MiB           occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385  429.512 MiB    0.000 MiB           dE_1b1b = tf.identity(occA_e1_f)
   386                             
   387                                     # Calculate 2B-2B contribution (full contraction)
   388                                 #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389  429.512 MiB    0.000 MiB           e2_occD = tf.matmul(eta2B, occD_t)
   390  429.512 MiB    0.000 MiB           e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391  429.512 MiB    0.000 MiB           dE_2b2b = tf.identity(e2_occD_G)
   392                             
   393  429.512 MiB    0.000 MiB           dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                             
   395                                     # --- 1B piece
   396                             
   397                                     # Calculate 1B-1B contribution (contraction over 1 index)
   398  429.512 MiB    0.000 MiB           e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399  429.512 MiB    0.000 MiB           e1_f_T = tf.transpose(e1_f)
   400  429.512 MiB    0.000 MiB           e1_f_add = tf.add(e1_f,e1_f_T)
   401  429.512 MiB    0.000 MiB           df_1b1b = tf.identity(e1_f_add)
   402                             
   403                                     # Calculate 1B-2B contribution (contraction over 2 indices)
   404  429.512 MiB    0.000 MiB           occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405  429.512 MiB    0.000 MiB           occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406  429.512 MiB    0.000 MiB           sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407  429.512 MiB    0.000 MiB           df_1b2b = tf.identity(sub_1b2b)
   408                             
   409                                     # Calculate 2B-2B contribution (contraction over 3 indices)
   410  429.512 MiB    0.000 MiB           e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411  429.754 MiB    0.242 MiB           e2_occC_G_T = tf.transpose(e2_occC_G)
   412  429.754 MiB    0.000 MiB           add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413  429.754 MiB    0.000 MiB           df_2b2b = tf.identity(add_2b2b)
   414                             
   415  429.754 MiB    0.000 MiB           df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                             
   417                                     # --- 2B piece
   418                             
   419                                     # Calculate 1B-2B contribution (contraction over 1 index)
   420  429.754 MiB    0.000 MiB           e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421  429.754 MiB    0.000 MiB           e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422  429.754 MiB    0.000 MiB           ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                             
   424  430.004 MiB    0.250 MiB           e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425  430.004 MiB    0.000 MiB           e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426  430.004 MiB    0.000 MiB           e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427  430.004 MiB    0.000 MiB           kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                             
   429  430.004 MiB    0.000 MiB           dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                             
   431                                     # Calculate 2B-2B contribution (occB term)
   432  430.004 MiB    0.000 MiB           e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433  430.258 MiB    0.254 MiB           G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434  430.258 MiB    0.000 MiB           sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                             
   436  430.258 MiB    0.000 MiB           dG_2b2b_B = tf.identity(sub_term)
   437                             
   438                                     # Calculate 2B-2B contribution (occA term)
   439  430.258 MiB    0.000 MiB           e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440  430.258 MiB    0.000 MiB           e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441  430.258 MiB    0.000 MiB           e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442  430.258 MiB    0.000 MiB           e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443  430.258 MiB    0.000 MiB           e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444  430.258 MiB    0.000 MiB           e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445  430.258 MiB    0.000 MiB           sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446  430.258 MiB    0.000 MiB           sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447  430.258 MiB    0.000 MiB           add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                             
   449  430.258 MiB    0.000 MiB           dG_2b2b_A = tf.identity(add3)
   450                             
   451  430.258 MiB    0.000 MiB           dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                     
   453  565.043 MiB  134.785 MiB           dE_e = dE.eval()
   454  564.465 MiB    0.000 MiB           df_e = df.eval()
   455  434.902 MiB    0.000 MiB           dG_e = dG.eval()
   456                                 
   457  434.902 MiB    0.000 MiB       tf.reset_default_graph()
   458                                 
   459  434.902 MiB    0.000 MiB       return (dE_e, df_e, dG_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   466  296.348 MiB  296.348 MiB   @profile
   467                             def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                 
   469  296.348 MiB  296.348 MiB       E, f, G = ravel(y, holes, particles)
   470                             
   471  365.508 MiB  365.508 MiB       eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                 
   473  434.902 MiB  434.902 MiB       dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                 
   475  434.902 MiB  434.902 MiB       dy = unravel(dE, df, dG)
   476                                 
   477  434.902 MiB    0.000 MiB       return dy


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   485  434.902 MiB  434.902 MiB   @profile
   486                             def unravel(E, f, G):
   487  434.902 MiB    0.000 MiB       unravel_E = np.reshape(E, -1)
   488  434.902 MiB    0.000 MiB       unravel_f = np.reshape(f, -1)
   489  434.902 MiB    0.000 MiB       unravel_G = np.reshape(G, -1)
   490                                 
   491  434.902 MiB    0.000 MiB       return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   493  427.586 MiB  427.586 MiB   @profile
   494                             def ravel(y, holes, particles):
   495                                 
   496  427.586 MiB    0.000 MiB       bas_len = len(np.append(holes,particles))
   497                                 
   498  427.586 MiB    0.000 MiB       ravel_E = np.reshape(y[0], ())
   499  427.586 MiB    0.000 MiB       ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500  427.586 MiB    0.000 MiB       ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501  427.586 MiB    0.000 MiB                            (bas_len, bas_len, bas_len, bas_len))
   502                                 
   503  427.586 MiB    0.000 MiB       return(ravel_E, ravel_f, ravel_G)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   522  259.543 MiB  259.543 MiB   @profile
   523                             def run(n_holes):
   524  259.543 MiB  259.543 MiB       H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                             
   526  259.984 MiB  259.984 MiB       occA = get_occA(B1, ref)
   527  260.500 MiB  260.500 MiB       occB = get_occB(B1, ref)
   528  276.484 MiB  276.484 MiB       occC = get_occC(B1, ref)
   529  277.000 MiB  277.000 MiB       occD = get_occD(B1, ref)
   530                                 
   531  296.348 MiB  296.348 MiB       E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                             
   533                                 
   534  296.348 MiB  296.348 MiB       y0 = unravel(E, f, G)
   535                             
   536  296.348 MiB    0.000 MiB       t = 1
   537  427.586 MiB  427.586 MiB       dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                             
   539  427.586 MiB  427.586 MiB       dE, df, dG = ravel(dy, holes, particles)
   540  427.586 MiB    0.000 MiB       print(dE)


---------------------------------------------\n

Executing TF on n_holes=10 ---------------------------
2019-06-20 15:04:19.522335: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 15:04:19.545808: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 15:04:19.546219: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ea5df8c2a0 executing computations on platform Host. Devices:
2019-06-20 15:04:19.546269: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-06-20 15:04:22.976841: W tensorflow/core/framework/allocator.cc:124] Allocation of 256000000 exceeds 10% of system memory.
2019-06-20 15:04:23.399721: W tensorflow/core/framework/allocator.cc:124] Allocation of 256000000 exceeds 10% of system memory.
2019-06-20 15:04:23.399797: W tensorflow/core/framework/allocator.cc:124] Allocation of 256000000 exceeds 10% of system memory.
2019-06-20 15:04:23.548171: W tensorflow/core/framework/allocator.cc:124] Allocation of 256000000 exceeds 10% of system memory.
2019-06-20 15:04:25.302236: W tensorflow/core/framework/allocator.cc:124] Allocation of 256000000 exceeds 10% of system memory.
1.13.1
-25.0
Wrote profile results to testing_tensorflow_v2_bench.py.lprof
Timer unit: 1e-06 s

Total time: 2.34874 s
File: testing_tensorflow_v2_bench.py
Function: build_hamiltonian at line 22

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    22                                           @profile
    23                                           def build_hamiltonian(n_hole_states, n_particle_states):
    24         1          1.0      1.0      0.0      numh = n_hole_states
    25         1          1.0      1.0      0.0      nump = n_particle_states
    26         1          0.0      0.0      0.0      nums = numh + nump
    27                                               
    28         1         76.0     76.0      0.0      ref = np.append(np.ones(numh), np.zeros(nump))
    29         1         12.0     12.0      0.0      holes = np.arange(numh)
    30         1          2.0      2.0      0.0      particles = np.arange(numh,numh+nump)
    31         1          8.0      8.0      0.0      B1 = np.append(holes,particles)
    32                                               
    33                                               # one body part of Hamiltonian is floor-division of basis index
    34                                               # matrix elements are (P-1) where P is energy level
    35         1         45.0     45.0      0.0      H1B = np.diag(np.floor_divide(B1,2))
    36                                           
    37         1         17.0     17.0      0.0      H2B = np.zeros((nums, nums, nums, nums))
    38        21         19.0      0.9      0.0      for p in B1:
    39       420        330.0      0.8      0.0          for q in B1:
    40      8400       6208.0      0.7      0.3              for r in B1:
    41    168000     117314.0      0.7      5.0                  for s in B1:
    42                                           
    43    160000     379283.0      2.4     16.1                      pp = np.floor_divide(p,2)
    44    160000     373593.0      2.3     15.9                      qp = np.floor_divide(q,2)
    45    160000     367803.0      2.3     15.7                      rp = np.floor_divide(r,2)
    46    160000     366673.0      2.3     15.6                      sp = np.floor_divide(s,2)
    47                                           
    48    160000     168288.0      1.1      7.2                      ps = 1 if p%2==0 else -1
    49    160000     153030.0      1.0      6.5                      qs = 1 if q%2==0 else -1
    50    160000     153536.0      1.0      6.5                      rs = 1 if r%2==0 else -1
    51    160000     151549.0      0.9      6.5                      ss = 1 if s%2==0 else -1
    52                                           
    53    160000     100005.0      0.6      4.3                      if pp != qp or rp != sp:
    54     14400       8469.0      0.6      0.4                          continue
    55      1600       1070.0      0.7      0.0                      if ps == qs or rs == ss:
    56       400        217.0      0.5      0.0                          continue
    57       400        259.0      0.6      0.0                      if ps == rs and qs == ss:
    58       200        353.0      1.8      0.0                          H2B[p,q,r,s] = -0.25
    59       400        263.0      0.7      0.0                      if ps == ss and qs == rs:
    60       200        315.0      1.6      0.0                          H2B[p,q,r,s] = 0.25
    61                                                                   
    62         1          1.0      1.0      0.0      return (H1B, H2B, ref, holes, particles, B1)

Total time: 0.001084 s
File: testing_tensorflow_v2_bench.py
Function: get_occA at line 65

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    65                                           @profile
    66                                           def get_occA(B1_basis, ref):
    67         1          2.0      2.0      0.2      n = len(B1_basis)
    68         1         73.0     73.0      6.7      occA = np.zeros((n,n,n,n))
    69                                               
    70        21         11.0      0.5      1.0      for a in B1_basis:
    71       420        225.0      0.5     20.8          for b in B1_basis:
    72       400        772.0      1.9     71.2              occA[a,b,a,b] = ref[a] - ref[b]
    73                                                       
    74         1          1.0      1.0      0.1      return occA

Total time: 0.000969 s
File: testing_tensorflow_v2_bench.py
Function: get_occB at line 77

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    77                                           @profile
    78                                           def get_occB(B1_basis, ref):
    79         1          1.0      1.0      0.1      n = len(B1_basis)    
    80         1         55.0     55.0      5.7      occB = np.zeros((n,n,n,n))
    81                                               
    82        21          9.0      0.4      0.9      for a in B1_basis:
    83       420        175.0      0.4     18.1          for b in B1_basis:
    84       400        728.0      1.8     75.1              occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                                       
    86         1          1.0      1.0      0.1      return occB

Total time: 0.027744 s
File: testing_tensorflow_v2_bench.py
Function: get_occC at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                           @profile
    90                                           def get_occC(B1_basis, ref):
    91         1          1.0      1.0      0.0      n = len(B1_basis)        
    92         1         10.0     10.0      0.0      occC = np.zeros((n,n,n,n,n,n))
    93                                               
    94        21         11.0      0.5      0.0      for a in B1_basis:
    95       420        181.0      0.4      0.7          for b in B1_basis:
    96      8400       3645.0      0.4     13.1              for c in B1_basis:
    97      8000      23895.0      3.0     86.1                  occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                                           
    99         1          1.0      1.0      0.0      return occC

Total time: 0.402002 s
File: testing_tensorflow_v2_bench.py
Function: get_occD at line 102

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   102                                           @profile
   103                                           def get_occD(B1_basis, ref):
   104         1          2.0      2.0      0.0      n = len(B1_basis)    
   105         1         74.0     74.0      0.0      occD = np.zeros((n,n,n,n))
   106                                               
   107        21          9.0      0.4      0.0      for a in B1_basis:
   108       420        195.0      0.5      0.0          for b in B1_basis:
   109      8400       3746.0      0.4      0.9              for c in B1_basis:
   110    168000      68176.0      0.4     17.0                  for d in B1_basis:
   111    160000     329800.0      2.1     82.0                      occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                               
   113         1          0.0      0.0      0.0      return occD

Total time: 0.42269 s
File: testing_tensorflow_v2_bench.py
Function: normal_order at line 126

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   126                                           @profile
   127                                           def normal_order(H1B_t, H2B_t, holes):
   128                                               
   129         1      10081.0  10081.0      2.4      H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130         1       2487.0   2487.0      0.6      H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131         1       1032.0   1032.0      0.2      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                               
   133                                               # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134         1      24663.0  24663.0      5.8      with tf.Session() as sess:
   135                                                   
   136                                                   # - Calculate 0B tensor
   137                                                   # E = tf.Variable(0.0)
   138         1     111330.0 111330.0     26.3          contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139         1      90693.0  90693.0     21.5          contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                                           
   141         1       2457.0   2457.0      0.6          E_1b = tf.reduce_sum(contr_1b, 0)
   142         1       4627.0   4627.0      1.1          E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143         1       1292.0   1292.0      0.3          E = tf.add_n([E_1b, E_2b])
   144                                           
   145                                                   # - Calculate 1B tensor
   146         1      90939.0  90939.0     21.5          contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147         1       2503.0   2503.0      0.6          contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                                           
   149         1       1282.0   1282.0      0.3          f = tf.add_n([H1B_t, contr_2b])
   150                                           
   151                                                   # - Calculate 2B tensor
   152         1       1041.0   1041.0      0.2          G = tf.identity(H2B_t)
   153                                                   
   154         1      78245.0  78245.0     18.5          E_e, f_e, G_e = sess.run([E, f, G])
   155                                           #         E_e = E.eval()
   156                                           #         f_e = f.eval()
   157                                           #         G_e = G.eval()
   158                                                   
   159                                           #         print(sess.run([E, f, G]))
   160                                                   
   161         1         16.0     16.0      0.0      tf.reset_default_graph()
   162                                               
   163         1          2.0      2.0      0.0      return (E_e, f_e, G_e)

Total time: 20.008 s
File: testing_tensorflow_v2_bench.py
Function: wegner at line 236

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                           @profile
   237                                           def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                               
   239         1       1230.0   1230.0      0.0      f = tf.convert_to_tensor(f, dtype=tf.float32)
   240         1       1559.0   1559.0      0.0      G = tf.convert_to_tensor(G, dtype=tf.float32)
   241         1        946.0    946.0      0.0      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242         1        795.0    795.0      0.0      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243         1       1606.0   1606.0      0.0      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244         1       1769.0   1769.0      0.0      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245         1    1304156.0 1304156.0      6.5      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246         1       2058.0   2058.0      0.0      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                               
   248         1        234.0    234.0      0.0      with tf.Session() as sess:
   249         1       1304.0   1304.0      0.0          plen = tf.size(particles)
   250         1       1010.0   1010.0      0.0          hlen = tf.size(holes)
   251                                           
   252                                                   # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                                   
   254                                                   # Decoupling 1B piece
   255                                                   # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256         1       3304.0   3304.0      0.0          particles_b = tf.broadcast_to(particles, [plen,plen])
   257         1       3137.0   3137.0      0.0          holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258         1       2656.0   2656.0      0.0          ph_comb = tf.concat([particles_b, holes_b], 0)
   259         1       4815.0   4815.0      0.0          hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                                   
   261         1       2218.0   2218.0      0.0          col_indices =tf.reshape(ph_comb, [-1])
   262         1       2223.0   2223.0      0.0          row_indices = tf.reshape(hp_comb, [-1])
   263         1       1444.0   1444.0      0.0          ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264         1       1337.0   1337.0      0.0          ph_updates = tf.gather_nd(f, ph_indices)
   265                                           
   266         1       2576.0   2576.0      0.0          fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267         1       1409.0   1409.0      0.0          fd = tf.subtract(f,fod)
   268                                           
   269                                                   # Decoupling 2B piece
   270                                                   # indices are constructed by all possible combinations of pphh(hhpp) states
   271         1      13648.0  13648.0      0.1          ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272         1       2514.0   2514.0      0.0          ind1_TC = tf.transpose(ind1_C) 
   273         1       2286.0   2286.0      0.0          ind1 = tf.reshape(ind1_TC,[-1])
   274                                           
   275         1      18217.0  18217.0      0.1          ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276         1       2336.0   2336.0      0.0          ind2_TC = tf.transpose(ind2_C)
   277         1       2185.0   2185.0      0.0          ind2 = tf.reshape(ind2_TC,[-1])
   278                                           
   279         1      13436.0  13436.0      0.1          ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280         1       2366.0   2366.0      0.0          ind3_TC = tf.transpose(ind3_C) 
   281         1       2174.0   2174.0      0.0          ind3 = tf.reshape(ind3_TC,[-1])
   282                                           
   283         1      15153.0  15153.0      0.1          ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284         1       2382.0   2382.0      0.0          ind4_TC = tf.transpose(ind4_C)
   285         1       2336.0   2336.0      0.0          ind4 = tf.reshape(ind4_TC,[-1])
   286                                           
   287         1       1584.0   1584.0      0.0          pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288         1       1366.0   1366.0      0.0          pphh_updates = tf.gather_nd(G, pphh_indices)
   289                                           
   290         1       2511.0   2511.0      0.0          God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291         1       1208.0   1208.0      0.0          Gd = tf.subtract(G,God)
   292                                           
   293                                           
   294                                                   # --- 1B piece
   295                                           
   296                                                   # Calculate 1B-1B contribution
   297         1      13408.0  13408.0      0.1          fd_fod = tf.tensordot(fd,fod,1)
   298         1       2530.0   2530.0      0.0          fd_fod_T = tf.transpose(fd_fod)
   299         1       1210.0   1210.0      0.0          eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                                           
   301                                                   # Calculate 1B-2B contribution
   302         1      27156.0  27156.0      0.1          fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303         1      26251.0  26251.0      0.1          fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304         1       1187.0   1187.0      0.0          eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                                           
   306                                                   # Calculate 2B-2B contribution
   307         1      25659.0  25659.0      0.1          Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308         1       2304.0   2304.0      0.0          Gd_God_T = tf.transpose(Gd_God)
   309         1       3223.0   3223.0      0.0          scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310         1          1.0      1.0      0.0          eta1B_2b2b = scaled_sub
   311                                           
   312         1       1339.0   1339.0      0.0          eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                                           
   314                                           
   315                                           
   316                                                   # --- 2B piece
   317                                           
   318                                                   # Calculate 1B-2B contribution
   319         1      27698.0  27698.0      0.1          fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320         1       2316.0   2316.0      0.0          fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321         1       1205.0   1205.0      0.0          ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                                           
   323         1      27399.0  27399.0      0.1          fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324         1       2223.0   2223.0      0.0          fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325         1       2197.0   2197.0      0.0          fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326         1       1151.0   1151.0      0.0          kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                                           
   328         1       1209.0   1209.0      0.0          eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                                           
   330                                           
   331                                                   # Calculate 2B-2B contribution
   332         1      25601.0  25601.0      0.1          GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333         1      25646.0  25646.0      0.1          GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334         1       3253.0   3253.0      0.0          scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                                           
   336         1          2.0      2.0      0.0          eta2B_2b2b_B = scaled_sub
   337                                           
   338         1      12725.0  12725.0      0.1          GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339         1       2233.0   2233.0      0.0          GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340         1      12815.0  12815.0      0.1          GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341         1       2195.0   2195.0      0.0          GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342         1       2160.0   2160.0      0.0          GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343         1       2286.0   2286.0      0.0          GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344         1       1373.0   1373.0      0.0          sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345         1       1188.0   1188.0      0.0          sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346         1       1164.0   1164.0      0.0          add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                                           
   348         1          2.0      2.0      0.0          eta2B_2b2b_A = add3
   349                                           
   350         1       1429.0   1429.0      0.0          eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                                   
   352         1   17749293.0 17749293.0     88.7          eta1B_e = eta1B.eval()
   353         1     567491.0 567491.0      2.8          eta2B_e = eta2B.eval()
   354                                                   
   355         1         21.0     21.0      0.0      tf.reset_default_graph()
   356                                               
   357         1          2.0      2.0      0.0      return (eta1B_e, eta2B_e)

Total time: 16.0657 s
File: testing_tensorflow_v2_bench.py
Function: flow at line 364

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   364                                           @profile
   365                                           def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                               
   367         1       1473.0   1473.0      0.0      f = tf.convert_to_tensor(f, dtype=tf.float32)
   368         1       1624.0   1624.0      0.0      G = tf.convert_to_tensor(G, dtype=tf.float32)
   369         1        980.0    980.0      0.0      eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370         1       1519.0   1519.0      0.0      eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371         1        977.0    977.0      0.0      holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372         1        844.0    844.0      0.0      particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373         1       1646.0   1646.0      0.0      occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374         1       2196.0   2196.0      0.0      occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375         1    1280973.0 1280973.0      8.0      occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376         1       2039.0   2039.0      0.0      occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                               
   378         1        215.0    215.0      0.0      with tf.Session() as sess:
   379                                                   
   380                                                   # --- 0B piece
   381                                           
   382                                                   # Calculate 1B-1B contribution (full contraction)
   383         1      14168.0  14168.0      0.1          occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384         1      13453.0  13453.0      0.1          occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385         1       1063.0   1063.0      0.0          dE_1b1b = tf.identity(occA_e1_f)
   386                                           
   387                                                   # Calculate 2B-2B contribution (full contraction)
   388                                               #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389         1       1602.0   1602.0      0.0          e2_occD = tf.matmul(eta2B, occD_t)
   390         1      15789.0  15789.0      0.1          e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391         1       1130.0   1130.0      0.0          dE_2b2b = tf.identity(e2_occD_G)
   392                                           
   393         1       1360.0   1360.0      0.0          dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                                           
   395                                                   # --- 1B piece
   396                                           
   397                                                   # Calculate 1B-1B contribution (contraction over 1 index)
   398         1      13055.0  13055.0      0.1          e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399         1       2319.0   2319.0      0.0          e1_f_T = tf.transpose(e1_f)
   400         1       1165.0   1165.0      0.0          e1_f_add = tf.add(e1_f,e1_f_T)
   401         1       1054.0   1054.0      0.0          df_1b1b = tf.identity(e1_f_add)
   402                                           
   403                                                   # Calculate 1B-2B contribution (contraction over 2 indices)
   404         1      26084.0  26084.0      0.2          occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405         1      25198.0  25198.0      0.2          occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406         1       1168.0   1168.0      0.0          sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407         1       1039.0   1039.0      0.0          df_1b2b = tf.identity(sub_1b2b)
   408                                           
   409                                                   # Calculate 2B-2B contribution (contraction over 3 indices)
   410         1      26445.0  26445.0      0.2          e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411         1       2248.0   2248.0      0.0          e2_occC_G_T = tf.transpose(e2_occC_G)
   412         1       3201.0   3201.0      0.0          add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413         1       1029.0   1029.0      0.0          df_2b2b = tf.identity(add_2b2b)
   414                                           
   415         1       1434.0   1434.0      0.0          df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                                           
   417                                                   # --- 2B piece
   418                                           
   419                                                   # Calculate 1B-2B contribution (contraction over 1 index)
   420         1     100270.0 100270.0      0.6          e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421         1       2470.0   2470.0      0.0          e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422         1       1318.0   1318.0      0.0          ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                                           
   424         1      27912.0  27912.0      0.2          e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425         1       2416.0   2416.0      0.0          e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426         1       2320.0   2320.0      0.0          e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427         1       1211.0   1211.0      0.0          kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                                           
   429         1       2262.0   2262.0      0.0          dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                                           
   431                                                   # Calculate 2B-2B contribution (occB term)
   432         1      26093.0  26093.0      0.2          e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433         1      26216.0  26216.0      0.2          G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434         1       3281.0   3281.0      0.0          sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                                           
   436         1       1034.0   1034.0      0.0          dG_2b2b_B = tf.identity(sub_term)
   437                                           
   438                                                   # Calculate 2B-2B contribution (occA term)
   439         1      12819.0  12819.0      0.1          e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440         1       2201.0   2201.0      0.0          e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441         1      16821.0  16821.0      0.1          e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442         1       2429.0   2429.0      0.0          e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443         1       2309.0   2309.0      0.0          e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444         1       2399.0   2399.0      0.0          e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445         1       1220.0   1220.0      0.0          sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446         1       1466.0   1466.0      0.0          sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447         1       1314.0   1314.0      0.0          add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                                           
   449         1       1091.0   1091.0      0.0          dG_2b2b_A = tf.identity(add3)
   450                                           
   451         1       1393.0   1393.0      0.0          dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                                   
   453         1     888490.0 888490.0      5.5          dE_e = dE.eval()
   454         1   12947683.0 12947683.0     80.6          df_e = df.eval()
   455         1     538779.0 538779.0      3.4          dG_e = dG.eval()
   456                                               
   457         1         39.0     39.0      0.0      tf.reset_default_graph()
   458                                               
   459         1          2.0      2.0      0.0      return (dE_e, df_e, dG_e)

Total time: 36.0833 s
File: testing_tensorflow_v2_bench.py
Function: derivative at line 466

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   466                                           @profile
   467                                           def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                               
   469         1         49.0     49.0      0.0      E, f, G = ravel(y, holes, particles)
   470                                           
   471         1   20008376.0 20008376.0     55.5      eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                               
   473         1   16065996.0 16065996.0     44.5      dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                               
   475         1       8924.0   8924.0      0.0      dy = unravel(dE, df, dG)
   476                                               
   477         1          2.0      2.0      0.0      return dy

Total time: 0.009124 s
File: testing_tensorflow_v2_bench.py
Function: unravel at line 485

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   485                                           @profile
   486                                           def unravel(E, f, G):
   487         2       8617.0   4308.5     94.4      unravel_E = np.reshape(E, -1)
   488         2         23.0     11.5      0.3      unravel_f = np.reshape(f, -1)
   489         2          7.0      3.5      0.1      unravel_G = np.reshape(G, -1)
   490                                               
   491         2        477.0    238.5      5.2      return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)

Total time: 0.000114 s
File: testing_tensorflow_v2_bench.py
Function: ravel at line 493

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   493                                           @profile
   494                                           def ravel(y, holes, particles):
   495                                               
   496         2         70.0     35.0     61.4      bas_len = len(np.append(holes,particles))
   497                                               
   498         2         21.0     10.5     18.4      ravel_E = np.reshape(y[0], ())
   499         2         12.0      6.0     10.5      ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500         2          4.0      2.0      3.5      ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501         2          6.0      3.0      5.3                           (bas_len, bas_len, bas_len, bas_len))
   502                                               
   503         2          1.0      0.5      0.9      return(ravel_E, ravel_f, ravel_G)

Total time: 40.4787 s
File: testing_tensorflow_v2_bench.py
Function: run at line 522

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   522                                           @profile
   523                                           def run(n_holes):
   524         1    3433969.0 3433969.0      8.5      H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                                           
   526         1       1375.0   1375.0      0.0      occA = get_occA(B1, ref)
   527         1       1201.0   1201.0      0.0      occB = get_occB(B1, ref)
   528         1      32704.0  32704.0      0.1      occC = get_occC(B1, ref)
   529         1     502433.0 502433.0      1.2      occD = get_occD(B1, ref)
   530                                               
   531         1     422762.0 422762.0      1.0      E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                                           
   533                                               
   534         1        232.0    232.0      0.0      y0 = unravel(E, f, G)
   535                                           
   536         1          0.0      0.0      0.0      t = 1
   537         1   36083938.0 36083938.0     89.1      dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                                           
   539         1         89.0     89.0      0.0      dE, df, dG = ravel(dy, holes, particles)
   540         1         21.0     21.0      0.0      print(dE)

2019-06-20 15:07:31.036105: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 15:07:31.057579: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-06-20 15:07:31.058106: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55bfff37afa0 executing computations on platform Host. Devices:
2019-06-20 15:07:31.058146: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
1.13.1
-25.0
Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    22  258.145 MiB  258.145 MiB   @profile
    23                             def build_hamiltonian(n_hole_states, n_particle_states):
    24  258.145 MiB    0.000 MiB       numh = n_hole_states
    25  258.145 MiB    0.000 MiB       nump = n_particle_states
    26  258.145 MiB    0.000 MiB       nums = numh + nump
    27                                 
    28  258.145 MiB    0.000 MiB       ref = np.append(np.ones(numh), np.zeros(nump))
    29  258.145 MiB    0.000 MiB       holes = np.arange(numh)
    30  258.145 MiB    0.000 MiB       particles = np.arange(numh,numh+nump)
    31  258.145 MiB    0.000 MiB       B1 = np.append(holes,particles)
    32                                 
    33                                 # one body part of Hamiltonian is floor-division of basis index
    34                                 # matrix elements are (P-1) where P is energy level
    35  258.145 MiB    0.000 MiB       H1B = np.diag(np.floor_divide(B1,2))
    36                             
    37  258.145 MiB    0.000 MiB       H2B = np.zeros((nums, nums, nums, nums))
    38  258.387 MiB    0.000 MiB       for p in B1:
    39  258.387 MiB    0.000 MiB           for q in B1:
    40  258.387 MiB    0.000 MiB               for r in B1:
    41  258.387 MiB    0.000 MiB                   for s in B1:
    42                             
    43  258.387 MiB    0.000 MiB                       pp = np.floor_divide(p,2)
    44  258.387 MiB    0.000 MiB                       qp = np.floor_divide(q,2)
    45  258.387 MiB    0.000 MiB                       rp = np.floor_divide(r,2)
    46  258.387 MiB    0.000 MiB                       sp = np.floor_divide(s,2)
    47                             
    48  258.387 MiB    0.000 MiB                       ps = 1 if p%2==0 else -1
    49  258.387 MiB    0.000 MiB                       qs = 1 if q%2==0 else -1
    50  258.387 MiB    0.000 MiB                       rs = 1 if r%2==0 else -1
    51  258.387 MiB    0.000 MiB                       ss = 1 if s%2==0 else -1
    52                             
    53  258.387 MiB    0.000 MiB                       if pp != qp or rp != sp:
    54  258.387 MiB    0.000 MiB                           continue
    55  258.387 MiB    0.000 MiB                       if ps == qs or rs == ss:
    56  258.387 MiB    0.000 MiB                           continue
    57  258.387 MiB    0.000 MiB                       if ps == rs and qs == ss:
    58  258.387 MiB    0.242 MiB                           H2B[p,q,r,s] = -0.25
    59  258.387 MiB    0.000 MiB                       if ps == ss and qs == rs:
    60  258.387 MiB    0.000 MiB                           H2B[p,q,r,s] = 0.25
    61                                                     
    62  258.387 MiB    0.000 MiB       return (H1B, H2B, ref, holes, particles, B1)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    65  258.387 MiB  258.387 MiB   @profile
    66                             def get_occA(B1_basis, ref):
    67  258.387 MiB    0.000 MiB       n = len(B1_basis)
    68  258.387 MiB    0.000 MiB       occA = np.zeros((n,n,n,n))
    69                                 
    70  259.414 MiB    0.000 MiB       for a in B1_basis:
    71  259.414 MiB    0.000 MiB           for b in B1_basis:
    72  259.414 MiB    0.258 MiB               occA[a,b,a,b] = ref[a] - ref[b]
    73                                         
    74  259.414 MiB    0.000 MiB       return occA


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    77  259.414 MiB  259.414 MiB   @profile
    78                             def get_occB(B1_basis, ref):
    79  259.414 MiB    0.000 MiB       n = len(B1_basis)    
    80  259.672 MiB    0.258 MiB       occB = np.zeros((n,n,n,n))
    81                                 
    82  260.703 MiB    0.000 MiB       for a in B1_basis:
    83  260.703 MiB    0.000 MiB           for b in B1_basis:
    84  260.703 MiB    0.258 MiB               occB[a,b,a,b] = 1 - ref[a] - ref[b]
    85                                         
    86  260.703 MiB    0.000 MiB       return occB


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
    89  260.703 MiB  260.703 MiB   @profile
    90                             def get_occC(B1_basis, ref):
    91  260.703 MiB    0.000 MiB       n = len(B1_basis)        
    92  260.703 MiB    0.000 MiB       occC = np.zeros((n,n,n,n,n,n))
    93                                 
    94  291.898 MiB    0.000 MiB       for a in B1_basis:
    95  291.898 MiB    0.000 MiB           for b in B1_basis:
    96  291.898 MiB    0.000 MiB               for c in B1_basis:
    97  291.898 MiB    0.258 MiB                   occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]
    98                                             
    99  291.898 MiB    0.000 MiB       return occC


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   102  291.898 MiB  291.898 MiB   @profile
   103                             def get_occD(B1_basis, ref):
   104  291.898 MiB    0.000 MiB       n = len(B1_basis)    
   105  292.156 MiB    0.258 MiB       occD = np.zeros((n,n,n,n))
   106                                 
   107  293.188 MiB    0.000 MiB       for a in B1_basis:
   108  293.188 MiB    0.000 MiB           for b in B1_basis:
   109  293.188 MiB    0.000 MiB               for c in B1_basis:
   110  293.188 MiB    0.000 MiB                   for d in B1_basis:
   111  293.188 MiB    0.258 MiB                       occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]
   112                                                 
   113  293.188 MiB    0.000 MiB       return occD


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   126  293.188 MiB  293.188 MiB   @profile
   127                             def normal_order(H1B_t, H2B_t, holes):
   128                                 
   129  295.516 MiB    2.328 MiB       H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32, name='a')
   130  298.129 MiB    2.613 MiB       H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32, name='b')
   131  298.129 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   132                                 
   133                                 # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
   134  299.832 MiB    1.703 MiB       with tf.Session() as sess:
   135                                     
   136                                     # - Calculate 0B tensor
   137                                     # E = tf.Variable(0.0)
   138  302.129 MiB    2.141 MiB           contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)
   139  302.367 MiB    0.238 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)
   140                             
   141  302.367 MiB    0.000 MiB           E_1b = tf.reduce_sum(contr_1b, 0)
   142  302.367 MiB    0.000 MiB           E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])
   143  302.367 MiB    0.000 MiB           E = tf.add_n([E_1b, E_2b])
   144                             
   145                                     # - Calculate 1B tensor
   146  302.840 MiB    0.258 MiB           contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)
   147  302.840 MiB    0.000 MiB           contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes
   148                             
   149  302.840 MiB    0.000 MiB           f = tf.add_n([H1B_t, contr_2b])
   150                             
   151                                     # - Calculate 2B tensor
   152  302.840 MiB    0.000 MiB           G = tf.identity(H2B_t)
   153                                     
   154  314.984 MiB   12.145 MiB           E_e, f_e, G_e = sess.run([E, f, G])
   155                             #         E_e = E.eval()
   156                             #         f_e = f.eval()
   157                             #         G_e = G.eval()
   158                                     
   159                             #         print(sess.run([E, f, G]))
   160                                     
   161  314.984 MiB    0.000 MiB       tf.reset_default_graph()
   162                                 
   163  314.984 MiB    0.000 MiB       return (E_e, f_e, G_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   236  314.984 MiB  314.984 MiB   @profile
   237                             def wegner(f, G, holes, particles, occA, occB, occC, occD):
   238                                 
   239  314.984 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   240  314.984 MiB    0.000 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   241  314.984 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   242  314.984 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   243  314.984 MiB    0.000 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   244  314.984 MiB    0.000 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   245  559.160 MiB  244.176 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   246  559.160 MiB    0.000 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   247                                 
   248  559.160 MiB    0.000 MiB       with tf.Session() as sess:
   249  559.160 MiB    0.000 MiB           plen = tf.size(particles)
   250  559.160 MiB    0.000 MiB           hlen = tf.size(holes)
   251                             
   252                                     # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP
   253                                     
   254                                     # Decoupling 1B piece
   255                                     # indices are constructed by all possible combinations of particle-hole(hole-particle) states
   256  559.160 MiB    0.000 MiB           particles_b = tf.broadcast_to(particles, [plen,plen])
   257  559.160 MiB    0.000 MiB           holes_b = tf.broadcast_to(holes, [hlen, hlen])
   258  559.160 MiB    0.000 MiB           ph_comb = tf.concat([particles_b, holes_b], 0)
   259  559.160 MiB    0.000 MiB           hp_comb = tf.transpose(tf.concat([holes_b, particles_b], 1))
   260                                     
   261  559.160 MiB    0.000 MiB           col_indices =tf.reshape(ph_comb, [-1])
   262  559.160 MiB    0.000 MiB           row_indices = tf.reshape(hp_comb, [-1])
   263  559.160 MiB    0.000 MiB           ph_indices = tf.stack([row_indices, col_indices], axis=1)
   264  559.160 MiB    0.000 MiB           ph_updates = tf.gather_nd(f, ph_indices)
   265                             
   266  559.160 MiB    0.000 MiB           fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)
   267  559.160 MiB    0.000 MiB           fd = tf.subtract(f,fod)
   268                             
   269                                     # Decoupling 2B piece
   270                                     # indices are constructed by all possible combinations of pphh(hhpp) states
   271  559.492 MiB    0.332 MiB           ind1_C = tf.concat([tf.broadcast_to(holes,[hlen**3,hlen]), tf.broadcast_to(particles,[plen**3,plen])],1)
   272  559.492 MiB    0.000 MiB           ind1_TC = tf.transpose(ind1_C) 
   273  559.492 MiB    0.000 MiB           ind1 = tf.reshape(ind1_TC,[-1])
   274                             
   275  559.492 MiB    0.000 MiB           ind2_C = tf.concat([tf.broadcast_to(holes,[hlen**2,hlen**2]),tf.broadcast_to(particles,[plen**2,plen**2])],1)
   276  559.492 MiB    0.000 MiB           ind2_TC = tf.transpose(ind2_C)
   277  559.492 MiB    0.000 MiB           ind2 = tf.reshape(ind2_TC,[-1])
   278                             
   279  559.492 MiB    0.000 MiB           ind3_C = tf.concat([tf.broadcast_to(particles,[plen,plen**3]),tf.broadcast_to(holes,[hlen,hlen**3])],1)
   280  559.492 MiB    0.000 MiB           ind3_TC = tf.transpose(ind3_C) 
   281  559.492 MiB    0.000 MiB           ind3 = tf.reshape(ind3_TC,[-1])
   282                             
   283  559.492 MiB    0.000 MiB           ind4_C = tf.concat([tf.broadcast_to(particles,[1,plen**4]),tf.broadcast_to(holes,[1,plen**4])],1)
   284  559.492 MiB    0.000 MiB           ind4_TC = tf.transpose(ind4_C)
   285  559.492 MiB    0.000 MiB           ind4 = tf.reshape(ind4_TC,[-1])
   286                             
   287  559.492 MiB    0.000 MiB           pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)
   288  559.742 MiB    0.250 MiB           pphh_updates = tf.gather_nd(G, pphh_indices)
   289                             
   290  559.742 MiB    0.000 MiB           God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)
   291  559.742 MiB    0.000 MiB           Gd = tf.subtract(G,God)
   292                             
   293                             
   294                                     # --- 1B piece
   295                             
   296                                     # Calculate 1B-1B contribution
   297  559.742 MiB    0.000 MiB           fd_fod = tf.tensordot(fd,fod,1)
   298  559.742 MiB    0.000 MiB           fd_fod_T = tf.transpose(fd_fod)
   299  559.742 MiB    0.000 MiB           eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)
   300                             
   301                                     # Calculate 1B-2B contribution
   302  559.742 MiB    0.000 MiB           fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))
   303  559.965 MiB    0.223 MiB           fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))
   304  559.965 MiB    0.000 MiB           eta1B_1b2b = tf.subtract(fd_God, fod_Gd)
   305                             
   306                                     # Calculate 2B-2B contribution
   307  559.965 MiB    0.000 MiB           Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))
   308  559.965 MiB    0.000 MiB           Gd_God_T = tf.transpose(Gd_God)
   309  559.965 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(Gd_God,Gd_God_T)
   310  559.965 MiB    0.000 MiB           eta1B_2b2b = scaled_sub
   311                             
   312  559.965 MiB    0.000 MiB           eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])
   313                             
   314                             
   315                             
   316                                     # --- 2B piece
   317                             
   318                                     # Calculate 1B-2B contribution
   319  559.965 MiB    0.000 MiB           fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )
   320  559.965 MiB    0.000 MiB           fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])
   321  559.965 MiB    0.000 MiB           ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)
   322                             
   323  559.965 MiB    0.000 MiB           fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )
   324  559.965 MiB    0.000 MiB           fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order
   325  559.965 MiB    0.000 MiB           fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])
   326  559.965 MiB    0.000 MiB           kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)
   327                             
   328  559.965 MiB    0.000 MiB           eta2B_1b2b = tf.subtract(ij_term,kl_term)
   329                             
   330                             
   331                                     # Calculate 2B-2B contribution
   332  559.965 MiB    0.000 MiB           GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])
   333  559.965 MiB    0.000 MiB           GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])
   334  559.965 MiB    0.000 MiB           scaled_sub = 0.5*tf.subtract(GdGod_occB,GodGd_occB)
   335                             
   336  559.965 MiB    0.000 MiB           eta2B_2b2b_B = scaled_sub
   337                             
   338  559.965 MiB    0.000 MiB           GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])
   339  559.965 MiB    0.000 MiB           GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order
   340  559.965 MiB    0.000 MiB           GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])
   341  559.965 MiB    0.000 MiB           GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])
   342  559.965 MiB    0.000 MiB           GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])
   343  559.965 MiB    0.000 MiB           GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])
   344  559.965 MiB    0.000 MiB           sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)
   345  559.965 MiB    0.000 MiB           sub2 = tf.subtract(sub1,GdGod_occA_Tkl)
   346  559.965 MiB    0.000 MiB           add3 = tf.add(sub2,GdGod_occA_Tijkl)
   347                             
   348  559.965 MiB    0.000 MiB           eta2B_2b2b_A = add3
   349                             
   350  559.965 MiB    0.000 MiB           eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])
   351                                     
   352 1061.625 MiB  501.660 MiB           eta1B_e = eta1B.eval()
   353  559.055 MiB    0.000 MiB           eta2B_e = eta2B.eval()
   354                                     
   355  559.055 MiB    0.000 MiB       tf.reset_default_graph()
   356                                 
   357  559.055 MiB    0.000 MiB       return (eta1B_e, eta2B_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   364  559.055 MiB  559.055 MiB   @profile
   365                             def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):
   366                                 
   367  559.055 MiB    0.000 MiB       f = tf.convert_to_tensor(f, dtype=tf.float32)
   368  561.371 MiB    2.316 MiB       G = tf.convert_to_tensor(G, dtype=tf.float32)
   369  561.371 MiB    0.000 MiB       eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)
   370  561.887 MiB    0.516 MiB       eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)
   371  561.887 MiB    0.000 MiB       holes = tf.convert_to_tensor(holes, dtype=tf.int32)
   372  561.887 MiB    0.000 MiB       particles = tf.convert_to_tensor(particles, dtype=tf.int32)
   373  562.402 MiB    0.516 MiB       occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)
   374  563.176 MiB    0.773 MiB       occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)
   375  807.348 MiB  244.172 MiB       occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)
   376  807.859 MiB    0.512 MiB       occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)
   377                                 
   378  807.859 MiB    0.000 MiB       with tf.Session() as sess:
   379                                     
   380                                     # --- 0B piece
   381                             
   382                                     # Calculate 1B-1B contribution (full contraction)
   383  807.859 MiB    0.000 MiB           occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])
   384  807.859 MiB    0.000 MiB           occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])
   385  807.859 MiB    0.000 MiB           dE_1b1b = tf.identity(occA_e1_f)
   386                             
   387                                     # Calculate 2B-2B contribution (full contraction)
   388                                 #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])
   389  807.859 MiB    0.000 MiB           e2_occD = tf.matmul(eta2B, occD_t)
   390  807.859 MiB    0.000 MiB           e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])
   391  807.859 MiB    0.000 MiB           dE_2b2b = tf.identity(e2_occD_G)
   392                             
   393  807.859 MiB    0.000 MiB           dE = tf.add_n([dE_1b1b, dE_2b2b])
   394                             
   395                                     # --- 1B piece
   396                             
   397                                     # Calculate 1B-1B contribution (contraction over 1 index)
   398  807.859 MiB    0.000 MiB           e1_f = tf.tensordot(eta1B,f,[[1],[0]])
   399  807.859 MiB    0.000 MiB           e1_f_T = tf.transpose(e1_f)
   400  807.859 MiB    0.000 MiB           e1_f_add = tf.add(e1_f,e1_f_T)
   401  807.859 MiB    0.000 MiB           df_1b1b = tf.identity(e1_f_add)
   402                             
   403                                     # Calculate 1B-2B contribution (contraction over 2 indices)
   404  807.859 MiB    0.000 MiB           occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])
   405  807.859 MiB    0.000 MiB           occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])
   406  807.859 MiB    0.000 MiB           sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)
   407  807.859 MiB    0.000 MiB           df_1b2b = tf.identity(sub_1b2b)
   408                             
   409                                     # Calculate 2B-2B contribution (contraction over 3 indices)
   410  808.098 MiB    0.238 MiB           e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])
   411  808.098 MiB    0.000 MiB           e2_occC_G_T = tf.transpose(e2_occC_G)
   412  808.098 MiB    0.000 MiB           add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)
   413  808.098 MiB    0.000 MiB           df_2b2b = tf.identity(add_2b2b)
   414                             
   415  808.098 MiB    0.000 MiB           df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])
   416                             
   417                                     # --- 2B piece
   418                             
   419                                     # Calculate 1B-2B contribution (contraction over 1 index)
   420  808.098 MiB    0.000 MiB           e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))
   421  808.098 MiB    0.000 MiB           e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])
   422  808.355 MiB    0.258 MiB           ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)
   423                             
   424  808.355 MiB    0.000 MiB           e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))
   425  808.355 MiB    0.000 MiB           e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order
   426  808.355 MiB    0.000 MiB           e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])
   427  808.355 MiB    0.000 MiB           kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)
   428                             
   429  808.355 MiB    0.000 MiB           dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))
   430                             
   431                                     # Calculate 2B-2B contribution (occB term)
   432  808.355 MiB    0.000 MiB           e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])
   433  808.613 MiB    0.258 MiB           G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])
   434  808.613 MiB    0.000 MiB           sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)
   435                             
   436  808.613 MiB    0.000 MiB           dG_2b2b_B = tf.identity(sub_term)
   437                             
   438                                     # Calculate 2B-2B contribution (occA term)
   439  808.613 MiB    0.000 MiB           e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])
   440  808.613 MiB    0.000 MiB           e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order
   441  808.613 MiB    0.000 MiB           e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])
   442  808.613 MiB    0.000 MiB           e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])
   443  808.613 MiB    0.000 MiB           e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])
   444  808.613 MiB    0.000 MiB           e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])
   445  808.613 MiB    0.000 MiB           sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)
   446  808.613 MiB    0.000 MiB           sub2 = tf.subtract(sub1, e2G_occA_Tkl)
   447  808.871 MiB    0.258 MiB           add3 = tf.add(sub2, e2G_occA_Tijkl)
   448                             
   449  808.871 MiB    0.000 MiB           dG_2b2b_A = tf.identity(add3)
   450                             
   451  808.871 MiB    0.000 MiB           dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])
   452                                     
   453 1316.242 MiB  507.371 MiB           dE_e = dE.eval()
   454 1317.801 MiB    1.559 MiB           df_e = df.eval()
   455  816.332 MiB    0.000 MiB           dG_e = dG.eval()
   456                                 
   457  816.332 MiB    0.000 MiB       tf.reset_default_graph()
   458                                 
   459  816.332 MiB    0.000 MiB       return (dE_e, df_e, dG_e)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   466  314.984 MiB  314.984 MiB   @profile
   467                             def derivative(t, y, holes, particles, occA, occB, occC, occD):
   468                                 
   469  314.984 MiB  314.984 MiB       E, f, G = ravel(y, holes, particles)
   470                             
   471  559.055 MiB  559.055 MiB       eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)
   472                                 
   473  816.332 MiB  816.332 MiB       dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)
   474                                 
   475  816.332 MiB  816.332 MiB       dy = unravel(dE, df, dG)
   476                                 
   477  816.332 MiB    0.000 MiB       return dy


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   485  816.332 MiB  816.332 MiB   @profile
   486                             def unravel(E, f, G):
   487  816.332 MiB    0.000 MiB       unravel_E = np.reshape(E, -1)
   488  816.332 MiB    0.000 MiB       unravel_f = np.reshape(f, -1)
   489  816.332 MiB    0.000 MiB       unravel_G = np.reshape(G, -1)
   490                                 
   491  816.332 MiB    0.000 MiB       return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   493  816.332 MiB  816.332 MiB   @profile
   494                             def ravel(y, holes, particles):
   495                                 
   496  816.332 MiB    0.000 MiB       bas_len = len(np.append(holes,particles))
   497                                 
   498  816.332 MiB    0.000 MiB       ravel_E = np.reshape(y[0], ())
   499  816.332 MiB    0.000 MiB       ravel_f = np.reshape(y[1:bas_len**2+1], (bas_len, bas_len))
   500  816.332 MiB    0.000 MiB       ravel_G = np.reshape(y[bas_len**2+1:bas_len**2+1+bas_len**4], 
   501  816.332 MiB    0.000 MiB                            (bas_len, bas_len, bas_len, bas_len))
   502                                 
   503  816.332 MiB    0.000 MiB       return(ravel_E, ravel_f, ravel_G)


Filename: testing_tensorflow_v2_bench.py

Line #    Mem usage    Increment   Line Contents
================================================
   522  258.145 MiB  258.145 MiB   @profile
   523                             def run(n_holes):
   524  258.387 MiB  258.387 MiB       H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(n_holes, n_holes)
   525                             
   526  259.414 MiB  259.414 MiB       occA = get_occA(B1, ref)
   527  260.703 MiB  260.703 MiB       occB = get_occB(B1, ref)
   528  291.898 MiB  291.898 MiB       occC = get_occC(B1, ref)
   529  293.188 MiB  293.188 MiB       occD = get_occD(B1, ref)
   530                                 
   531  314.984 MiB  314.984 MiB       E, f, G = normal_order(H1B_t, H2B_t, holes)
   532                             
   533                                 
   534  314.984 MiB  314.984 MiB       y0 = unravel(E, f, G)
   535                             
   536  314.984 MiB    0.000 MiB       t = 1
   537  816.332 MiB  816.332 MiB       dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)
   538                             
   539  816.332 MiB  816.332 MiB       dE, df, dG = ravel(dy, holes, particles)
   540  816.332 MiB    0.000 MiB       print(dE)


---------------------------------------------\n

