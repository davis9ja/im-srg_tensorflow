{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/davis9ja/im-srg_tensorflow/blob/master/testing_tensorflow_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "12WjV8yIyAb0",
    "outputId": "3ddb6ce6-28af-434f-bce6-dcaa221a307a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.integrate import odeint, ode\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQZeGM1NyHBk"
   },
   "outputs": [],
   "source": [
    "# --- BUILD HAMILTONIAN -----------\n",
    "def build_hamiltonian(n_hole_states, n_particle_states):\n",
    "    numh = n_hole_states\n",
    "    nump = n_particle_states\n",
    "    nums = numh + nump\n",
    "    \n",
    "    ref = np.append(np.ones(numh), np.zeros(nump))\n",
    "    holes = np.arange(numh)\n",
    "    particles = np.arange(numh,numh+nump)\n",
    "    B1 = np.append(holes,particles)\n",
    "    \n",
    "    # one body part of Hamiltonian is floor-division of basis index\n",
    "    # matrix elements are (P-1) where P is energy level\n",
    "    H1B = np.diag(np.floor_divide(B1,2))\n",
    "\n",
    "    H2B = np.zeros((nums, nums, nums, nums))\n",
    "    for p in B1:\n",
    "        for q in B1:\n",
    "            for r in B1:\n",
    "                for s in B1:\n",
    "\n",
    "                    pp = np.floor_divide(p,2)\n",
    "                    qp = np.floor_divide(q,2)\n",
    "                    rp = np.floor_divide(r,2)\n",
    "                    sp = np.floor_divide(s,2)\n",
    "\n",
    "                    ps = 1 if p%2==0 else -1\n",
    "                    qs = 1 if q%2==0 else -1\n",
    "                    rs = 1 if r%2==0 else -1\n",
    "                    ss = 1 if s%2==0 else -1\n",
    "\n",
    "                    if pp != qp or rp != sp:\n",
    "                        continue\n",
    "                    if ps == qs or rs == ss:\n",
    "                        continue\n",
    "                    if ps == rs and qs == ss:\n",
    "                        H2B[p,q,r,s] = -0.25\n",
    "                    if ps == ss and qs == rs:\n",
    "                        H2B[p,q,r,s] = 0.25\n",
    "                        \n",
    "    return (H1B, H2B, ref, holes, particles, B1)\n",
    "\n",
    "# covers na - nb\n",
    "def get_occA(B1_basis):\n",
    "    n = len(B1_basis)\n",
    "    occA = np.zeros((n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            occA[a,b,a,b] = ref[a] - ref[b]\n",
    "            \n",
    "    return occA\n",
    "        \n",
    "# covers (1-na-nb)\n",
    "def get_occB(B1_basis):\n",
    "    n = len(B1_basis)    \n",
    "    occB = np.zeros((n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            occB[a,b,a,b] = 1 - ref[a] - ref[b]\n",
    "            \n",
    "    return occB\n",
    "        \n",
    "# covers na*nb + (1-na-nb)*nc\n",
    "def get_occC(B1_basis):\n",
    "    n = len(B1_basis)        \n",
    "    occC = np.zeros((n,n,n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            for c in B1_basis:\n",
    "                occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]\n",
    "                \n",
    "    return occC\n",
    "\n",
    "# covers na*nb*(1-nc-nd) + na*nb*nc*nd\n",
    "def get_occD(B1_basis):\n",
    "    n = len(B1_basis)    \n",
    "    occD = np.zeros((n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            for c in B1_basis:\n",
    "                for d in B1_basis:\n",
    "                    occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]\n",
    "                    \n",
    "    return occD\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "t-gCmAPvyp4z",
    "outputId": "5c7228c6-8225-4e6b-9958-74543aa7156f"
   },
   "outputs": [],
   "source": [
    "# --- NORMAL ORDER HAMILTONIAN -----------\n",
    "# Calculate 0b, 1b, 2b pieces \n",
    "#\n",
    "# zero-body piece is scalar\n",
    "# one-body piece is rank 2 tensor\n",
    "# two-body piece is rank 4 tensor\n",
    "\n",
    "def normal_order(H1B_t, H2B_t, holes):\n",
    "    \n",
    "    H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32)\n",
    "    H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32)\n",
    "    holes = tf.convert_to_tensor(holes, dtype=tf.int32)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # - Calculate 0B tensor\n",
    "        # E = tf.Variable(0.0)\n",
    "        contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)\n",
    "        contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)\n",
    "\n",
    "        E_1b = tf.reduce_sum(contr_1b, 0)\n",
    "        E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])\n",
    "        E = tf.add_n([E_1b, E_2b])\n",
    "\n",
    "        # - Calculate 1B tensor\n",
    "        contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)\n",
    "        contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes\n",
    "\n",
    "        f = tf.add_n([H1B_t, contr_2b])\n",
    "\n",
    "        # - Calculate 2B tensor\n",
    "        G = tf.identity(H2B_t)\n",
    "        \n",
    "        E_e = E.eval()\n",
    "        f_e = f.eval()\n",
    "        G_e = G.eval()\n",
    "        \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    return (E_e, f_e, G_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwn3kw6yeUQO"
   },
   "outputs": [],
   "source": [
    "# # --- SET UP WHITE'S GENERATOR -----------\n",
    "\n",
    "# # TODO: try reduce_sum, einsum, tensordot?, other methods\n",
    "\n",
    "# def white(f, G, holes, particles):\n",
    "  \n",
    "#     # - Calculate 1b generator tensor\n",
    "#     # indices are constructed by all possible combinations of pp and hh states\n",
    "#     p1_ind = tf.reshape(tf.broadcast_to(particles,[4,4]), [-1])\n",
    "#     p2_ind = tf.reshape(tf.transpose(tf.broadcast_to(particles,[4,4])), [-1])\n",
    "#     pp_indices = tf.stack([p1_ind, p2_ind], axis=1)\n",
    "#     pp_updates = tf.gather_nd(f, pp_indices)\n",
    "    \n",
    "#     h1_ind = tf.reshape(tf.broadcast_to(holes,[4,4]), [-1])\n",
    "#     h2_ind = tf.reshape(tf.transpose(tf.broadcast_to(holes,[4,4])), [-1])\n",
    "#     hh_indices = tf.stack([h1_ind, h2_ind], axis=1)\n",
    "#     hh_updates = tf.gather_nd(f, hh_indices)\n",
    "    \n",
    "#     fpp = tf.scatter_nd(pp_indices, pp_updates, f.shape)\n",
    "#     fhh = tf.scatter_nd(hh_indices, hh_updates, f.shape)\n",
    "    \n",
    "#     # indices are constructed by all possible combinations of phph states\n",
    "#     ind1_C = tf.broadcast_to(particles,[64,4])\n",
    "#     ind1_TC = tf.transpose(ind1_C) \n",
    "#     ind1 = tf.reshape(ind1_TC,[-1])\n",
    "\n",
    "#     ind2_C = tf.broadcast_to(holes,[16,16])\n",
    "#     ind2_TC = tf.transpose(ind2_C)\n",
    "#     ind2 = tf.reshape(ind2_TC,[-1])\n",
    "\n",
    "#     ind3_C = tf.broadcast_to(particles,[4,64])\n",
    "#     ind3_TC = tf.transpose(ind3_C) \n",
    "#     ind3 = tf.reshape(ind3_TC,[-1])\n",
    "\n",
    "#     ind4_C = tf.broadcast_to(holes,[1,256])\n",
    "#     ind4_TC = tf.transpose(ind4_C)\n",
    "#     ind4 = tf.reshape(ind4_TC,[-1])\n",
    "\n",
    "#     phph_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)\n",
    "#     phph_updates = tf.gather_nd(G, phph_indices)\n",
    "\n",
    "#     Gphph = tf.scatter_nd(phph_indices, phph_updates, G.shape)\n",
    "#     Gphph_red = tf.reduce_sum(Gphph, [0,1])\n",
    "    \n",
    "#     delta_ph = tf.add(tf.subtract(fpp, fhh), Gphph_red)\n",
    "    \n",
    "#     ph_indices = tf.stack([p1_ind, h2_ind], axis=1)\n",
    "#     ph_updates = tf.gather_nd(f, ph_indices)\n",
    "#     fph = tf.scatter_nd(ph_indices, ph_updates, f.shape)\n",
    "    \n",
    "#     eta1B = tf.div_no_nan(fph, delta_ph)\n",
    "    \n",
    "#     # - Calculate 2b generator tensor\n",
    "#     eta2B = tf.zeros(G.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# #     return temp\n",
    "#     return (eta1B, pp_indices, delta_ph)\n",
    "# #     return (eta1B, eta2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SET UP WEGNER'S GENERATOR -----------\n",
    "\n",
    "def wegner(f, G, holes, particles, occA, occB, occC, occD):\n",
    "    \n",
    "    f = tf.convert_to_tensor(f, dtype=tf.float32)\n",
    "    G = tf.convert_to_tensor(G, dtype=tf.float32)\n",
    "    holes = tf.convert_to_tensor(holes, dtype=tf.int32)\n",
    "    particles = tf.convert_to_tensor(particles, dtype=tf.int32)\n",
    "    occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)\n",
    "    occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)\n",
    "    occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)\n",
    "    occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP\n",
    "\n",
    "        # Decoupling 1B piece\n",
    "        # indices are constructed by all possible combinations of particle-hole(hole-particle) states\n",
    "        col_indices =tf.reshape(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0),[-1])\n",
    "        row_indices = tf.reshape(tf.transpose(tf.concat([tf.broadcast_to(holes,[4,4]),tf.broadcast_to(particles,[4,4])],1)),[-1])\n",
    "        ph_indices = tf.stack([row_indices, col_indices], axis=1)\n",
    "        ph_updates = tf.gather_nd(f, ph_indices)\n",
    "\n",
    "        fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)\n",
    "        fd = tf.subtract(f,fod)\n",
    "\n",
    "        # Decoupling 2B piece\n",
    "        # indices are constructed by all possible combinations of pphh(hhpp) states\n",
    "        ind1_C = tf.concat([tf.broadcast_to(holes,[64,4]), tf.broadcast_to(particles,[64,4])],1)\n",
    "        ind1_TC = tf.transpose(ind1_C) \n",
    "        ind1 = tf.reshape(ind1_TC,[-1])\n",
    "\n",
    "        ind2_C = tf.concat([tf.broadcast_to(holes,[16,16]),tf.broadcast_to(particles,[16,16])],1)\n",
    "        ind2_TC = tf.transpose(ind2_C)\n",
    "        ind2 = tf.reshape(ind2_TC,[-1])\n",
    "\n",
    "        ind3_C = tf.concat([tf.broadcast_to(particles,[4,64]),tf.broadcast_to(holes,[4,64])],1)\n",
    "        ind3_TC = tf.transpose(ind3_C) \n",
    "        ind3 = tf.reshape(ind3_TC,[-1])\n",
    "\n",
    "        ind4_C = tf.concat([tf.broadcast_to(particles,[1,256]),tf.broadcast_to(holes,[1,256])],1)\n",
    "        ind4_TC = tf.transpose(ind4_C)\n",
    "        ind4 = tf.reshape(ind4_TC,[-1])\n",
    "\n",
    "        pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)\n",
    "        pphh_updates = tf.gather_nd(G, pphh_indices)\n",
    "\n",
    "        God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)\n",
    "        Gd = tf.subtract(G,God)\n",
    "\n",
    "\n",
    "        # --- 1B piece\n",
    "\n",
    "        # Calculate 1B-1B contribution\n",
    "        fd_fod = tf.tensordot(fd,fod,1)\n",
    "        fd_fod_T = tf.transpose(fd_fod)\n",
    "        eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)\n",
    "\n",
    "        # Calculate 1B-2B contribution\n",
    "        fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))\n",
    "        fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))\n",
    "        eta1B_1b2b = tf.subtract(fd_God, fod_Gd)\n",
    "\n",
    "        # Calculate 2B-2B contribution\n",
    "        Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))\n",
    "        Gd_God_T = tf.transpose(Gd_God)\n",
    "        scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(Gd_God,Gd_God_T))\n",
    "        eta1B_2b2b = scaled_sub\n",
    "\n",
    "        eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])\n",
    "\n",
    "\n",
    "\n",
    "        # --- 2B piece\n",
    "\n",
    "        # Calculate 1B-2B contribution\n",
    "        fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )\n",
    "        fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])\n",
    "        ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)\n",
    "\n",
    "        fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )\n",
    "        fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order\n",
    "        fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])\n",
    "        kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)\n",
    "\n",
    "        eta2B_1b2b = tf.subtract(ij_term,kl_term)\n",
    "\n",
    "\n",
    "        # Calculate 2B-2B contribution\n",
    "        GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])\n",
    "        GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])\n",
    "        scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(GdGod_occB,GodGd_occB))\n",
    "\n",
    "        eta2B_2b2b_B = scaled_sub\n",
    "\n",
    "        GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])\n",
    "        GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "        GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])\n",
    "        GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])\n",
    "        GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])\n",
    "        GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])\n",
    "        sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)\n",
    "        sub2 = tf.subtract(sub1,GdGod_occA_Tkl)\n",
    "        add3 = tf.add(sub2,GdGod_occA_Tijkl)\n",
    "\n",
    "        eta2B_2b2b_A = add3\n",
    "\n",
    "        eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])\n",
    "        \n",
    "        eta1B_e = eta1B.eval()\n",
    "        eta2B_e = eta2B.eval()\n",
    "        \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    return (eta1B_e, eta2B_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WRITE FLOW EQUATIONS -----------\n",
    "\n",
    "def flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD):\n",
    "    \n",
    "    f = tf.convert_to_tensor(f, dtype=tf.float32)\n",
    "    G = tf.convert_to_tensor(G, dtype=tf.float32)\n",
    "    eta1B = tf.convert_to_tensor(eta1B, dtype=tf.float32)\n",
    "    eta2B = tf.convert_to_tensor(eta2B, dtype=tf.float32)\n",
    "    holes = tf.convert_to_tensor(holes, dtype=tf.int32)\n",
    "    particles = tf.convert_to_tensor(particles, dtype=tf.int32)\n",
    "    occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)\n",
    "    occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)\n",
    "    occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)\n",
    "    occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # --- 0B piece\n",
    "\n",
    "        # Calculate 1B-1B contribution (full contraction)\n",
    "        occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])\n",
    "        occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])\n",
    "        dE_1b1b = tf.identity(occA_e1_f)\n",
    "\n",
    "        # Calculate 2B-2B contribution (full contraction)\n",
    "    #     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])\n",
    "        e2_occD = tf.matmul(eta2B, occD_t)\n",
    "        e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])\n",
    "        dE_2b2b = tf.identity(e2_occD_G)\n",
    "\n",
    "        dE = tf.add_n([dE_1b1b, dE_2b2b])\n",
    "\n",
    "        # --- 1B piece\n",
    "\n",
    "        # Calculate 1B-1B contribution (contraction over 1 index)\n",
    "        e1_f = tf.tensordot(eta1B,f,[[1],[0]])\n",
    "        e1_f_T = tf.transpose(e1_f)\n",
    "        e1_f_add = tf.add(e1_f,e1_f_T)\n",
    "        df_1b1b = tf.identity(e1_f_add)\n",
    "\n",
    "        # Calculate 1B-2B contribution (contraction over 2 indices)\n",
    "        occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])\n",
    "        occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])\n",
    "        sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)\n",
    "        df_1b2b = tf.identity(sub_1b2b)\n",
    "\n",
    "        # Calculate 2B-2B contribution (contraction over 3 indices)\n",
    "        e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])\n",
    "        e2_occC_G_T = tf.transpose(e2_occC_G)\n",
    "        add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)\n",
    "        df_2b2b = tf.identity(add_2b2b)\n",
    "\n",
    "        df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])\n",
    "\n",
    "        # --- 2B piece\n",
    "\n",
    "        # Calculate 1B-2B contribution (contraction over 1 index)\n",
    "        e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))\n",
    "        e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])\n",
    "        ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)\n",
    "\n",
    "        e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))\n",
    "        e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order\n",
    "        e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])\n",
    "        kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)\n",
    "\n",
    "        dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))\n",
    "\n",
    "        # Calculate 2B-2B contribution (occB term)\n",
    "        e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])\n",
    "        G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])\n",
    "        sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)\n",
    "\n",
    "        dG_2b2b_B = tf.identity(sub_term)\n",
    "\n",
    "        # Calculate 2B-2B contribution (occA term)\n",
    "        e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])\n",
    "        e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "        e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])\n",
    "        e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])\n",
    "        e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])\n",
    "        e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])\n",
    "        sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)\n",
    "        sub2 = tf.subtract(sub1, e2G_occA_Tkl)\n",
    "        add3 = tf.add(sub2, e2G_occA_Tijkl)\n",
    "\n",
    "        dG_2b2b_A = tf.identity(add3)\n",
    "\n",
    "        dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])\n",
    "        \n",
    "        dE_e = dE.eval()\n",
    "        df_e = df.eval()\n",
    "        dG_e = dG.eval()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    return (dE_e, df_e, dG_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEFINE DERIVATIVE TO PASS INTO ODEINT SOLVER -----------\n",
    "\n",
    "def derivative(t, y, holes, particles, occA, occB, occC, occD):\n",
    "    \n",
    "    E, f, G = ravel(y)\n",
    "\n",
    "    eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)\n",
    "    \n",
    "    dE, df, dG = flow(f, G, eta1B, eta2B, holes, particles, occA, occB, occC, occD)\n",
    "    \n",
    "    dy = unravel(dE, df, dG)\n",
    "    \n",
    "    return dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONVERT NORMAL ORDERED TENSORS INTO RANK 1 TENSOR -----------\n",
    "# Quality-of-life methods that facilite compatibility with scipy.ode\n",
    "\n",
    "# def unravel(E, f, G):\n",
    "#     unravel_E = tf.reshape(E, [-1])\n",
    "#     unravel_f = tf.reshape(f, [-1])\n",
    "#     unravel_G = tf.reshape(G, [-1])\n",
    "    \n",
    "#     return tf.concat([unravel_E, unravel_f, unravel_G], 0)\n",
    "\n",
    "# def ravel(y):\n",
    "    \n",
    "#     ravel_E = tf.reshape(y[0], ())\n",
    "#     ravel_f = tf.reshape(y[1:65], (8,8))\n",
    "#     ravel_G = tf.reshape(y[65:65+4096], (8,8,8,8))\n",
    "    \n",
    "#     return(ravel_E, ravel_f, ravel_G)\n",
    "\n",
    "def unravel(E, f, G):\n",
    "    unravel_E = np.reshape(E, -1)\n",
    "    unravel_f = np.reshape(f, -1)\n",
    "    unravel_G = np.reshape(G, -1)\n",
    "    \n",
    "    return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)\n",
    "\n",
    "def ravel(y):\n",
    "    \n",
    "    ravel_E = np.reshape(y[0], ())\n",
    "    ravel_f = np.reshape(y[1:65], (8,8))\n",
    "    ravel_G = np.reshape(y[65:65+4096], (8,8,8,8))\n",
    "    \n",
    "    return(ravel_E, ravel_f, ravel_G)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qqW27CGI0FF8",
    "outputId": "dbfb500f-ea0a-4e0d-f8d2-659b5719aa1b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.75\n",
      "-1.75\n",
      "-1.75\n",
      "-1.75\n",
      "-1.75\n",
      "-1.75\n",
      "-1.75\n",
      "-1.75\n",
      "457 ms ± 43.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN PROCEDURE -----------\n",
    "# Build and normal-order Hamiltonian (numpy tensors)\n",
    "# Build some useful occupation numpy tensors (for Wegner's generator and flow equations)\n",
    "# Iterate flow equation until convergence\n",
    "\n",
    "# The functions -wegner- and -flow- build and evaluate graphs in TensorFlow. The inputs\n",
    "# are numpy arrays which are dynamically converted into Tensor objects; the graphs\n",
    "# are built from these objects. At the end of each function, we evaluate the graph,\n",
    "# remember the results, and reset that session's graph (might not be necessary).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(4,4)\n",
    "\n",
    "occA = get_occA(B1)\n",
    "occB = get_occB(B1)\n",
    "occC = get_occC(B1)\n",
    "occD = get_occD(B1)\n",
    "\n",
    "# occA_t = tf.convert_to_tensor(get_occA(B1), dtype=tf.float32)\n",
    "# occB_t = tf.convert_to_tensor(get_occB(B1), dtype=tf.float32)\n",
    "# occC_t = tf.convert_to_tensor(get_occC(B1), dtype=tf.float32)\n",
    "# occD_t = tf.convert_to_tensor(get_occD(B1), dtype=tf.float32)\n",
    "\n",
    "E, f, G = normal_order(H1B_t, H2B_t, holes)\n",
    "# print(type(G))\n",
    "# eta1B, eta2B = wegner(f, G, holes, particles, occA, occB, occC, occD)\n",
    "# t = 1\n",
    "# dy = derivative(t, y, holes, particles, occA, occB, occC, occD)\n",
    "# # print(dy.shape)\n",
    "# dE, df, dG = ravel(dy)\n",
    "\n",
    "\n",
    "def run(E, f, G):\n",
    "\n",
    "    y0 = unravel(E, f, G)\n",
    "\n",
    "    t = 1\n",
    "    dy = derivative(t, y0, holes, particles, occA, occB, occC, occD)\n",
    "\n",
    "    dE, df, dG = ravel(dy)\n",
    "    print(dE)\n",
    "#         print(dG[0,1,4,5])\n",
    "%timeit run(E, f, G)\n",
    "\n",
    "\n",
    "# y0 = unravel(E, f, G)\n",
    "\n",
    "# solver = ode(derivative,jac=None)\n",
    "# solver.set_integrator('vode', method='bdf', order=5, nsteps=1000)\n",
    "# solver.set_f_params(holes, particles, occA, occB, occC, occD)\n",
    "# solver.set_initial_value(y0, 0.)\n",
    "\n",
    "# sfinal = 2\n",
    "# ds = 0.1\n",
    "# s_vals = []\n",
    "# E_vals = []\n",
    "\n",
    "# while solver.successful() and solver.t < sfinal:\n",
    "    \n",
    "#     ys = solver.integrate(sfinal, step=True)\n",
    "#     Es, fs, Gs = ravel(ys) \n",
    "\n",
    "#     print(\"scale param: {:0.4f} \\t E = {:0.5f}\".format(solver.t, Es))\n",
    "#     s_vals.append(solver.t)\n",
    "#     E_vals.append(Es)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqTTHpAJ4JPT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "testing_tensorflow_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
