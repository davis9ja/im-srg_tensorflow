{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/davis9ja/im-srg_tensorflow/blob/master/testing_tensorflow_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "12WjV8yIyAb0",
    "outputId": "3ddb6ce6-28af-434f-bce6-dcaa221a307a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.integrate import odeint, ode\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQZeGM1NyHBk"
   },
   "outputs": [],
   "source": [
    "# --- BUILD HAMILTONIAN -----------\n",
    "ref = np.asarray([1,1,1,1,0,0,0,0])\n",
    "holes = np.asarray([0,1,2,3])\n",
    "particles = np.asarray([4,5,6,7])\n",
    "\n",
    "# one-body basis is just all possible single particle states\n",
    "# B1 = tf.constant(holes+particles)#np.append(holes,particles)\n",
    "B1 = np.append(holes,particles)\n",
    "\n",
    "# we build two-body basis with all possible pairs of single particle states\n",
    "B2 = []\n",
    "ind2B = {}\n",
    "\n",
    "count = 0\n",
    "for h in holes:\n",
    "    for h2 in holes:\n",
    "        B2.append((h,h2))\n",
    "        ind2B[(h,h2)] = count\n",
    "        count += 1\n",
    "\n",
    "for h in holes:\n",
    "    for p in particles:\n",
    "        B2.append((h,p))\n",
    "        ind2B[(h,p)] = count\n",
    "        count += 1\n",
    "        \n",
    "for p in particles:\n",
    "    for h in holes:\n",
    "        B2.append((p,h))\n",
    "        ind2B[(p,h)] = count\n",
    "        count += 1\n",
    "            \n",
    "for p in particles:\n",
    "    for p2 in particles:\n",
    "        B2.append((p,p2)) \n",
    "        ind2B[(p,p2)] = count\n",
    "        count += 1           \n",
    "\n",
    "# the one-body Hamiltonian is diagonal, with elements given by P-1 or \n",
    "# single particle state index divided by 2 (rounding down)\n",
    "H1B = np.zeros((len(B1), len(B1)))\n",
    "for i in range(len(B1)):\n",
    "    H1B[i,i] = np.floor_divide(i,2)\n",
    "\n",
    "# the two-body Hamiltonian is sparse; only non-zero contributions \n",
    "# where pq=rs or pq=sr=-rs\n",
    "H2B = np.zeros((len(B2), len(B2)))\n",
    "for i in range(len(B2)):\n",
    "    for j in range(len(B2)):\n",
    "        p, q = B2[i]\n",
    "        r, s = B2[j]\n",
    "        \n",
    "        pp = np.floor_divide(p,2)\n",
    "        qp = np.floor_divide(q,2)\n",
    "        rp = np.floor_divide(r,2)\n",
    "        sp = np.floor_divide(s,2)\n",
    "        \n",
    "        ps = 1 if p%2==0 else -1\n",
    "        qs = 1 if q%2==0 else -1\n",
    "        rs = 1 if r%2==0 else -1\n",
    "        ss = 1 if s%2==0 else -1\n",
    "        \n",
    "        if pp != qp or rp != sp:\n",
    "            continue\n",
    "        if ps == qs or rs == ss:\n",
    "            continue\n",
    "        if ps == rs and qs == ss:\n",
    "            H2B[i,j] = -0.25\n",
    "        if ps == ss and qs == rs:\n",
    "            H2B[i,j] = 0.25\n",
    "\n",
    "B1_len = len(B1)\n",
    "H2B_t = np.zeros((B1_len,B1_len,B1_len,B1_len))\n",
    "for p in B1:\n",
    "    for q in B1:\n",
    "        for r in B1:\n",
    "            for s in B1:\n",
    "                H2B_t[p,q,r,s] = H2B[ind2B[(p,q)], ind2B[(r,s)]]\n",
    "        \n",
    "# test2 = np.einsum('ijij->ij',H2B_t)\n",
    "# print(test2)\n",
    "# for i in holes:\n",
    "#   for j in holes:\n",
    "#         print(H2B[ind2B[(i,j)], ind2B[(i,j)]])\n",
    "#         print(H2B_t[i,j,i,j])\n",
    "# print(np.shape(list(map(lambda i: H2B_t[i,:,i,:], holes))))\n",
    "# test = list(map(lambda i,j: H2B_t[i,j,i,j],holes,particles))\n",
    "# print(np.shape(test))\n",
    "\n",
    "# covers na - nb\n",
    "occA = np.zeros_like(H2B_t)\n",
    "for a in B1:\n",
    "    for b in B1:\n",
    "        occA[a,b,a,b] = ref[a] - ref[b]\n",
    "        \n",
    "# covers (1-na-nb)\n",
    "occB = np.zeros_like(H2B_t)\n",
    "for a in B1:\n",
    "    for b in B1:\n",
    "        occB[a,b,a,b] = 1 - ref[a] - ref[b]\n",
    "        \n",
    "# covers na*nb + (1-na-nb)*nc\n",
    "occC = np.zeros((B1_len,B1_len,B1_len,B1_len,B1_len,B1_len))\n",
    "for a in B1:\n",
    "    for b in B1:\n",
    "        for c in B1:\n",
    "            occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]\n",
    "\n",
    "# covers na*nb*(1-nc-nd) + na*nb*nc*nd\n",
    "occD = np.zeros((B1_len,B1_len,B1_len,B1_len,B1_len,B1_len,B1_len,B1_len))\n",
    "for a in B1:\n",
    "    for b in B1:\n",
    "        for c in B1:\n",
    "            for d in B1:\n",
    "                occD[a,b,c,d,a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]\n",
    "\n",
    "ref_t = tf.convert_to_tensor(ref)\n",
    "\n",
    "B1_t = tf.convert_to_tensor(B1, dtype=tf.int32)\n",
    "holes = tf.convert_to_tensor(holes, dtype=tf.int32)\n",
    "particles = tf.convert_to_tensor(particles, dtype=tf.int32)\n",
    "\n",
    "H1B_t = tf.convert_to_tensor(H1B, dtype=tf.float32)\n",
    "H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32)\n",
    "\n",
    "occA_t = tf.convert_to_tensor(occA, dtype=tf.float32)\n",
    "occB_t = tf.convert_to_tensor(occB, dtype=tf.float32)\n",
    "occC_t = tf.convert_to_tensor(occC, dtype=tf.float32)\n",
    "occD_t = tf.convert_to_tensor(occD, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "t-gCmAPvyp4z",
    "outputId": "5c7228c6-8225-4e6b-9958-74543aa7156f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# --- NORMAL ORDER HAMILTONIAN -----------\n",
    "# Calculate 0b, 1b, 2b pieces \n",
    "#\n",
    "# zero-body piece is scalar\n",
    "# one-body piece is rank 2 tensor\n",
    "# two-body piece is rank 4 tensor\n",
    "\n",
    "# - Calculate 0b tensor\n",
    "# E = tf.Variable(0.0)\n",
    "contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)\n",
    "contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)\n",
    "\n",
    "E_1b = tf.reduce_sum(contr_1b, 0)\n",
    "E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])\n",
    "E = tf.add_n([E_1b, E_2b])\n",
    "\n",
    "# - Calculate 1b tensor\n",
    "# f = tf.Variable(tf.identity(H1B_t))\n",
    "# f = tf.identity(H1B_t)\n",
    "contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)\n",
    "contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes\n",
    "\n",
    "f = tf.add_n([H1B_t, contr_2b])\n",
    "\n",
    "# - Calculate 2b tensor\n",
    "G = tf.identity(H2B_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwn3kw6yeUQO"
   },
   "outputs": [],
   "source": [
    "# --- SET UP WHITE'S GENERATOR -----------\n",
    "\n",
    "# TODO: try reduce_sum, einsum, tensordot?, other methods\n",
    "\n",
    "def white(f, G, holes, particles):\n",
    "  \n",
    "    # - Calculate 1b generator tensor\n",
    "    eta1B = tf.identity(f)\n",
    "    eta1Bph = eta1B[particles[0]:particles[-1]+1,holes[0]:holes[-1]+1]\n",
    "    fhh = f[holes[0]:holes[-1]+1,holes[0]:holes[-1]+1]\n",
    "    fpp = f[particles[0]:particles[-1]+1,particles[0]:particles[-1]+1]\n",
    "    Gphph = G[particles[0]:particles[-1]+1, holes[0]:holes[-1]+1, particles[0]:particles[-1]+1, holes[0]:holes[-1]+1]\n",
    "    Gphph = tf.reduce_sum(Gphph,[0,1]) # reduce to same rank as f\n",
    "    \n",
    "    Deltaph = tf.subtract(fpp, tf.add(fhh,Gphph))\n",
    "    temp = tf.div_no_nan(eta1Bph,Deltaph)\n",
    "    \n",
    "    top_block = tf.zeros((4,4))\n",
    "    bottom_block = tf.zeros((4,8))\n",
    "    conc_top = tf.concat([top_block, temp],1)\n",
    "    eta1B = tf.concat([conc_top, bottom_block], 0)\n",
    "    \n",
    "    # - Calculate 2b generator tensor\n",
    "    eta2B = tf.zeros(G.shape)\n",
    "#     return temp\n",
    "    return eta1B\n",
    "#     return (eta1B, eta2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SET UP WEGNER'S GENERATOR -----------\n",
    "\n",
    "def wegner(f, G):\n",
    "# basis = tf.concat([holes, particles],0)\n",
    "\n",
    "    # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP\n",
    "\n",
    "    # Decoupling 1B piece\n",
    "    # indices are constructed by all possible combinations of particle-hole(hole-particle) states\n",
    "    col_indices =tf.reshape(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0),[-1])\n",
    "    row_indices = tf.reshape(tf.transpose(tf.concat([tf.broadcast_to(holes,[4,4]),tf.broadcast_to(particles,[4,4])],1)),[-1])\n",
    "    ph_indices = tf.stack([row_indices, col_indices], axis=1)\n",
    "    ph_updates = tf.gather_nd(f, ph_indices)\n",
    "\n",
    "    fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)\n",
    "    fd = tf.subtract(f,fod)\n",
    "\n",
    "    # Decoupling 2B piece\n",
    "    # indices are constructed by all possible combinations of pphh(hhpp) states\n",
    "    ind1_C = tf.concat([tf.broadcast_to(holes,[64,4]), tf.broadcast_to(particles,[64,4])],1)\n",
    "    ind1_TC = tf.transpose(ind1_C) \n",
    "    ind1 = tf.reshape(ind1_TC,[-1])\n",
    "\n",
    "    ind2_C = tf.concat([tf.broadcast_to(holes,[16,16]),tf.broadcast_to(particles,[16,16])],1)\n",
    "    ind2_TC = tf.transpose(ind2_C)\n",
    "    ind2 = tf.reshape(ind2_TC,[-1])\n",
    "\n",
    "    ind3_C = tf.concat([tf.broadcast_to(particles,[4,64]),tf.broadcast_to(holes,[4,64])],1)\n",
    "    ind3_TC = tf.transpose(ind3_C) \n",
    "    ind3 = tf.reshape(ind3_TC,[-1])\n",
    "\n",
    "    ind4_C = tf.concat([tf.broadcast_to(particles,[1,256]),tf.broadcast_to(holes,[1,256])],1)\n",
    "    ind4_TC = tf.transpose(ind4_C)\n",
    "    ind4 = tf.reshape(ind4_TC,[-1])\n",
    "\n",
    "    pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)\n",
    "    pphh_updates = tf.gather_nd(G, pphh_indices)\n",
    "\n",
    "    God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)\n",
    "    Gd = tf.subtract(G,God)\n",
    "\n",
    "\n",
    "    # --- 1B piece\n",
    "#     eta1B = tf.Variable(tf.zeros(f.shape))\n",
    "\n",
    "    # Calculate 1B-1B contribution\n",
    "    fd_fod = tf.tensordot(fd,fod,1)\n",
    "    fd_fod_T = tf.transpose(fd_fod)\n",
    "    eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)\n",
    "\n",
    "    # fod_fd = tf.tensordot(fod,fd,1)\n",
    "    # eta1B = tf.assign_add(eta1B, tf.subtract(fd_fod, fod_fd))\n",
    "\n",
    "\n",
    "    # Calculate 1B-2B contribution\n",
    "    fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))\n",
    "    fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))\n",
    "    eta1B_1b2b = tf.subtract(fd_God, fod_Gd)\n",
    "\n",
    "\n",
    "    # Calculate 2B-2B contribution\n",
    "    Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))\n",
    "    Gd_God_T = tf.transpose(Gd_God)\n",
    "    scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(Gd_God,Gd_God_T))\n",
    "    eta1B_2b2b = scaled_sub\n",
    "    \n",
    "    eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])\n",
    "\n",
    "    #     God_Gd = tf.tensordot(God, tf.tensordot(occC_t,Gd,([0,1,2],[0,1,2])),([0,1,2],[2,3,1]))\n",
    "    #     scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(Gd_God,God_Gd))\n",
    "    #     eta1B = tf.assign_add(eta1B, scaled_sub)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # --- 2B piece\n",
    "#     eta2B = tf.Variable(tf.zeros(G.shape))\n",
    "\n",
    "    # Calculate 1B-2B contribution\n",
    "    fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )\n",
    "    fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])\n",
    "    ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)\n",
    "\n",
    "    # Godfd_Gdfod_ij = tf.subtract( tf.tensordot(God,fd,([0],[1])), tf.tensordot(Gd,fod,([0],[1])) )\n",
    "    # ij_term = tf.subtract(fdGod_fodGd_ij,Godfd_Gdfod_ij)\n",
    "\n",
    "    fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )\n",
    "    fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order\n",
    "    fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])\n",
    "    kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)\n",
    "\n",
    "    # Godfd_Gdfod_kl = tf.subtract( tf.tensordot(God,fd,([2],[0])), tf.tensordot(Gd,fod,([2],[0])) )\n",
    "    # kl_term = tf.subtract(fdGod_fodGd_kl,Godfd_Gdfod_kl)\n",
    "\n",
    "    eta2B_1b2b = tf.subtract(ij_term,kl_term)\n",
    "\n",
    "\n",
    "    # Calculate 2B-2B contribution\n",
    "    # GdGod_GodGd = tf.subtract( tf.tensordot(Gd,God,[[2,3],[0,1]]), tf.tensordot(God,Gd,[[2,3],[0,1]]) )\n",
    "    # GdGod_GodGd_occB = tf.tensordot(occB_t,GdGod_GodGd,[[2,3],[0,1]])\n",
    "\n",
    "    GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])\n",
    "    GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])\n",
    "    scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(GdGod_occB,GodGd_occB))\n",
    "    # GdGod_occB = tf.tensordot( Gd, tf.tensordot(occB_t,God,[[0,1],[0,1]]), [[2,3],[0,1]] )\n",
    "    # GodGd_occB = tf.tensordot( God, tf.tensordot(occB_t,Gd,[[0,1],[0,1]]), [[2,3],[0,1]] )\n",
    "    # scaled_sub = tf.scalar_mul(tf.constant(0.5), tf.subtract(GdGod_occB,GodGd_occB))\n",
    "    eta2B_2b2b_B = scaled_sub\n",
    "\n",
    "    GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])\n",
    "    GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "    GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])\n",
    "    # GdGod_occA = tf.tensordot( Gd, tf.tensordot(occA_t,God,[[0,1],[2,0]]), [[0,2],[0,1]] )\n",
    "    # GdGod_occA = tf.transpose(GdGod_occA, perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "    GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])\n",
    "    GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])\n",
    "    GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])\n",
    "    sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)\n",
    "    sub2 = tf.subtract(sub1,GdGod_occA_Tkl)\n",
    "    add3 = tf.add(sub2,GdGod_occA_Tijkl)\n",
    "\n",
    "    eta2B_2b2b_A = add3\n",
    "    \n",
    "    eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])\n",
    "    \n",
    "    return (eta1B, eta2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WRITE FLOW EQUATIONS -----------\n",
    "\n",
    "def flow(f, G, eta1B, eta2B):\n",
    "#     eta1B, eta2B = wegner(f,G)\n",
    "\n",
    "    # --- 0B piece\n",
    "    # dE = tf.Variable(0.0)\n",
    "\n",
    "    # Calculate 1B-1B contribution (full contraction)\n",
    "    occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])\n",
    "    occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])\n",
    "    dE_1b1b = tf.identity(occA_e1_f)\n",
    "\n",
    "    # Calculate 2B-2B contribution (full contraction)\n",
    "    e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])\n",
    "    e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])\n",
    "\n",
    "    # e2_occD_G = tf.scalar_mul(tf.constant(0.5),e2_occD_G)\n",
    "    dE_2b2b = tf.identity(e2_occD_G)\n",
    "\n",
    "    dE = tf.add_n([dE_1b1b, dE_2b2b])\n",
    "\n",
    "    # --- 1B piece\n",
    "    # df = tf.Variable(tf.zeros(f.shape))\n",
    "\n",
    "    # Calculate 1B-1B contribution (contraction over 1 index)\n",
    "    e1_f = tf.tensordot(eta1B,f,[[1],[0]])\n",
    "    e1_f_T = tf.transpose(e1_f)\n",
    "    e1_f_add = tf.add(e1_f,e1_f_T)\n",
    "    df_1b1b = tf.identity(e1_f_add)\n",
    "\n",
    "    # Calculate 1B-2B contribution (contraction over 2 indices)\n",
    "    occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])\n",
    "    occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])\n",
    "    sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)\n",
    "    df_1b2b = tf.identity(sub_1b2b)\n",
    "\n",
    "    # Calculate 2B-2B contribution (contraction over 3 indices)\n",
    "    e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])\n",
    "    e2_occC_G_T = tf.transpose(e2_occC_G)\n",
    "    add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)\n",
    "    df_2b2b = tf.identity(add_2b2b)\n",
    "\n",
    "    df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])\n",
    "\n",
    "    # --- 2B piece\n",
    "    # dG = tf.Variable(tf.zeros(G.shape))\n",
    "\n",
    "    # Calculate 1B-2B contribution (contraction over 1 index)\n",
    "    e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))\n",
    "    e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])\n",
    "    ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)\n",
    "\n",
    "    e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))\n",
    "    e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order\n",
    "    e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])\n",
    "    kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)\n",
    "\n",
    "    dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))\n",
    "\n",
    "    # Calculate 2B-2B contribution (occB term)\n",
    "    e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])\n",
    "    G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])\n",
    "    sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)\n",
    "#     e2G_Ge2 = tf.subtract(tf.tensordot(eta2B,G,[[2,3],[0,1]]), tf.tensordot(G,eta2B,[[2,3],[0,1]]))\n",
    "#     e2G_Ge2_occB = 0.5*tf.tensordot(occB_t,e2G_Ge2,[[2,3],[0,1]])\n",
    "\n",
    "    dG_2b2b_B = tf.identity(sub_term)\n",
    "\n",
    "    # Calculate 2B-2B contribution (occA term)\n",
    "    e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])\n",
    "    e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "    e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])\n",
    "    e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])\n",
    "    e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])\n",
    "    e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])\n",
    "    sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)\n",
    "    sub2 = tf.subtract(sub1, e2G_occA_Tkl)\n",
    "    add3 = tf.add(sub2, e2G_occA_Tijkl)\n",
    "\n",
    "    dG_2b2b_A = tf.identity(add3)\n",
    "\n",
    "    dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])\n",
    "\n",
    "    return (dE, df, dG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEFINE DERIVATIVE TO PASS INTO ODEINT SOLVER -----------\n",
    "# The input is an *evaluated graph* (numpy array); the output \n",
    "# is also an evaluated graph. Formatting in this way allows\n",
    "# for compability with scipy.ode; the tensorflow ode \n",
    "# package will be deprecated in TF v2.0\n",
    "\n",
    "def derivative(t, y):\n",
    "#     print(y.shape)\n",
    "    y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "    \n",
    "    E, f, G = ravel(y)\n",
    "    \n",
    "    eta1B, eta2B = wegner(f, G)\n",
    "    \n",
    "    dE, df, dG = flow(f, G, eta1B, eta2B)\n",
    "    \n",
    "    dy = unravel(dE, df, dG)\n",
    "    \n",
    "#     print(\"executed\")\n",
    "    \n",
    "    return dy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel(E, f, G):\n",
    "    unravel_E = tf.reshape(E, [-1])\n",
    "    unravel_f = tf.reshape(f, [-1])\n",
    "    unravel_G = tf.reshape(G, [-1])\n",
    "    \n",
    "    return tf.concat([unravel_E, unravel_f, unravel_G], 0)\n",
    "\n",
    "def ravel(y):\n",
    "    \n",
    "    ravel_E = tf.reshape(y[0], ())\n",
    "    ravel_f = tf.reshape(y[1:65], (8,8))\n",
    "    ravel_G = tf.reshape(y[65:65+4096], (8,8,8,8))\n",
    "    \n",
    "    return(ravel_E, ravel_f, ravel_G)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qqW27CGI0FF8",
    "outputId": "dbfb500f-ea0a-4e0d-f8d2-659b5719aa1b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.49999\n",
      "scale param: 0.0000 \t E = 1.49999\n",
      "scale param: 0.0000 \t E = 1.49998\n",
      "scale param: 0.0000 \t E = 1.49997\n",
      "scale param: 0.0000 \t E = 1.49993\n",
      "scale param: 0.0001 \t E = 1.49983\n",
      "scale param: 0.0002 \t E = 1.49973\n",
      "scale param: 0.0002 \t E = 1.49957\n",
      "scale param: 0.0003 \t E = 1.49941\n",
      "scale param: 0.0004 \t E = 1.49925\n",
      "scale param: 0.0006 \t E = 1.49894\n",
      "scale param: 0.0010 \t E = 1.49821\n",
      "scale param: 0.0015 \t E = 1.49749\n",
      "scale param: 0.0021 \t E = 1.49639\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-60bfcdaaea4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mE_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccessful\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msfinal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mEs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scale param: {:0.4f} \\t E = {:0.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/integrate/_ode.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t, step, relax)\u001b[0m\n\u001b[1;32m    430\u001b[0m             self._y, self.t = mth(self.f, self.jac or (lambda: None),\n\u001b[1;32m    431\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                                   self.f_params, self.jac_params)\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# f2py issue with tuple returns, see ticket 1187.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/integrate/_ode.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0mitask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/integrate/_ode.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, f, jac, y0, t0, t1, f_params, jac_params)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         args = ((f, jac, y0, t0, t1) + tuple(self.call_args) +\n\u001b[1;32m   1003\u001b[0m                 (f_params, jac_params))\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mistate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mistate\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-20a649c8b8c1>\u001b[0m in \u001b[0;36mderivative\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     print(\"executed\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- CAUTION: DO NOT EVALUATE PAST/FUTURE GRAPHS IN A SINGLE SESSION WHEN THOSE GRAPHS ARE DEPENDENT ---\n",
    "# e.g., evaluating dE also evaluates eta2B,eta1B; if you try to evaluate eta2B,eta1B again, you will \n",
    "#       receive an unexpected result\n",
    "# \n",
    "# --- The workaround is to use the var_print() method to \"print\" the value of the tensor you want;\n",
    "#     I think the issue has something to do with tf.Variable and the assign_add() method. In the \n",
    "#     future, I would like to fix the issue. For now, though, I just want a running code.\n",
    "#\n",
    "# ************ ABOVE ISSUE HAS BEEN FIXED; WILL CLOSE OUT WARNING IN RELEASE VERSION *****************\n",
    "\n",
    "# def var_print(session, tensor):\n",
    "#     session.run(tf.global_variables_initializer())\n",
    "#     print(session.run(tensor))\n",
    "\n",
    "\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     y0 = unravel(E, f, G)\n",
    "#     y0_eval = y0.eval()\n",
    "     \n",
    "#     t = 1\n",
    "#     dy = derivative(t, y0_eval)\n",
    "    \n",
    "#     dE, df, dG = ravel(dy)\n",
    "#     print(G[0,1,4,5].eval())\n",
    "#     print(dG[0,1,4,5].eval())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    y0 = unravel(E, f, G)\n",
    "    y0_eval = y0.eval()\n",
    "#     print(y0_eval.shape)\n",
    "    solver = ode(derivative,jac=None)\n",
    "    solver.set_integrator('vode', method='bdf', order=5, nsteps=1000)\n",
    "#     solver.set_f_params(len(f), len(Y))\n",
    "    solver.set_initial_value(y0_eval, 0.)\n",
    "\n",
    "    sfinal = 7\n",
    "    ds = 0.1\n",
    "    s_vals = []\n",
    "    E_vals = []\n",
    "    while solver.successful() and solver.t < sfinal:\n",
    "        ys = solver.integrate(sfinal, step=True)\n",
    "        Es, fs, Gs = ravel(ys) # outputs tensors\n",
    "        print(\"scale param: {:0.4f} \\t E = {:0.5f}\".format(solver.t,Es.eval()))\n",
    "        s_vals.append(solver.t)\n",
    "        E_vals.append(Es)\n",
    "        \n",
    "        \n",
    "    plt.plot(s_vals, E_vals)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqTTHpAJ4JPT"
   },
   "outputs": [],
   "source": [
    "#     print(ravel)\n",
    "#     print(dG[0,1,5,4].eval())\n",
    "\n",
    "#     test = np.zeros((8,8,8,8))\n",
    "#     test1 = np.zeros((8,8,8,8))\n",
    "#     test2 = np.zeros_like(test)\n",
    "#     test3 = np.zeros_like(test)\n",
    "#     test4 = np.zeros_like(test)\n",
    "#     eta2B_l = eta2B.eval()\n",
    "#     for i in B1:\n",
    "#         for j in B1:\n",
    "#             for k in B1:\n",
    "#                 for l in B1:\n",
    "# #                     for a in B1:\n",
    "#                     if(eta2B_l[i,j,k,l]>0):\n",
    "#                         print(eta2B_l[i,j,k,l],i,j,k,l)\n",
    "# #                         if(fd_l[a,k]*God_l[i,j,a,l] < 0 or fd_l[a,k]*God_l[i,j,a,l] > 0):\n",
    "# #                             print(fd_l[a,k]*God_l[i,j,a,l], a,\"|\",i,j,k,l)\n",
    "#                         test1[i,j,k,l] += fd_l[i,a]*God_l[a,j,k,l]\n",
    "#                         test2[i,j,k,l] += fd_l[j,a]*God_l[a,i,k,l]\n",
    "#                         test3[i,j,k,l] += fd_l[a,k]*God_l[i,j,a,l]\n",
    "#                         test4[i,j,k,l] += fd_l[a,l]*God_l[i,j,a,k]\n",
    "                        \n",
    "#                         test[i,j,k,l] += fd_l[i,a]*God_l[a,j,k,l] \\\n",
    "#                                        - fd_l[j,a]*God_l[a,i,k,l] \\\n",
    "#                                        - fd_l[a,k]*God_l[i,j,a,l] \\\n",
    "#                                        + fd_l[a,l]*God_l[i,j,a,k]\n",
    "#     print(test[0,1,4,5])\n",
    "#     print(test1[0,1,4,5],test2[0,1,4,5],test3[0,1,4,5],test4[0,1,4,5])\n",
    "# #     print(tf.transpose(test,perm=[0,1,3,2])[0,1,4,5].eval())\n",
    "    \n",
    "#     test_con1 = tf.tensordot(fd,God,[[1],[0]])\n",
    "#     test_con2 = tf.transpose(test_con1,perm=[1,0,2,3])\n",
    "#     test_con3 = tf.transpose(tf.tensordot(fd,God,[[0],[2]]),perm=[1,2,0,3])\n",
    "#     test_con4 = tf.transpose(test_con3,perm=[0,1,3,2])\n",
    "#     test_con = tf.add(tf.subtract(tf.subtract(test_con1,test_con2),test_con3),test_con4)\n",
    "#     print(test_con1[0,1,4,5].eval(), test_con2[0,1,4,5].eval(),test_con3[0,1,4,5].eval(),test_con4[0,1,4,5].eval())\n",
    "#     print(test_con[0,1,4,5].eval())\n",
    "#     print(\"true,\",test3[0,1,4,5])\n",
    "#     print(\"test,\",test_con3[0,1,4,5].eval())\n",
    "#     print(\"tf,\",tf.tensordot(fd,God,[[0],[2]])[4,0,1,5].eval())\n",
    "#     print(\"tf_p,\", tf.transpose(tf.tensordot(fd,God,[[0],[2]]),perm=[1,2,0,3])[0,1,4,5].eval())\n",
    "#     print(\"numpy,\",np.tensordot(fd_l,God_l,axes=((0),(2)))[0,1,4,5])\n",
    "#     print(tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3])[0,1,4,5].eval())\n",
    "\n",
    "# A = tf.constant([[1,2,3,4,5,6,7,8],\n",
    "#                  [3,4,5,6,7,8,9,1], \n",
    "#                  [7,8,9,1,2,3,4,5], \n",
    "#                  [6,7,8,9,1,2,3,4],\n",
    "#                  [1,2,3,4,5,6,7,8],\n",
    "#                  [3,4,5,6,7,8,9,1], \n",
    "#                  [7,8,9,1,2,3,4,5], \n",
    "#                  [6,7,8,9,1,2,3,4] ])\n",
    "\n",
    "# # indices = tf.constant([4,5,6,7, 4,5,6,7, 4,5,6,7, 4,5,6,7, 0,1,2,3, 0,1,2,3, 0,1,2,3, 0,1,2,3])\n",
    "# indices =tf.reshape(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0),[-1])\n",
    "\n",
    "# # prepare row indices\n",
    "# # row_indices = tf.range(tf.shape(indices)[0])\n",
    "# # row_indices = tf.constant([0,0,0,0, 1,1,1,1, 2,2,2,2, 3,3,3,3, 4,4,4,4, 5,5,5,5, 6,6,6,6, 7,7,7,7])\n",
    "# row_indices = tf.reshape(tf.transpose(tf.concat([tf.broadcast_to(holes,[4,4]),tf.broadcast_to(particles,[4,4])],1)),[-1])\n",
    "# # row_indices = tf.reshape(tf)\n",
    "# # zip row indices with column indices\n",
    "# full_indices = tf.stack([row_indices, indices], axis=1)\n",
    "\n",
    "# # retrieve values by indices\n",
    "# # indices = tf.transpose(full_indices)\n",
    "# # updates = tf.reshape(tf.gather_nd(A, full_indices),[2,2])\n",
    "# updates = tf.gather_nd(A, full_indices)\n",
    "# S = tf.scatter_nd(full_indices,updates,[8,8])\n",
    "\n",
    "# test = tf.scatter_nd([[[1,0,0,1],[1,0,0,0]]],[[1,2]],[8,8,8,8])\n",
    "# idx2b = tf.expand_dims(tf.stack([row_indices,row_indices,indices,indices],axis=1),0)\n",
    "# test2b = tf.zeros([8,8,8,8])\n",
    "# with tf.Session() as sess:\n",
    "# #     print(full_indices.eval())\n",
    "#     print(test[1,0,0,1].eval())\n",
    "#     print(test[1,0,0,0].eval())\n",
    "# #     print(tf.gather_nd([[[1,0,0,1],[1,0,0,0]]],test))\n",
    "#     print(A.eval())\n",
    "#     print(\"\\n\")\n",
    "#     print(S.eval())\n",
    "#     # print(full_indices.eval())\n",
    "#     # print(tf.transpose(full_indices))\n",
    "#     print(idx2b.eval())\n",
    "#     print(tf.gather_nd(test2b,idx2b).eval())\n",
    "# #     print(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0).eval())\n",
    "# #     print(tf.reshape(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0),[-1]).eval())\n",
    "# #     print(tf.reshape(tf.transpose(tf.broadcast_to(B1_t,[4,8])),[-1]).eval())\n",
    "# #     print(tf.broadcast_to(tf.concat([holes,particles],1),[4,4]).eval())\n",
    "# #     print(tf.reshape(test,[-1]).eval())\n",
    "# # session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.constant(1)\n",
    "# shape = a.shape\n",
    "# print(len(shape))\n",
    "\n",
    "# def off_diagonal(tensor):\n",
    "#     # returns off diagonal elements defined by indices ph,hp (1B) or pphh,hhpp (2B)\n",
    "#     shape = tensor.shape\n",
    "#     if(shape==() or len(shape)==1):\n",
    "#         return 0\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hols = np.asarray([0,1,2,3])\n",
    "# pars = np.asarray([4,5,6,7])\n",
    "\n",
    "# count = 0\n",
    "# for p in pars:\n",
    "#     for pp in pars:\n",
    "#         for h in hols:\n",
    "#             for hh in hols:\n",
    "# #                 print(p,pp,h,hh)\n",
    "#                 count += 1\n",
    "                \n",
    "# print(count)\n",
    "\n",
    "# indices are p,pp,h,hh\n",
    "# for every possible combination:\n",
    "#\n",
    "# p   --> switches every 64 states - 2^6\n",
    "# pp  --> switches every 16 states - 2^4\n",
    "# h   --> switches every 04 states - 2^2\n",
    "# hh  --> swithces every 01 states - 2^0\n",
    "\n",
    "# ind1_C = tf.concat([tf.broadcast_to(holes,[64,4]), tf.broadcast_to(particles,[64,4])],1)\n",
    "# ind1_TC = tf.transpose(ind1_C) \n",
    "# ind1 = tf.reshape(ind1_TC,[-1])\n",
    "\n",
    "# ind2_C = tf.concat([tf.broadcast_to(holes,[16,16]),tf.broadcast_to(particles,[16,16])],1)\n",
    "# ind2_TC = tf.transpose(ind2_C)\n",
    "# ind2 = tf.reshape(ind2_TC,[-1])\n",
    "\n",
    "# ind3_C = tf.concat([tf.broadcast_to(particles,[4,64]),tf.broadcast_to(holes,[4,64])],1)\n",
    "# ind3_TC = tf.transpose(ind3_C) \n",
    "# ind3 = tf.reshape(ind3_TC,[-1])\n",
    "\n",
    "# ind4_C = tf.concat([tf.broadcast_to(particles,[1,256]),tf.broadcast_to(holes,[1,256])],1)\n",
    "# ind4_TC = tf.transpose(ind4_C)\n",
    "# ind4 = tf.reshape(ind4_TC,[-1])\n",
    "\n",
    "# pphh_ind = tf.stack([ind1,ind2,ind3,ind4],axis=1)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print(pphh_ind.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "testing_tensorflow_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
