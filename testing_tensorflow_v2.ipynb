{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/davis9ja/im-srg_tensorflow/blob/master/testing_tensorflow_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "12WjV8yIyAb0",
    "outputId": "3ddb6ce6-28af-434f-bce6-dcaa221a307a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.integrate import odeint, ode\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQZeGM1NyHBk"
   },
   "outputs": [],
   "source": [
    "# --- BUILD HAMILTONIAN -----------\n",
    "def build_hamiltonian(n_hole_states, n_particle_states):\n",
    "    numh = n_hole_states\n",
    "    nump = n_particle_states\n",
    "    nums = numh + nump\n",
    "    \n",
    "    ref = np.append(np.ones(numh), np.zeros(nump))\n",
    "    holes = np.arange(numh)\n",
    "    particles = np.arange(numh,numh+nump)\n",
    "    B1 = np.append(holes,particles)\n",
    "    \n",
    "    # one body part of Hamiltonian is floor-division of basis index\n",
    "    # matrix elements are (P-1) where P is energy level\n",
    "    H1B = np.diag(np.floor_divide(B1,2))\n",
    "\n",
    "    H2B = np.zeros((nums, nums, nums, nums))\n",
    "    for p in B1:\n",
    "        for q in B1:\n",
    "            for r in B1:\n",
    "                for s in B1:\n",
    "\n",
    "                    pp = np.floor_divide(p,2)\n",
    "                    qp = np.floor_divide(q,2)\n",
    "                    rp = np.floor_divide(r,2)\n",
    "                    sp = np.floor_divide(s,2)\n",
    "\n",
    "                    ps = 1 if p%2==0 else -1\n",
    "                    qs = 1 if q%2==0 else -1\n",
    "                    rs = 1 if r%2==0 else -1\n",
    "                    ss = 1 if s%2==0 else -1\n",
    "\n",
    "                    if pp != qp or rp != sp:\n",
    "                        continue\n",
    "                    if ps == qs or rs == ss:\n",
    "                        continue\n",
    "                    if ps == rs and qs == ss:\n",
    "                        H2B[p,q,r,s] = -0.25\n",
    "                    if ps == ss and qs == rs:\n",
    "                        H2B[p,q,r,s] = 0.25\n",
    "                        \n",
    "    return (H1B, H2B, ref, holes, particles, B1)\n",
    "\n",
    "# covers na - nb\n",
    "def get_occA(B1_basis):\n",
    "    n = len(B1_basis)\n",
    "    occA = np.zeros((n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            occA[a,b,a,b] = ref[a] - ref[b]\n",
    "            \n",
    "    return occA\n",
    "        \n",
    "# covers (1-na-nb)\n",
    "def get_occB(B1_basis):\n",
    "    n = len(B1_basis)    \n",
    "    occB = np.zeros((n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            occB[a,b,a,b] = 1 - ref[a] - ref[b]\n",
    "            \n",
    "    return occB\n",
    "        \n",
    "# covers na*nb + (1-na-nb)*nc\n",
    "def get_occC(B1_basis):\n",
    "    n = len(B1_basis)        \n",
    "    occC = np.zeros((n,n,n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            for c in B1_basis:\n",
    "                occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]\n",
    "                \n",
    "    return occC\n",
    "\n",
    "# covers na*nb*(1-nc-nd) + na*nb*nc*nd\n",
    "def get_occD(B1_basis):\n",
    "    n = len(B1_basis)    \n",
    "    occD = np.zeros((n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            for c in B1_basis:\n",
    "                for d in B1_basis:\n",
    "                    occD[a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]\n",
    "                    \n",
    "    return occD\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "t-gCmAPvyp4z",
    "outputId": "5c7228c6-8225-4e6b-9958-74543aa7156f"
   },
   "outputs": [],
   "source": [
    "# --- NORMAL ORDER HAMILTONIAN -----------\n",
    "# Calculate 0b, 1b, 2b pieces \n",
    "#\n",
    "# zero-body piece is scalar\n",
    "# one-body piece is rank 2 tensor\n",
    "# two-body piece is rank 4 tensor\n",
    "\n",
    "def normal_order(H1B_t, H2B_t, holes):\n",
    "\n",
    "    # - Calculate 0B tensor\n",
    "    # E = tf.Variable(0.0)\n",
    "    contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)\n",
    "    contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)\n",
    "\n",
    "    E_1b = tf.reduce_sum(contr_1b, 0)\n",
    "    E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])\n",
    "    E = tf.add_n([E_1b, E_2b])\n",
    "\n",
    "    # - Calculate 1B tensor\n",
    "    contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)\n",
    "    contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes\n",
    "\n",
    "    f = tf.add_n([H1B_t, contr_2b])\n",
    "\n",
    "    # - Calculate 2B tensor\n",
    "    G = tf.identity(H2B_t)\n",
    "    \n",
    "    return (E, f, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwn3kw6yeUQO"
   },
   "outputs": [],
   "source": [
    "# # --- SET UP WHITE'S GENERATOR -----------\n",
    "\n",
    "# # TODO: try reduce_sum, einsum, tensordot?, other methods\n",
    "\n",
    "# def white(f, G, holes, particles):\n",
    "  \n",
    "#     # - Calculate 1b generator tensor\n",
    "#     # indices are constructed by all possible combinations of pp and hh states\n",
    "#     p1_ind = tf.reshape(tf.broadcast_to(particles,[4,4]), [-1])\n",
    "#     p2_ind = tf.reshape(tf.transpose(tf.broadcast_to(particles,[4,4])), [-1])\n",
    "#     pp_indices = tf.stack([p1_ind, p2_ind], axis=1)\n",
    "#     pp_updates = tf.gather_nd(f, pp_indices)\n",
    "    \n",
    "#     h1_ind = tf.reshape(tf.broadcast_to(holes,[4,4]), [-1])\n",
    "#     h2_ind = tf.reshape(tf.transpose(tf.broadcast_to(holes,[4,4])), [-1])\n",
    "#     hh_indices = tf.stack([h1_ind, h2_ind], axis=1)\n",
    "#     hh_updates = tf.gather_nd(f, hh_indices)\n",
    "    \n",
    "#     fpp = tf.scatter_nd(pp_indices, pp_updates, f.shape)\n",
    "#     fhh = tf.scatter_nd(hh_indices, hh_updates, f.shape)\n",
    "    \n",
    "#     # indices are constructed by all possible combinations of phph states\n",
    "#     ind1_C = tf.broadcast_to(particles,[64,4])\n",
    "#     ind1_TC = tf.transpose(ind1_C) \n",
    "#     ind1 = tf.reshape(ind1_TC,[-1])\n",
    "\n",
    "#     ind2_C = tf.broadcast_to(holes,[16,16])\n",
    "#     ind2_TC = tf.transpose(ind2_C)\n",
    "#     ind2 = tf.reshape(ind2_TC,[-1])\n",
    "\n",
    "#     ind3_C = tf.broadcast_to(particles,[4,64])\n",
    "#     ind3_TC = tf.transpose(ind3_C) \n",
    "#     ind3 = tf.reshape(ind3_TC,[-1])\n",
    "\n",
    "#     ind4_C = tf.broadcast_to(holes,[1,256])\n",
    "#     ind4_TC = tf.transpose(ind4_C)\n",
    "#     ind4 = tf.reshape(ind4_TC,[-1])\n",
    "\n",
    "#     phph_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)\n",
    "#     phph_updates = tf.gather_nd(G, phph_indices)\n",
    "\n",
    "#     Gphph = tf.scatter_nd(phph_indices, phph_updates, G.shape)\n",
    "#     Gphph_red = tf.reduce_sum(Gphph, [0,1])\n",
    "    \n",
    "#     delta_ph = tf.add(tf.subtract(fpp, fhh), Gphph_red)\n",
    "    \n",
    "#     ph_indices = tf.stack([p1_ind, h2_ind], axis=1)\n",
    "#     ph_updates = tf.gather_nd(f, ph_indices)\n",
    "#     fph = tf.scatter_nd(ph_indices, ph_updates, f.shape)\n",
    "    \n",
    "#     eta1B = tf.div_no_nan(fph, delta_ph)\n",
    "    \n",
    "#     # - Calculate 2b generator tensor\n",
    "#     eta2B = tf.zeros(G.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# #     return temp\n",
    "#     return (eta1B, pp_indices, delta_ph)\n",
    "# #     return (eta1B, eta2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SET UP WEGNER'S GENERATOR -----------\n",
    "\n",
    "def wegner(f, G):\n",
    "\n",
    "    # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP\n",
    "\n",
    "    # Decoupling 1B piece\n",
    "    # indices are constructed by all possible combinations of particle-hole(hole-particle) states\n",
    "    col_indices =tf.reshape(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0),[-1])\n",
    "    row_indices = tf.reshape(tf.transpose(tf.concat([tf.broadcast_to(holes,[4,4]),tf.broadcast_to(particles,[4,4])],1)),[-1])\n",
    "    ph_indices = tf.stack([row_indices, col_indices], axis=1)\n",
    "    ph_updates = tf.gather_nd(f, ph_indices)\n",
    "\n",
    "    fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)\n",
    "    fd = tf.subtract(f,fod)\n",
    "\n",
    "    # Decoupling 2B piece\n",
    "    # indices are constructed by all possible combinations of pphh(hhpp) states\n",
    "    ind1_C = tf.concat([tf.broadcast_to(holes,[64,4]), tf.broadcast_to(particles,[64,4])],1)\n",
    "    ind1_TC = tf.transpose(ind1_C) \n",
    "    ind1 = tf.reshape(ind1_TC,[-1])\n",
    "\n",
    "    ind2_C = tf.concat([tf.broadcast_to(holes,[16,16]),tf.broadcast_to(particles,[16,16])],1)\n",
    "    ind2_TC = tf.transpose(ind2_C)\n",
    "    ind2 = tf.reshape(ind2_TC,[-1])\n",
    "\n",
    "    ind3_C = tf.concat([tf.broadcast_to(particles,[4,64]),tf.broadcast_to(holes,[4,64])],1)\n",
    "    ind3_TC = tf.transpose(ind3_C) \n",
    "    ind3 = tf.reshape(ind3_TC,[-1])\n",
    "\n",
    "    ind4_C = tf.concat([tf.broadcast_to(particles,[1,256]),tf.broadcast_to(holes,[1,256])],1)\n",
    "    ind4_TC = tf.transpose(ind4_C)\n",
    "    ind4 = tf.reshape(ind4_TC,[-1])\n",
    "\n",
    "    pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)\n",
    "    pphh_updates = tf.gather_nd(G, pphh_indices)\n",
    "\n",
    "    God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)\n",
    "    Gd = tf.subtract(G,God)\n",
    "\n",
    "\n",
    "    # --- 1B piece\n",
    "\n",
    "    # Calculate 1B-1B contribution\n",
    "    fd_fod = tf.tensordot(fd,fod,1)\n",
    "    fd_fod_T = tf.transpose(fd_fod)\n",
    "    eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)\n",
    "\n",
    "    # Calculate 1B-2B contribution\n",
    "    fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))\n",
    "    fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))\n",
    "    eta1B_1b2b = tf.subtract(fd_God, fod_Gd)\n",
    "\n",
    "    # Calculate 2B-2B contribution\n",
    "    Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))\n",
    "    Gd_God_T = tf.transpose(Gd_God)\n",
    "    scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(Gd_God,Gd_God_T))\n",
    "    eta1B_2b2b = scaled_sub\n",
    "    \n",
    "    eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])\n",
    "\n",
    "\n",
    "\n",
    "    # --- 2B piece\n",
    "\n",
    "    # Calculate 1B-2B contribution\n",
    "    fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )\n",
    "    fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])\n",
    "    ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)\n",
    "\n",
    "    fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )\n",
    "    fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order\n",
    "    fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])\n",
    "    kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)\n",
    "\n",
    "    eta2B_1b2b = tf.subtract(ij_term,kl_term)\n",
    "\n",
    "\n",
    "    # Calculate 2B-2B contribution\n",
    "    GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])\n",
    "    GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])\n",
    "    scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(GdGod_occB,GodGd_occB))\n",
    "    \n",
    "    eta2B_2b2b_B = scaled_sub\n",
    "\n",
    "    GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])\n",
    "    GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "    GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])\n",
    "    GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])\n",
    "    GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])\n",
    "    GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])\n",
    "    sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)\n",
    "    sub2 = tf.subtract(sub1,GdGod_occA_Tkl)\n",
    "    add3 = tf.add(sub2,GdGod_occA_Tijkl)\n",
    "\n",
    "    eta2B_2b2b_A = add3\n",
    "    \n",
    "    eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])\n",
    "    \n",
    "    return (eta1B, eta2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WRITE FLOW EQUATIONS -----------\n",
    "\n",
    "def flow(f, G, eta1B, eta2B):\n",
    "\n",
    "    # --- 0B piece\n",
    "\n",
    "    # Calculate 1B-1B contribution (full contraction)\n",
    "    occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])\n",
    "    occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])\n",
    "    dE_1b1b = tf.identity(occA_e1_f)\n",
    "\n",
    "    # Calculate 2B-2B contribution (full contraction)\n",
    "#     e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])\n",
    "    e2_occD = tf.matmul(eta2B, occD_t)\n",
    "    e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])\n",
    "    dE_2b2b = tf.identity(e2_occD_G)\n",
    "\n",
    "    dE = tf.add_n([dE_1b1b, dE_2b2b])\n",
    "\n",
    "    # --- 1B piece\n",
    "    \n",
    "    # Calculate 1B-1B contribution (contraction over 1 index)\n",
    "    e1_f = tf.tensordot(eta1B,f,[[1],[0]])\n",
    "    e1_f_T = tf.transpose(e1_f)\n",
    "    e1_f_add = tf.add(e1_f,e1_f_T)\n",
    "    df_1b1b = tf.identity(e1_f_add)\n",
    "\n",
    "    # Calculate 1B-2B contribution (contraction over 2 indices)\n",
    "    occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])\n",
    "    occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])\n",
    "    sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)\n",
    "    df_1b2b = tf.identity(sub_1b2b)\n",
    "\n",
    "    # Calculate 2B-2B contribution (contraction over 3 indices)\n",
    "    e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])\n",
    "    e2_occC_G_T = tf.transpose(e2_occC_G)\n",
    "    add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)\n",
    "    df_2b2b = tf.identity(add_2b2b)\n",
    "\n",
    "    df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])\n",
    "\n",
    "    # --- 2B piece\n",
    "\n",
    "    # Calculate 1B-2B contribution (contraction over 1 index)\n",
    "    e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))\n",
    "    e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])\n",
    "    ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)\n",
    "\n",
    "    e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))\n",
    "    e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order\n",
    "    e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])\n",
    "    kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)\n",
    "\n",
    "    dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))\n",
    "\n",
    "    # Calculate 2B-2B contribution (occB term)\n",
    "    e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])\n",
    "    G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])\n",
    "    sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)\n",
    "\n",
    "    dG_2b2b_B = tf.identity(sub_term)\n",
    "\n",
    "    # Calculate 2B-2B contribution (occA term)\n",
    "    e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])\n",
    "    e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "    e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])\n",
    "    e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])\n",
    "    e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])\n",
    "    e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])\n",
    "    sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)\n",
    "    sub2 = tf.subtract(sub1, e2G_occA_Tkl)\n",
    "    add3 = tf.add(sub2, e2G_occA_Tijkl)\n",
    "\n",
    "    dG_2b2b_A = tf.identity(add3)\n",
    "\n",
    "    dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])\n",
    "\n",
    "    return (dE, df, dG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEFINE DERIVATIVE TO PASS INTO ODEINT SOLVER -----------\n",
    "# The input is an *evaluated graph* (numpy array); the output \n",
    "# is also an evaluated graph. Formatting in this way allows\n",
    "# for compability with scipy.ode; the tensorflow ode \n",
    "# package will be deprecated in TF v2.0\n",
    "\n",
    "def derivative(t, y):\n",
    "\n",
    "    y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "    \n",
    "    E, f, G = ravel(y)\n",
    "    \n",
    "#     E = tf.convert_to_tensor(E, dtype=tf.float32)\n",
    "#     f = tf.convert_to_tensor(f, dtype=tf.float32)\n",
    "#     G = tf.convert_to_tensor(G, dtype=tf.float32)\n",
    "    \n",
    "    eta1B, eta2B = wegner(f, G)\n",
    "    \n",
    "    dE, df, dG = flow(f, G, eta1B, eta2B)\n",
    "    \n",
    "    dy = unravel(dE, df, dG)\n",
    "    \n",
    "    return dy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONVERT NORMAL ORDERED TENSORS INTO RANK 1 TENSOR -----------\n",
    "# Quality-of-life methods that facilite compatibility with scipy.ode\n",
    "\n",
    "def unravel(E, f, G):\n",
    "    unravel_E = tf.reshape(E, [-1])\n",
    "    unravel_f = tf.reshape(f, [-1])\n",
    "    unravel_G = tf.reshape(G, [-1])\n",
    "    \n",
    "    return tf.concat([unravel_E, unravel_f, unravel_G], 0)\n",
    "\n",
    "def ravel(y):\n",
    "    \n",
    "    ravel_E = tf.reshape(y[0], ())\n",
    "    ravel_f = tf.reshape(y[1:65], (8,8))\n",
    "    ravel_G = tf.reshape(y[65:65+4096], (8,8,8,8))\n",
    "    \n",
    "    return(ravel_E, ravel_f, ravel_G)\n",
    "\n",
    "# def unravel(E, f, G):\n",
    "#     unravel_E = np.reshape(E, -1)\n",
    "#     unravel_f = np.reshape(f, -1)\n",
    "#     unravel_G = np.reshape(G, -1)\n",
    "    \n",
    "#     return np.concatenate([unravel_E, unravel_f, unravel_G], axis=0)\n",
    "\n",
    "# def ravel(y):\n",
    "    \n",
    "#     ravel_E = np.reshape(y[0], ())\n",
    "#     ravel_f = np.reshape(y[1:65], (8,8))\n",
    "#     ravel_G = np.reshape(y[65:65+4096], (8,8,8,8))\n",
    "    \n",
    "#     return(ravel_E, ravel_f, ravel_G)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qqW27CGI0FF8",
    "outputId": "dbfb500f-ea0a-4e0d-f8d2-659b5719aa1b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.50000\n",
      "scale param: 0.0000 \t E = 1.49999\n",
      "scale param: 0.0000 \t E = 1.49999\n",
      "scale param: 0.0000 \t E = 1.49998\n",
      "scale param: 0.0000 \t E = 1.49997\n",
      "scale param: 0.0000 \t E = 1.49993\n",
      "scale param: 0.0001 \t E = 1.49983\n",
      "scale param: 0.0002 \t E = 1.49973\n",
      "scale param: 0.0002 \t E = 1.49957\n",
      "scale param: 0.0003 \t E = 1.49941\n",
      "scale param: 0.0004 \t E = 1.49925\n",
      "scale param: 0.0006 \t E = 1.49894\n",
      "scale param: 0.0010 \t E = 1.49821\n",
      "scale param: 0.0015 \t E = 1.49749\n",
      "scale param: 0.0021 \t E = 1.49639\n",
      "scale param: 0.0028 \t E = 1.49531\n",
      "scale param: 0.0035 \t E = 1.49426\n",
      "scale param: 0.0042 \t E = 1.49324\n",
      "scale param: 0.0054 \t E = 1.49139\n",
      "scale param: 0.0067 \t E = 1.48961\n",
      "scale param: 0.0079 \t E = 1.48791\n",
      "scale param: 0.0092 \t E = 1.48628\n",
      "scale param: 0.0104 \t E = 1.48471\n",
      "scale param: 0.0117 \t E = 1.48321\n",
      "scale param: 0.0130 \t E = 1.48176\n",
      "scale param: 0.0165 \t E = 1.47800\n",
      "scale param: 0.0189 \t E = 1.47566\n",
      "scale param: 0.0212 \t E = 1.47348\n",
      "scale param: 0.0236 \t E = 1.47143\n",
      "scale param: 0.0260 \t E = 1.46951\n",
      "scale param: 0.0284 \t E = 1.46770\n",
      "scale param: 0.0308 \t E = 1.46600\n",
      "scale param: 0.0332 \t E = 1.46439\n",
      "scale param: 0.0368 \t E = 1.46209\n",
      "scale param: 0.0405 \t E = 1.45996\n",
      "scale param: 0.0442 \t E = 1.45800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-344c58498f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccessful\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msfinal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mEs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# outputs tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mEs_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/integrate/_ode.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t, step, relax)\u001b[0m\n\u001b[1;32m    430\u001b[0m             self._y, self.t = mth(self.f, self.jac or (lambda: None),\n\u001b[1;32m    431\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                                   self.f_params, self.jac_params)\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# f2py issue with tuple returns, see ticket 1187.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/integrate/_ode.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0mitask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/integrate/_ode.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, f, jac, y0, t0, t1, f_params, jac_params)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         args = ((f, jac, y0, t0, t1) + tuple(self.call_args) +\n\u001b[1;32m   1003\u001b[0m                 (f_params, jac_params))\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mistate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mistate\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-67c140334cab>\u001b[0m in \u001b[0;36mderivative\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- MAIN PROCEDURE -----------\n",
    "# Build and normal-order Hamiltonian\n",
    "# Build some useful occupation tensors (for Wegner's generator and flow equations)\n",
    "# Execute flow graph and repeat until satisfactory convergence of E\n",
    "\n",
    "# with tf.device(\"/cpu:0\"):\n",
    "H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(4,4)\n",
    "\n",
    "ref_t = tf.convert_to_tensor(ref)\n",
    "\n",
    "B1_t = tf.convert_to_tensor(B1, dtype=tf.int32)\n",
    "holes = tf.convert_to_tensor(holes, dtype=tf.int32)\n",
    "particles = tf.convert_to_tensor(particles, dtype=tf.int32)\n",
    "\n",
    "H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32)\n",
    "H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32)\n",
    "\n",
    "occA_t = tf.convert_to_tensor(get_occA(B1), dtype=tf.float32)\n",
    "occB_t = tf.convert_to_tensor(get_occB(B1), dtype=tf.float32)\n",
    "occC_t = tf.convert_to_tensor(get_occC(B1), dtype=tf.float32)\n",
    "occD_t = tf.convert_to_tensor(get_occD(B1), dtype=tf.float32)\n",
    "\n",
    "E, f, G = normal_order(H1B_t, H2B_t, holes)\n",
    "\n",
    "# def run(E, f, G):\n",
    "\n",
    "#     with tf.Session() as sess:\n",
    "#         y0 = unravel(E, f, G)\n",
    "#         y0_eval = y0.eval()\n",
    "# #         print(y0_eval.shape)\n",
    "#         t = 1\n",
    "#         dy = derivative(t, y0_eval)\n",
    "        \n",
    "#         dE, df, dG = ravel(dy)\n",
    "#         print(dE.eval())\n",
    "# #         print(dG[0,1,4,5])\n",
    "# %timeit run(E, f, G)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    y0 = unravel(E, f, G)\n",
    "    y0_eval = y0.eval()\n",
    "#     print(y0_eval.shape)\n",
    "    solver = ode(derivative,jac=None)\n",
    "    solver.set_integrator('vode', method='bdf', order=5, nsteps=1000)\n",
    "#     solver.set_f_params(len(f), len(Y))\n",
    "    solver.set_initial_value(y0_eval, 0.)\n",
    "\n",
    "    sfinal = 7\n",
    "    ds = 0.1\n",
    "    s_vals = []\n",
    "    E_vals = []\n",
    "    \n",
    "    while solver.successful() and solver.t < sfinal:\n",
    "        ys = solver.integrate(sfinal, step=True)\n",
    "        Es, fs, Gs = ravel(ys) # outputs tensors\n",
    "        Es_e = Es.eval()\n",
    "        print(\"scale param: {:0.4f} \\t E = {:0.5f}\".format(solver.t,Es_e))\n",
    "        s_vals.append(solver.t)\n",
    "        E_vals.append(Es_e)\n",
    "#         if len(E_vals) > 1 and E_vals[-2] - E_vals[-1] > 0 and E_vals[-2] - E_vals[-1] < 10**-6\n",
    "        \n",
    "#     plt.plot(s_vals, E_vals)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqTTHpAJ4JPT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "testing_tensorflow_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
