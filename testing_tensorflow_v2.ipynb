{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/davis9ja/im-srg_tensorflow/blob/master/testing_tensorflow_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "12WjV8yIyAb0",
    "outputId": "3ddb6ce6-28af-434f-bce6-dcaa221a307a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "[0 1 2 3] [4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.integrate import odeint, ode\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "\n",
    "numh = 4\n",
    "nump = 4\n",
    "holes = np.arange(numh)\n",
    "particles = np.arange(numh,numh+nump)\n",
    "\n",
    "print(holes, particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQZeGM1NyHBk"
   },
   "outputs": [],
   "source": [
    "# --- BUILD HAMILTONIAN -----------\n",
    "def build_hamiltonian(n_hole_states, n_particle_states):\n",
    "    numh = n_hole_states\n",
    "    nump = n_particle_states\n",
    "    nums = numh + nump\n",
    "    \n",
    "    ref = np.append(np.ones(numh), np.zeros(nump))\n",
    "    holes = np.arange(numh)\n",
    "    particles = np.arange(numh,numh+nump)\n",
    "    B1 = np.append(holes,particles)\n",
    "    \n",
    "    # one body part of Hamiltonian is floor-division of basis index\n",
    "    # matrix elements are (P-1) where P is energy level\n",
    "    H1B = np.diag(np.floor_divide(B1,2))\n",
    "\n",
    "    H2B = np.zeros((nums, nums, nums, nums))\n",
    "    for p in B1:\n",
    "        for q in B1:\n",
    "            for r in B1:\n",
    "                for s in B1:\n",
    "\n",
    "                    pp = np.floor_divide(p,2)\n",
    "                    qp = np.floor_divide(q,2)\n",
    "                    rp = np.floor_divide(r,2)\n",
    "                    sp = np.floor_divide(s,2)\n",
    "\n",
    "                    ps = 1 if p%2==0 else -1\n",
    "                    qs = 1 if q%2==0 else -1\n",
    "                    rs = 1 if r%2==0 else -1\n",
    "                    ss = 1 if s%2==0 else -1\n",
    "\n",
    "                    if pp != qp or rp != sp:\n",
    "                        continue\n",
    "                    if ps == qs or rs == ss:\n",
    "                        continue\n",
    "                    if ps == rs and qs == ss:\n",
    "                        H2B[p,q,r,s] = -0.25\n",
    "                    if ps == ss and qs == rs:\n",
    "                        H2B[p,q,r,s] = 0.25\n",
    "                        \n",
    "    return (H1B, H2B, ref, holes, particles, B1)\n",
    "\n",
    "# covers na - nb\n",
    "def get_occA(B1_basis):\n",
    "    n = len(B1_basis)\n",
    "    occA = np.zeros((n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            occA[a,b,a,b] = ref[a] - ref[b]\n",
    "            \n",
    "    return occA\n",
    "        \n",
    "# covers (1-na-nb)\n",
    "def get_occB(B1_basis):\n",
    "    n = len(B1_basis)    \n",
    "    occB = np.zeros((n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            occB[a,b,a,b] = 1 - ref[a] - ref[b]\n",
    "            \n",
    "    return occB\n",
    "        \n",
    "# covers na*nb + (1-na-nb)*nc\n",
    "def get_occC(B1_basis):\n",
    "    n = len(B1_basis)        \n",
    "    occC = np.zeros((n,n,n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            for c in B1_basis:\n",
    "                occC[a,b,c,a,b,c] = ref[a]*ref[b] + (1-ref[a]-ref[b])*ref[c]\n",
    "                \n",
    "    return occC\n",
    "\n",
    "# covers na*nb*(1-nc-nd) + na*nb*nc*nd\n",
    "def get_occD(B1_basis):\n",
    "    n = len(B1_basis)    \n",
    "    occD = np.zeros((n,n,n,n,n,n,n,n))\n",
    "    \n",
    "    for a in B1_basis:\n",
    "        for b in B1_basis:\n",
    "            for c in B1_basis:\n",
    "                for d in B1_basis:\n",
    "                    occD[a,b,c,d,a,b,c,d] = ref[a]*ref[b]*(1-ref[c]-ref[d])+ref[a]*ref[b]*ref[c]*ref[d]\n",
    "                    \n",
    "    return occD\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "t-gCmAPvyp4z",
    "outputId": "5c7228c6-8225-4e6b-9958-74543aa7156f"
   },
   "outputs": [],
   "source": [
    "# --- NORMAL ORDER HAMILTONIAN -----------\n",
    "# Calculate 0b, 1b, 2b pieces \n",
    "#\n",
    "# zero-body piece is scalar\n",
    "# one-body piece is rank 2 tensor\n",
    "# two-body piece is rank 4 tensor\n",
    "\n",
    "def normal_order(H1B_t, H2B_t, holes):\n",
    "\n",
    "    # - Calculate 0B tensor\n",
    "    # E = tf.Variable(0.0)\n",
    "    contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float32)\n",
    "    contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float32)\n",
    "\n",
    "    E_1b = tf.reduce_sum(contr_1b, 0)\n",
    "    E_2b = 0.5*tf.reduce_sum(contr_2b, [0,1,2])\n",
    "    E = tf.add_n([E_1b, E_2b])\n",
    "\n",
    "    # - Calculate 1B tensor\n",
    "    # f = tf.Variable(tf.identity(H1B_t))\n",
    "    # f = tf.identity(H1B_t)\n",
    "    contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float32)\n",
    "    contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes\n",
    "\n",
    "    f = tf.add_n([H1B_t, contr_2b])\n",
    "\n",
    "    # - Calculate 2B tensor\n",
    "    G = tf.identity(H2B_t)\n",
    "    \n",
    "    return (E, f, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwn3kw6yeUQO"
   },
   "outputs": [],
   "source": [
    "# --- SET UP WHITE'S GENERATOR -----------\n",
    "\n",
    "# TODO: try reduce_sum, einsum, tensordot?, other methods\n",
    "\n",
    "# def white(f, G, holes, particles):\n",
    "  \n",
    "#     # - Calculate 1b generator tensor\n",
    "#     eta1B = tf.identity(f)\n",
    "#     eta1Bph = eta1B[particles[0]:particles[-1]+1,holes[0]:holes[-1]+1]\n",
    "#     fhh = f[holes[0]:holes[-1]+1,holes[0]:holes[-1]+1]\n",
    "#     fpp = f[particles[0]:particles[-1]+1,particles[0]:particles[-1]+1]\n",
    "#     Gphph = G[particles[0]:particles[-1]+1, holes[0]:holes[-1]+1, particles[0]:particles[-1]+1, holes[0]:holes[-1]+1]\n",
    "#     Gphph = tf.reduce_sum(Gphph,[0,1]) # reduce to same rank as f\n",
    "    \n",
    "#     Deltaph = tf.subtract(fpp, tf.add(fhh,Gphph))\n",
    "#     temp = tf.div_no_nan(eta1Bph,Deltaph)\n",
    "    \n",
    "#     top_block = tf.zeros((4,4))\n",
    "#     bottom_block = tf.zeros((4,8))\n",
    "#     conc_top = tf.concat([top_block, temp],1)\n",
    "#     eta1B = tf.concat([conc_top, bottom_block], 0)\n",
    "    \n",
    "#     # - Calculate 2b generator tensor\n",
    "#     eta2B = tf.zeros(G.shape)\n",
    "# #     return temp\n",
    "#     return eta1B\n",
    "# #     return (eta1B, eta2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SET UP WEGNER'S GENERATOR -----------\n",
    "\n",
    "def wegner(f, G):\n",
    "# basis = tf.concat([holes, particles],0)\n",
    "\n",
    "    # --- Need to decouple diagonal and off-diagonal elements; procedure in Ch.10 AACCNP\n",
    "\n",
    "    # Decoupling 1B piece\n",
    "    # indices are constructed by all possible combinations of particle-hole(hole-particle) states\n",
    "    col_indices =tf.reshape(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0),[-1])\n",
    "    row_indices = tf.reshape(tf.transpose(tf.concat([tf.broadcast_to(holes,[4,4]),tf.broadcast_to(particles,[4,4])],1)),[-1])\n",
    "    ph_indices = tf.stack([row_indices, col_indices], axis=1)\n",
    "    ph_updates = tf.gather_nd(f, ph_indices)\n",
    "\n",
    "    fod = tf.scatter_nd(ph_indices,ph_updates,f.shape)\n",
    "    fd = tf.subtract(f,fod)\n",
    "\n",
    "    # Decoupling 2B piece\n",
    "    # indices are constructed by all possible combinations of pphh(hhpp) states\n",
    "    ind1_C = tf.concat([tf.broadcast_to(holes,[64,4]), tf.broadcast_to(particles,[64,4])],1)\n",
    "    ind1_TC = tf.transpose(ind1_C) \n",
    "    ind1 = tf.reshape(ind1_TC,[-1])\n",
    "\n",
    "    ind2_C = tf.concat([tf.broadcast_to(holes,[16,16]),tf.broadcast_to(particles,[16,16])],1)\n",
    "    ind2_TC = tf.transpose(ind2_C)\n",
    "    ind2 = tf.reshape(ind2_TC,[-1])\n",
    "\n",
    "    ind3_C = tf.concat([tf.broadcast_to(particles,[4,64]),tf.broadcast_to(holes,[4,64])],1)\n",
    "    ind3_TC = tf.transpose(ind3_C) \n",
    "    ind3 = tf.reshape(ind3_TC,[-1])\n",
    "\n",
    "    ind4_C = tf.concat([tf.broadcast_to(particles,[1,256]),tf.broadcast_to(holes,[1,256])],1)\n",
    "    ind4_TC = tf.transpose(ind4_C)\n",
    "    ind4 = tf.reshape(ind4_TC,[-1])\n",
    "\n",
    "    pphh_indices = tf.stack([ind1,ind2,ind3,ind4],axis=1)\n",
    "    pphh_updates = tf.gather_nd(G, pphh_indices)\n",
    "\n",
    "    God = tf.scatter_nd(pphh_indices,pphh_updates,G.shape)\n",
    "    Gd = tf.subtract(G,God)\n",
    "\n",
    "\n",
    "    # --- 1B piece\n",
    "#     eta1B = tf.Variable(tf.zeros(f.shape))\n",
    "\n",
    "    # Calculate 1B-1B contribution\n",
    "    fd_fod = tf.tensordot(fd,fod,1)\n",
    "    fd_fod_T = tf.transpose(fd_fod)\n",
    "    eta1B_1b1b = tf.subtract(fd_fod, fd_fod_T)\n",
    "\n",
    "    # fod_fd = tf.tensordot(fod,fd,1)\n",
    "    # eta1B = tf.assign_add(eta1B, tf.subtract(fd_fod, fod_fd))\n",
    "\n",
    "\n",
    "    # Calculate 1B-2B contribution\n",
    "    fd_God = tf.tensordot(fd, tf.tensordot(occA_t,God,([0,1],[2,0])),([0,1],[2,0]))\n",
    "    fod_Gd = tf.tensordot(fod, tf.tensordot(occA_t,Gd,([0,1],[2,0])),([0,1],[2,0]))\n",
    "    eta1B_1b2b = tf.subtract(fd_God, fod_Gd)\n",
    "\n",
    "\n",
    "    # Calculate 2B-2B contribution\n",
    "    Gd_God = tf.tensordot(Gd, tf.tensordot(occC_t,God,([0,1,2],[0,1,2])),([2,3,1],[0,1,2]))\n",
    "    Gd_God_T = tf.transpose(Gd_God)\n",
    "    scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(Gd_God,Gd_God_T))\n",
    "    eta1B_2b2b = scaled_sub\n",
    "    \n",
    "    eta1B = tf.add_n([eta1B_1b1b, eta1B_1b2b, eta1B_2b2b])\n",
    "\n",
    "    #     God_Gd = tf.tensordot(God, tf.tensordot(occC_t,Gd,([0,1,2],[0,1,2])),([0,1,2],[2,3,1]))\n",
    "    #     scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(Gd_God,God_Gd))\n",
    "    #     eta1B = tf.assign_add(eta1B, scaled_sub)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # --- 2B piece\n",
    "#     eta2B = tf.Variable(tf.zeros(G.shape))\n",
    "\n",
    "    # Calculate 1B-2B contribution\n",
    "    fdGod_fodGd_ij = tf.subtract( tf.tensordot(fd,God,[[1],[0]]), tf.tensordot(fod,Gd,[[1],[0]]) )\n",
    "    fdGod_fodGd_ij_T = tf.transpose(fdGod_fodGd_ij, perm=[1,0,2,3])\n",
    "    ij_term = tf.subtract(fdGod_fodGd_ij,fdGod_fodGd_ij_T)\n",
    "\n",
    "    # Godfd_Gdfod_ij = tf.subtract( tf.tensordot(God,fd,([0],[1])), tf.tensordot(Gd,fod,([0],[1])) )\n",
    "    # ij_term = tf.subtract(fdGod_fodGd_ij,Godfd_Gdfod_ij)\n",
    "\n",
    "    fdGod_fodGd_kl = tf.subtract( tf.tensordot(fd,God,[[0],[2]]), tf.tensordot(fod,Gd,[[0],[2]]) )\n",
    "    fdGod_fodGd_kl = tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3]) # permute back to i,j,k,l order\n",
    "    fdGod_fodGd_kl_T = tf.transpose(fdGod_fodGd_kl,perm=[0,1,3,2])\n",
    "    kl_term = tf.subtract(fdGod_fodGd_kl,fdGod_fodGd_kl_T)\n",
    "\n",
    "    # Godfd_Gdfod_kl = tf.subtract( tf.tensordot(God,fd,([2],[0])), tf.tensordot(Gd,fod,([2],[0])) )\n",
    "    # kl_term = tf.subtract(fdGod_fodGd_kl,Godfd_Gdfod_kl)\n",
    "\n",
    "    eta2B_1b2b = tf.subtract(ij_term,kl_term)\n",
    "\n",
    "\n",
    "    # Calculate 2B-2B contribution\n",
    "    # GdGod_GodGd = tf.subtract( tf.tensordot(Gd,God,[[2,3],[0,1]]), tf.tensordot(God,Gd,[[2,3],[0,1]]) )\n",
    "    # GdGod_GodGd_occB = tf.tensordot(occB_t,GdGod_GodGd,[[2,3],[0,1]])\n",
    "\n",
    "    GdGod_occB = tf.tensordot(Gd, tf.tensordot(occB_t, God, [[0,1],[0,1]]), [[2,3],[0,1]])\n",
    "    GodGd_occB = tf.tensordot(God, tf.tensordot(occB_t, Gd, [[0,1],[0,1]]), [[2,3],[0,1]])\n",
    "    scaled_sub = tf.scalar_mul(tf.constant(0.5),tf.subtract(GdGod_occB,GodGd_occB))\n",
    "    # GdGod_occB = tf.tensordot( Gd, tf.tensordot(occB_t,God,[[0,1],[0,1]]), [[2,3],[0,1]] )\n",
    "    # GodGd_occB = tf.tensordot( God, tf.tensordot(occB_t,Gd,[[0,1],[0,1]]), [[2,3],[0,1]] )\n",
    "    # scaled_sub = tf.scalar_mul(tf.constant(0.5), tf.subtract(GdGod_occB,GodGd_occB))\n",
    "    eta2B_2b2b_B = scaled_sub\n",
    "\n",
    "    GdGod = tf.tensordot(Gd,God,[[0,2],[2,0]])\n",
    "    GdGod = tf.transpose(GdGod,perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "    GdGod_occA = tf.tensordot(occA_t,GdGod,[[2,3],[0,1]])\n",
    "    # GdGod_occA = tf.tensordot( Gd, tf.tensordot(occA_t,God,[[0,1],[2,0]]), [[0,2],[0,1]] )\n",
    "    # GdGod_occA = tf.transpose(GdGod_occA, perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "    GdGod_occA_Tij = tf.transpose(GdGod_occA,perm=[1,0,2,3])\n",
    "    GdGod_occA_Tkl = tf.transpose(GdGod_occA,perm=[0,1,3,2])\n",
    "    GdGod_occA_Tijkl = tf.transpose(GdGod_occA,perm=[1,0,3,2])\n",
    "    sub1 = tf.subtract(GdGod_occA,GdGod_occA_Tij)\n",
    "    sub2 = tf.subtract(sub1,GdGod_occA_Tkl)\n",
    "    add3 = tf.add(sub2,GdGod_occA_Tijkl)\n",
    "\n",
    "    eta2B_2b2b_A = add3\n",
    "    \n",
    "    eta2B = tf.add_n([eta2B_1b2b, eta2B_2b2b_B, eta2B_2b2b_A])\n",
    "    \n",
    "    return (eta1B, eta2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WRITE FLOW EQUATIONS -----------\n",
    "\n",
    "def flow(f, G, eta1B, eta2B):\n",
    "#     eta1B, eta2B = wegner(f,G)\n",
    "\n",
    "    # --- 0B piece\n",
    "    # dE = tf.Variable(0.0)\n",
    "\n",
    "    # Calculate 1B-1B contribution (full contraction)\n",
    "    occA_e1 = tf.tensordot(occA_t, eta1B, [[0,1],[0,1]])\n",
    "    occA_e1_f = tf.tensordot(occA_e1, f, [[0,1],[1,0]])\n",
    "    dE_1b1b = tf.identity(occA_e1_f)\n",
    "\n",
    "    # Calculate 2B-2B contribution (full contraction)\n",
    "    e2_occD = tf.tensordot(eta2B, occD_t, [[0,1,2,3],[0,1,2,3]])\n",
    "    e2_occD_G = 0.5*tf.tensordot(e2_occD, G, [[0,1,2,3],[2,3,0,1]])\n",
    "\n",
    "    # e2_occD_G = tf.scalar_mul(tf.constant(0.5),e2_occD_G)\n",
    "    dE_2b2b = tf.identity(e2_occD_G)\n",
    "\n",
    "    dE = tf.add_n([dE_1b1b, dE_2b2b])\n",
    "\n",
    "    # --- 1B piece\n",
    "    # df = tf.Variable(tf.zeros(f.shape))\n",
    "\n",
    "    # Calculate 1B-1B contribution (contraction over 1 index)\n",
    "    e1_f = tf.tensordot(eta1B,f,[[1],[0]])\n",
    "    e1_f_T = tf.transpose(e1_f)\n",
    "    e1_f_add = tf.add(e1_f,e1_f_T)\n",
    "    df_1b1b = tf.identity(e1_f_add)\n",
    "\n",
    "    # Calculate 1B-2B contribution (contraction over 2 indices)\n",
    "    occA_e1_G = tf.tensordot(occA_t, tf.tensordot(eta1B,G,[[0,1],[2,0]]), [[2,3],[0,1]])\n",
    "    occA_f_e2 = tf.tensordot(occA_t, tf.tensordot(f,eta2B,[[0,1],[2,0]]), [[2,3],[0,1]])\n",
    "    sub_1b2b = tf.subtract(occA_e1_G, occA_f_e2)\n",
    "    df_1b2b = tf.identity(sub_1b2b)\n",
    "\n",
    "    # Calculate 2B-2B contribution (contraction over 3 indices)\n",
    "    e2_occC_G = tf.tensordot(eta2B, tf.tensordot(occC_t,G,[[3,4,5],[0,1,2]]), [[2,3,0],[0,1,2]])\n",
    "    e2_occC_G_T = tf.transpose(e2_occC_G)\n",
    "    add_2b2b = 0.5*tf.add(e2_occC_G,e2_occC_G_T)\n",
    "    df_2b2b = tf.identity(add_2b2b)\n",
    "\n",
    "    df = tf.add_n([df_1b1b, df_1b2b, df_2b2b])\n",
    "\n",
    "    # --- 2B piece\n",
    "    # dG = tf.Variable(tf.zeros(G.shape))\n",
    "\n",
    "    # Calculate 1B-2B contribution (contraction over 1 index)\n",
    "    e1G_fe2_ij = tf.subtract(tf.tensordot(eta1B,G,[[1],[0]]), tf.tensordot(f,eta2B,[[1],[0]]))\n",
    "    e1G_fe2_ij_T = tf.transpose(e1G_fe2_ij, perm=[1,0,2,3])\n",
    "    ij_term = tf.subtract(e1G_fe2_ij,e1G_fe2_ij_T)\n",
    "\n",
    "    e1G_fe2_kl = tf.subtract(tf.tensordot(eta1B,G,[[0],[2]]), tf.tensordot(f,eta2B,[[0],[2]]))\n",
    "    e1G_fe2_kl = tf.transpose(e1G_fe2_kl, perm=[1,2,0,3]) # permute to i,j,k,l order\n",
    "    e1G_fe2_kl_T = tf.transpose(e1G_fe2_kl, perm=[0,1,3,2])\n",
    "    kl_term = tf.subtract(e1G_fe2_kl,e1G_fe2_kl_T)\n",
    "\n",
    "    dG_1b2b = tf.identity(tf.subtract(ij_term, kl_term))\n",
    "\n",
    "    # Calculate 2B-2B contribution (occB term)\n",
    "    e2_occB_G = tf.tensordot(eta2B, tf.tensordot(occB_t, G, [[2,3],[0,1]]), [[2,3],[0,1]])\n",
    "    G_occB_e2 = tf.tensordot(G, tf.tensordot(occB_t, eta2B, [[2,3],[0,1]]), [[2,3],[0,1]])\n",
    "    sub_term = 0.5*tf.subtract(e2_occB_G, G_occB_e2)\n",
    "#     e2G_Ge2 = tf.subtract(tf.tensordot(eta2B,G,[[2,3],[0,1]]), tf.tensordot(G,eta2B,[[2,3],[0,1]]))\n",
    "#     e2G_Ge2_occB = 0.5*tf.tensordot(occB_t,e2G_Ge2,[[2,3],[0,1]])\n",
    "\n",
    "    dG_2b2b_B = tf.identity(sub_term)\n",
    "\n",
    "    # Calculate 2B-2B contribution (occA term)\n",
    "    e2G = tf.tensordot(eta2B, G, [[0,2],[2,0]])\n",
    "    e2G = tf.transpose(e2G, perm=[0,2,1,3]) # permute back to i,j,k,l order\n",
    "    e2G_occA = tf.tensordot(occA_t, e2G, [[2,3],[0,1]])\n",
    "    e2G_occA_Tij = tf.transpose(e2G_occA, perm=[1,0,2,3])\n",
    "    e2G_occA_Tkl = tf.transpose(e2G_occA, perm=[0,1,3,2])\n",
    "    e2G_occA_Tijkl = tf.transpose(e2G_occA, perm=[1,0,3,2])\n",
    "    sub1 = tf.subtract(e2G_occA, e2G_occA_Tij)\n",
    "    sub2 = tf.subtract(sub1, e2G_occA_Tkl)\n",
    "    add3 = tf.add(sub2, e2G_occA_Tijkl)\n",
    "\n",
    "    dG_2b2b_A = tf.identity(add3)\n",
    "\n",
    "    dG = tf.add_n([dG_1b2b, dG_2b2b_B, dG_2b2b_A])\n",
    "\n",
    "    return (dE, df, dG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEFINE DERIVATIVE TO PASS INTO ODEINT SOLVER -----------\n",
    "# The input is an *evaluated graph* (numpy array); the output \n",
    "# is also an evaluated graph. Formatting in this way allows\n",
    "# for compability with scipy.ode; the tensorflow ode \n",
    "# package will be deprecated in TF v2.0\n",
    "\n",
    "def derivative(t, y):\n",
    "#     print(y.shape)\n",
    "    y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "    \n",
    "    E, f, G = ravel(y)\n",
    "    \n",
    "    eta1B, eta2B = wegner(f, G)\n",
    "    \n",
    "    dE, df, dG = flow(f, G, eta1B, eta2B)\n",
    "    \n",
    "    dy = unravel(dE, df, dG)\n",
    "    \n",
    "#     print(\"executed\")\n",
    "    \n",
    "    return dy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONVERT NORMAL ORDERED TENSORS INTO RANK 1 TENSOR -----------\n",
    "# Quality-of-life methods that facilite compatibility with scipy.ode\n",
    "\n",
    "def unravel(E, f, G):\n",
    "    unravel_E = tf.reshape(E, [-1])\n",
    "    unravel_f = tf.reshape(f, [-1])\n",
    "    unravel_G = tf.reshape(G, [-1])\n",
    "    \n",
    "    return tf.concat([unravel_E, unravel_f, unravel_G], 0)\n",
    "\n",
    "def ravel(y):\n",
    "    \n",
    "    ravel_E = tf.reshape(y[0], ())\n",
    "    ravel_f = tf.reshape(y[1:65], (8,8))\n",
    "    ravel_G = tf.reshape(y[65:65+4096], (8,8,8,8))\n",
    "    \n",
    "    return(ravel_E, ravel_f, ravel_G)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qqW27CGI0FF8",
    "outputId": "dbfb500f-ea0a-4e0d-f8d2-659b5719aa1b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0625\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN PROCEDURE -----------\n",
    "# Build and normal-order Hamiltonian\n",
    "# Build some useful occupation tensors (for Wegner's generator and flow equations)\n",
    "# Execute flow graph and repeat until satisfactory convergence of E\n",
    "\n",
    "H1B_t, H2B_t, ref, holes, particles, B1 = build_hamiltonian(4,4)\n",
    "\n",
    "ref_t = tf.convert_to_tensor(ref)\n",
    "\n",
    "B1_t = tf.convert_to_tensor(B1, dtype=tf.int32)\n",
    "holes = tf.convert_to_tensor(holes, dtype=tf.int32)\n",
    "particles = tf.convert_to_tensor(particles, dtype=tf.int32)\n",
    "\n",
    "H1B_t = tf.convert_to_tensor(H1B_t, dtype=tf.float32)\n",
    "H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float32)\n",
    "\n",
    "occA_t = tf.convert_to_tensor(get_occA(B1), dtype=tf.float32)\n",
    "occB_t = tf.convert_to_tensor(get_occB(B1), dtype=tf.float32)\n",
    "occC_t = tf.convert_to_tensor(get_occC(B1), dtype=tf.float32)\n",
    "occD_t = tf.convert_to_tensor(get_occD(B1), dtype=tf.float32)\n",
    "\n",
    "E, f, G = normal_order(H1B_t, H2B_t, holes)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y0 = unravel(E, f, G)\n",
    "    y0_eval = y0.eval()\n",
    "     \n",
    "    t = 1\n",
    "    dy = derivative(t, y0_eval)\n",
    "    \n",
    "    dE, df, dG = ravel(dy)\n",
    "#     print(G[0,1,4,5].eval())\n",
    "    print(dG[0,1,4,5].eval())\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "\n",
    "#     y0 = unravel(E, f, G)\n",
    "#     y0_eval = y0.eval()\n",
    "# #     print(y0_eval.shape)\n",
    "#     solver = ode(derivative,jac=None)\n",
    "#     solver.set_integrator('vode', method='bdf', order=5, nsteps=1000)\n",
    "# #     solver.set_f_params(len(f), len(Y))\n",
    "#     solver.set_initial_value(y0_eval, 0.)\n",
    "\n",
    "#     sfinal = 7\n",
    "#     ds = 0.1\n",
    "#     s_vals = []\n",
    "#     E_vals = []\n",
    "    \n",
    "#     while solver.successful() and solver.t < sfinal:\n",
    "#         ys = solver.integrate(sfinal, step=True)\n",
    "# #         Es, fs, Gs = ravel(ys) # outputs tensors\n",
    "# #         Es_e = Es.eval()\n",
    "# #         print(\"scale param: {:0.4f} \\t E = {:0.5f}\".format(solver.t,Es_e)\n",
    "# #         s_vals.append(solver.t)\n",
    "# #         E_vals.append(Es)\n",
    "#         if len(E_vals) > 1 and E_vals[-2] - E_vals[-1] > 0 and E_vals[-2] - E_vals[-1] < 10**-6\n",
    "        \n",
    "#     plt.plot(s_vals, E_vals)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqTTHpAJ4JPT"
   },
   "outputs": [],
   "source": [
    "#     print(ravel)\n",
    "#     print(dG[0,1,5,4].eval())\n",
    "\n",
    "#     test = np.zeros((8,8,8,8))\n",
    "#     test1 = np.zeros((8,8,8,8))\n",
    "#     test2 = np.zeros_like(test)\n",
    "#     test3 = np.zeros_like(test)\n",
    "#     test4 = np.zeros_like(test)\n",
    "#     eta2B_l = eta2B.eval()\n",
    "#     for i in B1:\n",
    "#         for j in B1:\n",
    "#             for k in B1:\n",
    "#                 for l in B1:\n",
    "# #                     for a in B1:\n",
    "#                     if(eta2B_l[i,j,k,l]>0):\n",
    "#                         print(eta2B_l[i,j,k,l],i,j,k,l)\n",
    "# #                         if(fd_l[a,k]*God_l[i,j,a,l] < 0 or fd_l[a,k]*God_l[i,j,a,l] > 0):\n",
    "# #                             print(fd_l[a,k]*God_l[i,j,a,l], a,\"|\",i,j,k,l)\n",
    "#                         test1[i,j,k,l] += fd_l[i,a]*God_l[a,j,k,l]\n",
    "#                         test2[i,j,k,l] += fd_l[j,a]*God_l[a,i,k,l]\n",
    "#                         test3[i,j,k,l] += fd_l[a,k]*God_l[i,j,a,l]\n",
    "#                         test4[i,j,k,l] += fd_l[a,l]*God_l[i,j,a,k]\n",
    "                        \n",
    "#                         test[i,j,k,l] += fd_l[i,a]*God_l[a,j,k,l] \\\n",
    "#                                        - fd_l[j,a]*God_l[a,i,k,l] \\\n",
    "#                                        - fd_l[a,k]*God_l[i,j,a,l] \\\n",
    "#                                        + fd_l[a,l]*God_l[i,j,a,k]\n",
    "#     print(test[0,1,4,5])\n",
    "#     print(test1[0,1,4,5],test2[0,1,4,5],test3[0,1,4,5],test4[0,1,4,5])\n",
    "# #     print(tf.transpose(test,perm=[0,1,3,2])[0,1,4,5].eval())\n",
    "    \n",
    "#     test_con1 = tf.tensordot(fd,God,[[1],[0]])\n",
    "#     test_con2 = tf.transpose(test_con1,perm=[1,0,2,3])\n",
    "#     test_con3 = tf.transpose(tf.tensordot(fd,God,[[0],[2]]),perm=[1,2,0,3])\n",
    "#     test_con4 = tf.transpose(test_con3,perm=[0,1,3,2])\n",
    "#     test_con = tf.add(tf.subtract(tf.subtract(test_con1,test_con2),test_con3),test_con4)\n",
    "#     print(test_con1[0,1,4,5].eval(), test_con2[0,1,4,5].eval(),test_con3[0,1,4,5].eval(),test_con4[0,1,4,5].eval())\n",
    "#     print(test_con[0,1,4,5].eval())\n",
    "#     print(\"true,\",test3[0,1,4,5])\n",
    "#     print(\"test,\",test_con3[0,1,4,5].eval())\n",
    "#     print(\"tf,\",tf.tensordot(fd,God,[[0],[2]])[4,0,1,5].eval())\n",
    "#     print(\"tf_p,\", tf.transpose(tf.tensordot(fd,God,[[0],[2]]),perm=[1,2,0,3])[0,1,4,5].eval())\n",
    "#     print(\"numpy,\",np.tensordot(fd_l,God_l,axes=((0),(2)))[0,1,4,5])\n",
    "#     print(tf.transpose(fdGod_fodGd_kl,perm=[1,2,0,3])[0,1,4,5].eval())\n",
    "\n",
    "# A = tf.constant([[1,2,3,4,5,6,7,8],\n",
    "#                  [3,4,5,6,7,8,9,1], \n",
    "#                  [7,8,9,1,2,3,4,5], \n",
    "#                  [6,7,8,9,1,2,3,4],\n",
    "#                  [1,2,3,4,5,6,7,8],\n",
    "#                  [3,4,5,6,7,8,9,1], \n",
    "#                  [7,8,9,1,2,3,4,5], \n",
    "#                  [6,7,8,9,1,2,3,4] ])\n",
    "\n",
    "# # indices = tf.constant([4,5,6,7, 4,5,6,7, 4,5,6,7, 4,5,6,7, 0,1,2,3, 0,1,2,3, 0,1,2,3, 0,1,2,3])\n",
    "# indices =tf.reshape(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0),[-1])\n",
    "\n",
    "# # prepare row indices\n",
    "# # row_indices = tf.range(tf.shape(indices)[0])\n",
    "# # row_indices = tf.constant([0,0,0,0, 1,1,1,1, 2,2,2,2, 3,3,3,3, 4,4,4,4, 5,5,5,5, 6,6,6,6, 7,7,7,7])\n",
    "# row_indices = tf.reshape(tf.transpose(tf.concat([tf.broadcast_to(holes,[4,4]),tf.broadcast_to(particles,[4,4])],1)),[-1])\n",
    "# # row_indices = tf.reshape(tf)\n",
    "# # zip row indices with column indices\n",
    "# full_indices = tf.stack([row_indices, indices], axis=1)\n",
    "\n",
    "# # retrieve values by indices\n",
    "# # indices = tf.transpose(full_indices)\n",
    "# # updates = tf.reshape(tf.gather_nd(A, full_indices),[2,2])\n",
    "# updates = tf.gather_nd(A, full_indices)\n",
    "# S = tf.scatter_nd(full_indices,updates,[8,8])\n",
    "\n",
    "# test = tf.scatter_nd([[[1,0,0,1],[1,0,0,0]]],[[1,2]],[8,8,8,8])\n",
    "# idx2b = tf.expand_dims(tf.stack([row_indices,row_indices,indices,indices],axis=1),0)\n",
    "# test2b = tf.zeros([8,8,8,8])\n",
    "# with tf.Session() as sess:\n",
    "# #     print(full_indices.eval())\n",
    "#     print(test[1,0,0,1].eval())\n",
    "#     print(test[1,0,0,0].eval())\n",
    "# #     print(tf.gather_nd([[[1,0,0,1],[1,0,0,0]]],test))\n",
    "#     print(A.eval())\n",
    "#     print(\"\\n\")\n",
    "#     print(S.eval())\n",
    "#     # print(full_indices.eval())\n",
    "#     # print(tf.transpose(full_indices))\n",
    "#     print(idx2b.eval())\n",
    "#     print(tf.gather_nd(test2b,idx2b).eval())\n",
    "# #     print(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0).eval())\n",
    "# #     print(tf.reshape(tf.concat([tf.broadcast_to(particles,[4,4]),tf.broadcast_to(holes,[4,4])],0),[-1]).eval())\n",
    "# #     print(tf.reshape(tf.transpose(tf.broadcast_to(B1_t,[4,8])),[-1]).eval())\n",
    "# #     print(tf.broadcast_to(tf.concat([holes,particles],1),[4,4]).eval())\n",
    "# #     print(tf.reshape(test,[-1]).eval())\n",
    "# # session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.constant(1)\n",
    "# shape = a.shape\n",
    "# print(len(shape))\n",
    "\n",
    "# def off_diagonal(tensor):\n",
    "#     # returns off diagonal elements defined by indices ph,hp (1B) or pphh,hhpp (2B)\n",
    "#     shape = tensor.shape\n",
    "#     if(shape==() or len(shape)==1):\n",
    "#         return 0\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hols = np.asarray([0,1,2,3])\n",
    "# pars = np.asarray([4,5,6,7])\n",
    "\n",
    "# count = 0\n",
    "# for p in pars:\n",
    "#     for pp in pars:\n",
    "#         for h in hols:\n",
    "#             for hh in hols:\n",
    "# #                 print(p,pp,h,hh)\n",
    "#                 count += 1\n",
    "                \n",
    "# print(count)\n",
    "\n",
    "# indices are p,pp,h,hh\n",
    "# for every possible combination:\n",
    "#\n",
    "# p   --> switches every 64 states - 2^6\n",
    "# pp  --> switches every 16 states - 2^4\n",
    "# h   --> switches every 04 states - 2^2\n",
    "# hh  --> swithces every 01 states - 2^0\n",
    "\n",
    "# ind1_C = tf.concat([tf.broadcast_to(holes,[64,4]), tf.broadcast_to(particles,[64,4])],1)\n",
    "# ind1_TC = tf.transpose(ind1_C) \n",
    "# ind1 = tf.reshape(ind1_TC,[-1])\n",
    "\n",
    "# ind2_C = tf.concat([tf.broadcast_to(holes,[16,16]),tf.broadcast_to(particles,[16,16])],1)\n",
    "# ind2_TC = tf.transpose(ind2_C)\n",
    "# ind2 = tf.reshape(ind2_TC,[-1])\n",
    "\n",
    "# ind3_C = tf.concat([tf.broadcast_to(particles,[4,64]),tf.broadcast_to(holes,[4,64])],1)\n",
    "# ind3_TC = tf.transpose(ind3_C) \n",
    "# ind3 = tf.reshape(ind3_TC,[-1])\n",
    "\n",
    "# ind4_C = tf.concat([tf.broadcast_to(particles,[1,256]),tf.broadcast_to(holes,[1,256])],1)\n",
    "# ind4_TC = tf.transpose(ind4_C)\n",
    "# ind4 = tf.reshape(ind4_TC,[-1])\n",
    "\n",
    "# pphh_ind = tf.stack([ind1,ind2,ind3,ind4],axis=1)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print(pphh_ind.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "testing_tensorflow_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
