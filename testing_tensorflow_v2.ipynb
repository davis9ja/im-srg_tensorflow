{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/davis9ja/im-srg_tensorflow/blob/master/testing_tensorflow_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "12WjV8yIyAb0",
    "outputId": "3ddb6ce6-28af-434f-bce6-dcaa221a307a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQZeGM1NyHBk"
   },
   "outputs": [],
   "source": [
    "# --- BUILD HAMILTONIAN -----------\n",
    "\n",
    "holes = np.asarray([0,1,2,3])\n",
    "particles = np.asarray([4,5,6,7])\n",
    "\n",
    "# one-body basis is just all possible single particle states\n",
    "# B1 = tf.constant(holes+particles)#np.append(holes,particles)\n",
    "B1 = np.append(holes,particles)\n",
    "\n",
    "# we build two-body basis with all possible pairs of single particle states\n",
    "B2 = []\n",
    "ind2B = {}\n",
    "\n",
    "count = 0\n",
    "for h in holes:\n",
    "    for h2 in holes:\n",
    "        B2.append((h,h2))\n",
    "        ind2B[(h,h2)] = count\n",
    "        count += 1\n",
    "\n",
    "for h in holes:\n",
    "    for p in particles:\n",
    "        B2.append((h,p))\n",
    "        ind2B[(h,p)] = count\n",
    "        count += 1\n",
    "        \n",
    "for p in particles:\n",
    "    for h in holes:\n",
    "        B2.append((p,h))\n",
    "        ind2B[(p,h)] = count\n",
    "        count += 1\n",
    "            \n",
    "for p in particles:\n",
    "    for p2 in particles:\n",
    "        B2.append((p,p2)) \n",
    "        ind2B[(p,p2)] = count\n",
    "        count += 1           \n",
    "\n",
    "# the one-body Hamiltonian is diagonal, with elements given by P-1 or \n",
    "# single particle state index divided by 2 (rounding down)\n",
    "H1B = np.zeros((len(B1), len(B1)))\n",
    "for i in range(len(B1)):\n",
    "    H1B[i,i] = np.floor_divide(i,2)\n",
    "\n",
    "# the two-body Hamiltonian is sparse; only non-zero contributions \n",
    "# where pq=rs or pq=sr=-rs\n",
    "H2B = np.zeros((len(B2), len(B2)))\n",
    "for i in range(len(B2)):\n",
    "    for j in range(len(B2)):\n",
    "        p, q = B2[i]\n",
    "        r, s = B2[j]\n",
    "        \n",
    "        pp = np.floor_divide(p,2)\n",
    "        qp = np.floor_divide(q,2)\n",
    "        rp = np.floor_divide(r,2)\n",
    "        sp = np.floor_divide(s,2)\n",
    "        \n",
    "        ps = 1 if p%2==0 else -1\n",
    "        qs = 1 if q%2==0 else -1\n",
    "        rs = 1 if r%2==0 else -1\n",
    "        ss = 1 if s%2==0 else -1\n",
    "        \n",
    "        if pp != qp or rp != sp:\n",
    "            continue\n",
    "        if ps == qs or rs == ss:\n",
    "            continue\n",
    "        if ps == rs and qs == ss:\n",
    "            H2B[i,j] = -0.25\n",
    "        if ps == ss and qs == rs:\n",
    "            H2B[i,j] = 0.25\n",
    "\n",
    "B1_len = len(B1)\n",
    "H2B_t = np.zeros((B1_len,B1_len,B1_len,B1_len))\n",
    "for p in B1:\n",
    "    for q in B1:\n",
    "        for r in B1:\n",
    "            for s in B1:\n",
    "                H2B_t[p,q,r,s] = H2B[ind2B[(p,q)], ind2B[(r,s)]]\n",
    "        \n",
    "# test2 = np.einsum('ijij->ij',H2B_t)\n",
    "# print(test2)\n",
    "# for i in holes:\n",
    "#   for j in holes:\n",
    "#         print(H2B[ind2B[(i,j)], ind2B[(i,j)]])\n",
    "#         print(H2B_t[i,j,i,j])\n",
    "# print(np.shape(list(map(lambda i: H2B_t[i,:,i,:], holes))))\n",
    "# test = list(map(lambda i,j: H2B_t[i,j,i,j],holes,particles))\n",
    "# print(np.shape(test))\n",
    "\n",
    "\n",
    "holes = tf.convert_to_tensor(holes, dtype=tf.int64)\n",
    "particles = tf.convert_to_tensor(particles, dtype=tf.int64)\n",
    "\n",
    "H1B_t = tf.convert_to_tensor(H1B, dtype=tf.float64)\n",
    "H2B_t = tf.convert_to_tensor(H2B_t, dtype=tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "t-gCmAPvyp4z",
    "outputId": "5c7228c6-8225-4e6b-9958-74543aa7156f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jacob/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# --- NORMAL ORDER HAMILTONIAN -----------\n",
    "# Calculate 0b, 1b, 2b pieces \n",
    "#\n",
    "# zero-body piece is scalar\n",
    "# one-body piece is rank 2 tensor\n",
    "# two-body piece is rank 4 tensor\n",
    "\n",
    "# - Calculate 0b tensor\n",
    "E = tf.Variable(0, dtype=tf.float64)\n",
    "contr_1b = tf.map_fn(lambda i: H1B_t[i,i], holes, dtype=tf.float64)\n",
    "contr_2b = tf.map_fn(lambda i: H2B_t[i,:,i,:], holes, dtype=tf.float64)\n",
    "\n",
    "E = tf.assign_add( E, tf.reduce_sum(contr_1b, 0) )\n",
    "E = tf.assign_add( E, 0.5*tf.reduce_sum(contr_2b, [0,1,2]) )\n",
    "\n",
    "# - Calculate 1b tensor\n",
    "f = tf.Variable(tf.identity(H1B_t), dtype=tf.float64)\n",
    "contr_2b = tf.map_fn(lambda i: H2B_t[:,i,:,i], holes, dtype=tf.float64)\n",
    "contr_2b = tf.reduce_sum(contr_2b,0) # sum over holes\n",
    "\n",
    "f = tf.add(f,contr_2b)\n",
    "\n",
    "# - Calculate 2b tensor\n",
    "G = tf.identity(H2B_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwn3kw6yeUQO"
   },
   "outputs": [],
   "source": [
    "# --- SET UP WHITE'S GENERATOR -----------\n",
    "\n",
    "# TODO: try reduce_sum, einsum, tensordot?, other methods\n",
    "\n",
    "def white(f, G, holes, particles):\n",
    "  \n",
    "    # - Calculate 1b generator tensor\n",
    "    eta1B = tf.zeros(f.shape,dtype=tf.float64)\n",
    "    eta1Bph = eta1B[particles[0]:particles[-1]+1,holes[0]:holes[-1]+1]\n",
    "    fhh = f[holes[0]:holes[-1]+1,holes[0]:holes[-1]+1]\n",
    "    fpp = f[particles[0]:particles[-1]+1,particles[0]:particles[-1]+1]\n",
    "    Gphph = G[particles[0]:particles[-1]+1, holes[0]:holes[-1]+1, particles[0]:particles[-1]+1, holes[0]:holes[-1]+1]\n",
    "    Gphph = tf.reduce_sum(Gphph,[0,2]) # reduce to same rank as f\n",
    "    \n",
    "    Deltaph = tf.subtract(fpp, tf.add(fhh,Gphph))\n",
    "    temp = tf.div_no_nan(eta1Bph,Deltaph)\n",
    "    \n",
    "    \n",
    "    # - Calculate 2b generator tensor\n",
    "    eta2B = tf.zeros(G.shape)\n",
    "    return temp\n",
    "#     return (eta1B, eta2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fEsXazD7OBO"
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qqW27CGI0FF8",
    "outputId": "dbfb500f-ea0a-4e0d-f8d2-659b5719aa1b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [1 2 3 4]\n",
      " [1 2 3 4]\n",
      " [1 2 3 4]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The inner 1 dimensions of output.shape=[8,8] must match the inner 1 dimensions of updates.shape=[4,4]: Dimension 0 in both shapes must be equal, but are 8 and 4. Shapes are [8] and [4]. for 'ScatterNd_2' (op: 'ScatterNd') with input shapes: [4,1], [4,4], [2] and with input tensors computed as partial shapes: input[2] = [8,8].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: The inner 1 dimensions of output.shape=[8,8] must match the inner 1 dimensions of updates.shape=[4,4]: Dimension 0 in both shapes must be equal, but are 8 and 4. Shapes are [8] and [4]. for 'ScatterNd_2' (op: 'ScatterNd') with input shapes: [4,1], [4,4], [2] and with input tensors computed as partial shapes: input[2] = [8,8].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-337194f72281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mscatter_nd\u001b[0;34m(indices, updates, shape, name)\u001b[0m\n\u001b[1;32m   7823\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7824\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 7825\u001b[0;31m         \"ScatterNd\", indices=indices, updates=updates, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   7826\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7827\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The inner 1 dimensions of output.shape=[8,8] must match the inner 1 dimensions of updates.shape=[4,4]: Dimension 0 in both shapes must be equal, but are 8 and 4. Shapes are [8] and [4]. for 'ScatterNd_2' (op: 'ScatterNd') with input shapes: [4,1], [4,4], [2] and with input tensors computed as partial shapes: input[2] = [8,8]."
     ]
    }
   ],
   "source": [
    "# indices = tf.constant([[4], [5], [6], [7]])\n",
    "# updates = tf.gather(f,particles) #tf.constant(tf.gather(f,holes))\n",
    "# shape = tf.constant([8, 8])\n",
    "# scatter = tf.scatter_nd(indices, updates, shape)\n",
    "\n",
    "# indices = tf.constant([[0,1,2,3],[0,1,2,3]])\n",
    "# updates = tf.constant([[1,2,3,4],[1,2,3,4]])\n",
    "# ref = tf.Variable([[1,2,3,4],[1,2,3,4]])\n",
    "x = tf.constant([[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]])\n",
    "y = tf.constant([[1,2,3,4],[1,2,3,4]])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(x.eval())\n",
    "print(tf.scatter_nd(tf.constant([[0],[1],[2],[3]]),x,(8,8)).eval())\n",
    "\n",
    "\n",
    "\n",
    "print(white(f,G,holes,particles).eval())\n",
    "# eta1B,eta2B = white(f,G,holes,particles)\n",
    "# print(eta1B.eval())\n",
    "# print(tf.einsum('ijkl->ik',G).eval())\n",
    "# print(  tf.reduce_sum(tf.map_fn(lambda p: H2B_t[p,:,p,:], particles, dtype=tf.float64),0).eval())\n",
    "# print(E.eval())\n",
    "# print(f.eval())\n",
    "# print(tf.gather(f,particles).eval())\n",
    "# print(scatter.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNNLN6YM0Kot"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqTTHpAJ4JPT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "testing_tensorflow_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
